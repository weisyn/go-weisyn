#!/bin/bash
# æ£€æŸ¥å¹¶ç”Ÿæˆä¿®å¤å‹å¥½çš„æŠ¥å‘Š
# æ¶æ„ï¼šæ£€æŸ¥ï¼ˆä¸€æ¬¡æ€§ï¼‰-> æŠ¥å‘Šç”Ÿæˆï¼ˆåŒ…å«ä»£ç ä¸Šä¸‹æ–‡ï¼‰-> ä¿®å¤
# ç›®çš„ï¼šä¸ºä¿®å¤æä¾›ç²¾ç¡®å®šä½ï¼Œå³ä½¿è¡Œå·å˜åŒ–ä¹Ÿèƒ½æ‰¾åˆ°é—®é¢˜

set -e

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(cd "$SCRIPT_DIR/../.." && pwd)"
cd "$PROJECT_ROOT"

# é…ç½®
RAW_OUTPUT="${1:-.lint-raw.json}"      # åŸå§‹æ£€æŸ¥ç»“æœï¼ˆä¸€æ¬¡æ€§ç”Ÿæˆï¼‰
REPORT_JSON="${2:-.lint-report.json}"  # ä¿®å¤å‹å¥½çš„æŠ¥å‘Šï¼ˆJSONï¼‰
REPORT_MD="${3:-.lint-report.md}"     # ä¿®å¤å‹å¥½çš„æŠ¥å‘Šï¼ˆMarkdownï¼‰

echo "ğŸ” ä»£ç è´¨é‡æ£€æŸ¥ä¸æŠ¥å‘Šç”Ÿæˆ"
echo "=========================================="
echo "åŸå§‹è¾“å‡º: $RAW_OUTPUT"
echo "æŠ¥å‘Š JSON: $REPORT_JSON"
echo "æŠ¥å‘Š Markdown: $REPORT_MD"
echo ""

# æ£€æŸ¥å·¥å…·
if [ ! -f "./bin/golangci-lint" ]; then
    echo "âŒ golangci-lint æœªæ‰¾åˆ°ï¼Œè¯·å…ˆè¿è¡Œ: make install-lint-tools"
    exit 1
fi

# æ­¥éª¤1: è¿è¡Œæ£€æŸ¥ï¼ˆä¸€æ¬¡æ€§ï¼‰
echo "ğŸ“Š æ­¥éª¤1: è¿è¡Œ golangci-lint æ£€æŸ¥ï¼ˆè¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼‰..."
if [ -f "$RAW_OUTPUT" ] && [ "$RAW_OUTPUT" != ".lint-raw.json" ]; then
    echo "âš ï¸  ä½¿ç”¨å·²å­˜åœ¨çš„æ£€æŸ¥ç»“æœ: $RAW_OUTPUT"
else
    # å°è¯•ä¸åŒçš„æ£€æŸ¥æ–¹å¼ï¼ˆå¤„ç† go.work é—®é¢˜ï¼‰
    echo "   æ­£åœ¨æ£€æŸ¥ä»£ç ..."
    
    # æ–¹æ³•1: å°è¯•ç›´æ¥è¿è¡Œï¼ˆå¯èƒ½å› ä¸º go.work å¤±è´¥ï¼‰
    ./bin/golangci-lint run --output.json.path "$RAW_OUTPUT" 2>/tmp/lint-errors.txt || true
    
    # æ£€æŸ¥æ˜¯å¦æœ‰é—®é¢˜
    issue_count=$(cat "$RAW_OUTPUT" 2>/dev/null | python3 -c "import json, sys; d=json.load(sys.stdin); print(len(d.get('Issues', [])))" 2>/dev/null || echo "0")
    
    # å¦‚æœå¤±è´¥æˆ–é—®é¢˜æ•°ä¸º0ï¼Œä½¿ç”¨æ–‡ä»¶åˆ—è¡¨æ–¹å¼ï¼ˆè§£å†³ go.work é—®é¢˜ï¼‰
    if [ ! -s "$RAW_OUTPUT" ] || [ "$issue_count" = "0" ]; then
        echo "   ä½¿ç”¨æ–‡ä»¶åˆ—è¡¨æ–¹å¼æ£€æŸ¥ï¼ˆè§£å†³ go.work é—®é¢˜ï¼‰..."
        
        # æŸ¥æ‰¾æ‰€æœ‰éœ€è¦æ£€æŸ¥çš„ Go æ–‡ä»¶
        echo '{"Issues":[]}' > "$RAW_OUTPUT"
        
        # æŸ¥æ‰¾æ‰€æœ‰ .go æ–‡ä»¶ï¼ˆæ’é™¤æµ‹è¯•æ–‡ä»¶å’Œç”Ÿæˆæ–‡ä»¶ï¼‰
        go_files=$(find . \
            -name "*.go" \
            -not -path "./_archived/*" \
            -not -path "./vendor/*" \
            -not -path "./_docs/*" \
            -not -path "./_sdks/*" \
            -not -path "./docs.backup.*/*" \
            -not -path "./data/*" \
            -not -path "./bin/*" \
            -not -path "./config-temp/*" \
            -not -name "*_test.go" \
            -not -name "*.pb.go" \
            2>/dev/null | head -1000)
        
        file_count=$(echo "$go_files" | grep -c . || echo "0")
        echo "   æ‰¾åˆ° $file_count ä¸ª Go æ–‡ä»¶éœ€è¦æ£€æŸ¥"
        
        if [ "$file_count" -gt 0 ]; then
            # ä½¿ç”¨ Python è„šæœ¬è¿›è¡Œæ‰¹é‡æ£€æŸ¥å’Œåˆå¹¶ï¼ˆæ›´å¯é ï¼‰
            echo "   å¼€å§‹æ‰¹é‡æ£€æŸ¥ $file_count ä¸ªæ–‡ä»¶..."
            
            python3 << BATCH_CHECK_SCRIPT
import json
import subprocess
import os
import sys
from pathlib import Path

raw_output = "$RAW_OUTPUT"
go_files_list = """$go_files"""

# è§£ææ–‡ä»¶åˆ—è¡¨
files = [f.strip() for f in go_files_list.split('\n') if f.strip()]

all_issues = []
total_files = len(files)
processed = 0
batch_size = 50  # æ¯50ä¸ªæ–‡ä»¶æ˜¾ç¤ºä¸€æ¬¡è¿›åº¦

print(f"   æ€»å…±éœ€è¦æ£€æŸ¥ {total_files} ä¸ªæ–‡ä»¶")

for idx, file_path in enumerate(files, 1):
    if not os.path.exists(file_path):
        continue
    
    try:
        # æ£€æŸ¥å•ä¸ªæ–‡ä»¶
        result = subprocess.run(
            ['./bin/golangci-lint', 'run', file_path, '--output.json.path', '/tmp/lint-single.json'],
            capture_output=True,
            timeout=30,
            cwd='.'
        )
        
        # è¯»å–ç»“æœ
        if os.path.exists('/tmp/lint-single.json'):
            with open('/tmp/lint-single.json', 'r') as f:
                try:
                    data = json.load(f)
                    issues = data.get('Issues', [])
                    all_issues.extend(issues)
                    processed += 1
                except json.JSONDecodeError:
                    pass
            os.remove('/tmp/lint-single.json')
        
        # æ˜¾ç¤ºè¿›åº¦
        if idx % batch_size == 0 or idx == total_files:
            print(f"   è¿›åº¦: {idx}/{total_files} ({idx*100//total_files}%) - å·²æ”¶é›† {len(all_issues)} ä¸ªé—®é¢˜")
    
    except subprocess.TimeoutExpired:
        print(f"   âš ï¸  æ–‡ä»¶ {file_path} æ£€æŸ¥è¶…æ—¶ï¼Œè·³è¿‡")
    except Exception as e:
        pass  # é™é»˜å¿½ç•¥é”™è¯¯

# ä¿å­˜ç»“æœ
result_data = {"Issues": all_issues}
with open(raw_output, 'w') as f:
    json.dump(result_data, f)

print(f"   âœ… æ£€æŸ¥å®Œæˆï¼å…±æ£€æŸ¥ {processed} ä¸ªæ–‡ä»¶ï¼Œå‘ç° {len(all_issues)} ä¸ªé—®é¢˜")
BATCH_CHECK_SCRIPT
        else
            echo "   âš ï¸  æœªæ‰¾åˆ°éœ€è¦æ£€æŸ¥çš„ Go æ–‡ä»¶"
        fi
    fi
    
    if [ -s /tmp/lint-errors.txt ] || [ -s /tmp/lint-errors2.txt ]; then
        echo "âš ï¸  æ£€æŸ¥è¿‡ç¨‹ä¸­æœ‰é”™è¯¯è¾“å‡ºï¼Œä½†ç»§ç»­å¤„ç†..."
        cat /tmp/lint-errors.txt /tmp/lint-errors2.txt 2>/dev/null | head -20
    fi
    
    echo "âœ… æ£€æŸ¥å®Œæˆï¼Œç»“æœå·²ä¿å­˜åˆ°: $RAW_OUTPUT"
fi

# æ­¥éª¤2: ç”Ÿæˆä¿®å¤å‹å¥½çš„æŠ¥å‘Šï¼ˆåŒ…å«ä»£ç ä¸Šä¸‹æ–‡ï¼‰
echo ""
echo "ğŸ“ æ­¥éª¤2: ç”Ÿæˆä¿®å¤å‹å¥½çš„æŠ¥å‘Šï¼ˆæå–ä»£ç ä¸Šä¸‹æ–‡ï¼‰..."

# å°†å˜é‡å†™å…¥ä¸´æ—¶æ–‡ä»¶ä¾› Python ä½¿ç”¨
echo "$RAW_OUTPUT" > /tmp/lint-raw-output-path.txt
echo "$REPORT_JSON" > /tmp/lint-report-json-path.txt
echo "$REPORT_MD" > /tmp/lint-report-md-path.txt

python3 << 'PYTHON_SCRIPT'
import json
import os
from collections import defaultdict
from datetime import datetime

# ä¼˜å…ˆçº§å®šä¹‰
PRIORITY_HIGH = ['errcheck', 'gosec', 'bodyclose']
PRIORITY_MEDIUM = ['revive', 'staticcheck', 'gocritic', 'govet', 'ineffassign']
PRIORITY_LOW = ['unused', 'unparam', 'prealloc', 'misspell']

def get_priority(linter):
    if linter in PRIORITY_HIGH:
        return 1, 'é«˜'
    elif linter in PRIORITY_MEDIUM:
        return 2, 'ä¸­'
    else:
        return 3, 'ä½'

def extract_code_context(file_path, line_num, context_lines=3):
    """æå–ä»£ç ä¸Šä¸‹æ–‡ï¼ˆé—®é¢˜è¡Œå‰åå‡ è¡Œï¼‰"""
    try:
        if not os.path.exists(file_path):
            return None, None
        
        with open(file_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()
        
        if line_num < 1 or line_num > len(lines):
            return None, None
        
        # æå–ä¸Šä¸‹æ–‡ï¼ˆå‰åå„ context_lines è¡Œï¼‰
        start_line = max(0, line_num - context_lines - 1)
        end_line = min(len(lines), line_num + context_lines)
        
        context_before = lines[start_line:line_num-1]
        problem_line = lines[line_num-1] if line_num <= len(lines) else ""
        context_after = lines[line_num:end_line]
        
        # æ„å»ºä¸Šä¸‹æ–‡
        context = {
            'start_line': start_line + 1,
            'problem_line': line_num,
            'end_line': end_line,
            'before': [line.rstrip() for line in context_before],
            'line': problem_line.rstrip(),
            'after': [line.rstrip() for line in context_after]
        }
        
        # ç”Ÿæˆä»£ç ç‰‡æ®µï¼ˆç”¨äºå®šä½ï¼‰
        code_snippet = problem_line.strip()[:100]  # é™åˆ¶é•¿åº¦
        
        return context, code_snippet
    except Exception as e:
        return None, None

try:
    # è¯»å–æ–‡ä»¶è·¯å¾„
    with open('/tmp/lint-raw-output-path.txt', 'r') as f:
        raw_output_file = f.read().strip()
    with open('/tmp/lint-report-json-path.txt', 'r') as f:
        report_json_file = f.read().strip()
    with open('/tmp/lint-report-md-path.txt', 'r') as f:
        report_md_file = f.read().strip()
    
    # è¯»å–åŸå§‹æ£€æŸ¥ç»“æœ
    with open(raw_output_file, 'r') as f:
        raw_data = json.load(f)
    
    issues = raw_data.get('Issues', [])
    total = len(issues)
    
    print(f"   æ‰¾åˆ° {total} ä¸ªé—®é¢˜")
    print(f"   æ­£åœ¨æå–ä»£ç ä¸Šä¸‹æ–‡...")
    
    # å¤„ç†æ¯ä¸ªé—®é¢˜ï¼Œæå–ä»£ç ä¸Šä¸‹æ–‡
    processed_issues = []
    issues_by_file = defaultdict(list)
    
    for idx, issue in enumerate(issues):
        if (idx + 1) % 100 == 0:
            print(f"   å¤„ç†è¿›åº¦: {idx + 1}/{total}")
        
        linter = issue.get('FromLinter', 'unknown')
        file_path = issue.get('Pos', {}).get('Filename', 'unknown')
        line = issue.get('Pos', {}).get('Line', 0)
        text = issue.get('Text', '')
        severity = issue.get('Severity', '')
        
        # æå–ä»£ç ä¸Šä¸‹æ–‡
        context, code_snippet = extract_code_context(file_path, line)
        
        issue_data = {
            'id': f"{file_path}:{line}:{linter}",  # å”¯ä¸€æ ‡è¯†
            'linter': linter,
            'file': file_path,
            'line': line,
            'text': text,
            'severity': severity,
            'code_context': context,  # ä»£ç ä¸Šä¸‹æ–‡
            'code_snippet': code_snippet,  # ä»£ç ç‰‡æ®µï¼ˆç”¨äºå®šä½ï¼‰
            'priority': get_priority(linter)[0],
            'priority_name': get_priority(linter)[1]
        }
        
        processed_issues.append(issue_data)
        issues_by_file[file_path].append(issue_data)
    
    # ç»Ÿè®¡ä¿¡æ¯
    linter_counts = defaultdict(int)
    for issue in processed_issues:
        linter_counts[issue['linter']] += 1
    
    # ç”ŸæˆæŠ¥å‘Šæ•°æ®
    report_data = {
        'generated_at': datetime.now().isoformat(),
        'raw_file': raw_output_file,
        'total_issues': total,
        'files_count': len(issues_by_file),
        'linter_counts': dict(linter_counts),
        'issues_by_file': {
            file_path: sorted(issues, key=lambda x: x['line'])
            for file_path, issues in issues_by_file.items()
        },
        'all_issues': processed_issues
    }
    
    # ä¿å­˜ JSON æŠ¥å‘Š
    with open(report_json_file, 'w', encoding='utf-8') as f:
        json.dump(report_data, f, indent=2, ensure_ascii=False)
    
    print(f"âœ… JSON æŠ¥å‘Šå·²ç”Ÿæˆ: {report_json_file}")
    
    # ç”Ÿæˆ Markdown æŠ¥å‘Š
    md_lines = []
    md_lines.append("# ä»£ç è´¨é‡æ£€æŸ¥æŠ¥å‘Šï¼ˆä¿®å¤å‹å¥½ç‰ˆï¼‰")
    md_lines.append("")
    md_lines.append(f"**ç”Ÿæˆæ—¶é—´**: {report_data['generated_at']}")
    md_lines.append(f"**æ€»é—®é¢˜æ•°**: {total} ä¸ª")
    md_lines.append(f"**æ¶‰åŠæ–‡ä»¶**: {len(issues_by_file)} ä¸ª")
    md_lines.append("")
    md_lines.append("---")
    md_lines.append("")
    md_lines.append("## ğŸ“Š é—®é¢˜ç»Ÿè®¡")
    md_lines.append("")
    md_lines.append("### æŒ‰æ£€æŸ¥å™¨ç»Ÿè®¡")
    md_lines.append("")
    md_lines.append("| æ£€æŸ¥å™¨ | é—®é¢˜æ•° | ä¼˜å…ˆçº§ |")
    md_lines.append("|--------|--------|--------|")
    for linter, count in sorted(linter_counts.items(), key=lambda x: x[1], reverse=True):
        _, priority_name = get_priority(linter)
        md_lines.append(f"| {linter} | {count} | {priority_name} |")
    
    md_lines.append("")
    md_lines.append("### æŒ‰ä¼˜å…ˆçº§ç»Ÿè®¡")
    md_lines.append("")
    priority_counts = defaultdict(int)
    for issue in processed_issues:
        priority_counts[issue['priority_name']] += 1
    
    # å¯è§†åŒ–è¿›åº¦æ¡
    for priority in ['é«˜', 'ä¸­', 'ä½']:
        count = priority_counts[priority]
        percentage = (count / total * 100) if total > 0 else 0
        # ç”Ÿæˆè¿›åº¦æ¡ï¼ˆæ¯2%ä¸€ä¸ªå­—ç¬¦ï¼Œæœ€å¤š50ä¸ªå­—ç¬¦ï¼‰
        bar_length = int(percentage / 2) if percentage > 0 else 0
        bar = "â–ˆ" * bar_length + "â–‘" * (50 - bar_length)
        md_lines.append(f"- **{priority}ä¼˜å…ˆçº§**: {count:4d} ä¸ª ({percentage:5.1f}%) {bar}")
    
    md_lines.append("")
    md_lines.append("### æŒ‰æ£€æŸ¥å™¨ç»Ÿè®¡ï¼ˆå‰10ä¸ªï¼‰")
    md_lines.append("")
    md_lines.append("| æ’å | æ£€æŸ¥å™¨ | é—®é¢˜æ•° | ç™¾åˆ†æ¯” | ä¼˜å…ˆçº§ | è¿›åº¦æ¡ |")
    md_lines.append("|------|--------|--------|--------|--------|--------|")
    
    # æŒ‰æ•°é‡æ’åº
    sorted_linters = sorted(linter_counts.items(), key=lambda x: x[1], reverse=True)
    for rank, (linter, count) in enumerate(sorted_linters[:10], 1):
        _, priority_name = get_priority(linter)
        percentage = (count / total * 100) if total > 0 else 0
        bar_length = int(percentage / 2) if percentage > 0 else 0
        bar = "â–ˆ" * min(bar_length, 50) + "â–‘" * max(0, 50 - bar_length)
        md_lines.append(f"| {rank} | {linter} | {count:4d} | {percentage:5.1f}% | {priority_name} | {bar} |")
    
    md_lines.append("")
    md_lines.append("---")
    md_lines.append("")
    md_lines.append("## ğŸ“‹ é—®é¢˜è¯¦æƒ…ï¼ˆæŒ‰æ–‡ä»¶åˆ†ç»„ï¼‰")
    md_lines.append("")
    md_lines.append("> ğŸ’¡ **æç¤º**: æ¯ä¸ªé—®é¢˜éƒ½åŒ…å«ä»£ç ä¸Šä¸‹æ–‡ï¼Œå³ä½¿è¡Œå·å˜åŒ–ä¹Ÿèƒ½å‡†ç¡®å®šä½")
    md_lines.append("")
    
    # æ·»åŠ æ€»ä½“è¿›åº¦å¯è§†åŒ–
    if total > 0:
        md_lines.append("### ğŸ“ˆ ä¿®å¤è¿›åº¦æ¦‚è§ˆ")
        md_lines.append("")
        md_lines.append("```")
        md_lines.append(f"æ€»é—®é¢˜æ•°: {total}")
        md_lines.append("")
        for priority in ['é«˜', 'ä¸­', 'ä½']:
            count = priority_counts[priority]
            percentage = (count / total * 100) if total > 0 else 0
            bar_length = int(percentage / 2)
            bar = "â–ˆ" * bar_length + "â–‘" * (50 - bar_length)
            md_lines.append(f"{priority:2s}ä¼˜å…ˆçº§: {bar} {count:4d} ({percentage:5.1f}%)")
        md_lines.append("```")
        md_lines.append("")
    
    # æŒ‰ä¼˜å…ˆçº§å’Œæ–‡ä»¶åˆ†ç»„
    for priority_level, priority_name in [(1, 'é«˜ä¼˜å…ˆçº§'), (2, 'ä¸­ä¼˜å…ˆçº§'), (3, 'ä½ä¼˜å…ˆçº§')]:
        priority_files = []
        for file_path, file_issues in issues_by_file.items():
            has_priority_issue = any(i['priority'] == priority_level for i in file_issues)
            if has_priority_issue:
                priority_files.append((file_path, file_issues))
        
        if priority_files:
            md_lines.append(f"### {priority_name}é—®é¢˜")
            md_lines.append("")
            
            # æŒ‰é—®é¢˜æ•°é‡æ’åº
            priority_files.sort(key=lambda x: len(x[1]), reverse=True)
            
            for file_path, file_issues in priority_files:
                # ç»Ÿè®¡è¯¥æ–‡ä»¶çš„é—®é¢˜
                file_total = len(file_issues)
                priority_issues = [i for i in file_issues if i['priority'] == priority_level]
                
                md_lines.append(f"#### ğŸ“„ `{file_path}` ({len(priority_issues)} ä¸ª{priority_name}é—®é¢˜ï¼Œå…± {file_total} ä¸ª)")
                md_lines.append("")
                
                # æŒ‰è¡Œå·æ’åº
                for issue in sorted(priority_issues, key=lambda x: x['line']):
                    md_lines.append(f"**é—®é¢˜ #{issue['line']}** [{issue['linter']}]")
                    md_lines.append("")
                    md_lines.append(f"> {issue['text']}")
                    md_lines.append("")
                    
                    # æ˜¾ç¤ºä»£ç ä¸Šä¸‹æ–‡
                    if issue['code_context']:
                        ctx = issue['code_context']
                        md_lines.append("```go")
                        # æ˜¾ç¤ºä¸Šä¸‹æ–‡
                        for i, line in enumerate(ctx['before'], start=ctx['start_line']):
                            md_lines.append(f"{i:4d} | {line}")
                        # é—®é¢˜è¡Œï¼ˆæ ‡è®°ï¼‰
                        md_lines.append(f"{ctx['problem_line']:4d} | {ctx['line']}  // âš ï¸ é—®é¢˜ä½ç½®")
                        for i, line in enumerate(ctx['after'], start=ctx['problem_line'] + 1):
                            md_lines.append(f"{i:4d} | {line}")
                        md_lines.append("```")
                        md_lines.append("")
                    
                    md_lines.append("---")
                    md_lines.append("")
            
            md_lines.append("")
    
    md_lines.append("## âœ… ä¿®å¤å»ºè®®")
    md_lines.append("")
    md_lines.append("1. **æŒ‰æ–‡ä»¶ä¿®å¤**: ä¼˜å…ˆä¿®å¤é—®é¢˜æ•°é‡å¤šçš„æ–‡ä»¶ï¼Œä¸€æ¬¡ä¿®å¤æ–‡ä»¶ä¸­çš„æ‰€æœ‰é—®é¢˜")
    md_lines.append("2. **æŒ‰ä¼˜å…ˆçº§ä¿®å¤**: å…ˆä¿®å¤é«˜ä¼˜å…ˆçº§é—®é¢˜ï¼ˆerrcheck, gosec, bodycloseï¼‰")
    md_lines.append("3. **ä½¿ç”¨ä»£ç ä¸Šä¸‹æ–‡**: å³ä½¿è¡Œå·å˜åŒ–ï¼Œä¹Ÿèƒ½é€šè¿‡ä»£ç ç‰‡æ®µå‡†ç¡®å®šä½é—®é¢˜")
    md_lines.append("4. **éªŒè¯ä¿®å¤**: ä¿®å¤åè¿è¡Œ `make lint-verify FILE=path/to/file.go` éªŒè¯")
    md_lines.append("")
    
    with open(report_md_file, 'w', encoding='utf-8') as f:
        f.write('\n'.join(md_lines))
    
    print(f"âœ… Markdown æŠ¥å‘Šå·²ç”Ÿæˆ: {report_md_file}")
    
    # æ˜¾ç¤ºæ–‡ä»¶ç»Ÿè®¡ï¼ˆå¸¦å¯è§†åŒ–ï¼‰
    print("")
    print("ğŸ“ é—®é¢˜æœ€å¤šçš„å‰10ä¸ªæ–‡ä»¶:")
    print("=" * 80)
    file_counts = [(file_path, len(issues)) for file_path, issues in issues_by_file.items()]
    file_counts.sort(key=lambda x: x[1], reverse=True)
    
    if file_counts:
        max_count = file_counts[0][1]
        for rank, (file_path, count) in enumerate(file_counts[:10], 1):
            # ç”Ÿæˆè¿›åº¦æ¡
            bar_length = int((count / max_count) * 50) if max_count > 0 else 0
            bar = "â–ˆ" * bar_length + "â–‘" * (50 - bar_length)
            percentage = (count / total * 100) if total > 0 else 0
            print(f"  {rank:2d}. {count:4d} ä¸ª ({percentage:5.1f}%) {bar} {file_path}")
    else:
        print("  (æ— )")
    print("=" * 80)
    
    # æ˜¾ç¤ºæ£€æŸ¥å™¨ç»Ÿè®¡ï¼ˆå¯è§†åŒ–ï¼‰
    print("")
    print("ğŸ” æŒ‰æ£€æŸ¥å™¨ç»Ÿè®¡ï¼ˆå‰10ä¸ªï¼‰:")
    print("=" * 80)
    sorted_linters = sorted(linter_counts.items(), key=lambda x: x[1], reverse=True)
    max_linter_count = sorted_linters[0][1] if sorted_linters else 1
    
    for rank, (linter, count) in enumerate(sorted_linters[:10], 1):
        _, priority_name = get_priority(linter)
        percentage = (count / total * 100) if total > 0 else 0
        bar_length = int((count / max_linter_count) * 50) if max_linter_count > 0 else 0
        bar = "â–ˆ" * bar_length + "â–‘" * (50 - bar_length)
        print(f"  {rank:2d}. {linter:15s} {count:4d} ä¸ª ({percentage:5.1f}%) [{priority_name:2s}] {bar}")
    print("=" * 80)

except Exception as e:
    print(f"âŒ é”™è¯¯: {e}")
    import traceback
    traceback.print_exc()
    exit(1)
PYTHON_SCRIPT

echo ""
echo "âœ… å®Œæˆï¼"
echo ""
echo "ğŸ“ æŠ¥å‘Šæ–‡ä»¶:"
echo "   - JSON æ ¼å¼: $REPORT_JSON"
echo "   - Markdown æ ¼å¼: $REPORT_MD"
echo ""
echo "ğŸ’¡ ä½¿ç”¨å»ºè®®:"
echo "   1. æŸ¥çœ‹ Markdown æŠ¥å‘Š: cat $REPORT_MD"
echo "   2. æŒ‰æ–‡ä»¶ä¿®å¤é—®é¢˜ï¼ˆæŠ¥å‘Šå·²æŒ‰æ–‡ä»¶åˆ†ç»„ï¼‰"
echo "   3. ä½¿ç”¨ä»£ç ä¸Šä¸‹æ–‡ç²¾ç¡®å®šä½é—®é¢˜ï¼ˆå³ä½¿è¡Œå·å˜åŒ–ï¼‰"

