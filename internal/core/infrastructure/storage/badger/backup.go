package badger

import (
	"bufio"
	"context"
	"crypto/sha256"
	"encoding/hex"
	"encoding/json"
	"fmt"
	"io"
	"os"
	"path/filepath"
	"runtime"
	"runtime/debug"
	"sort"
	"strconv"
	"strings"
	"sync"
	"time"

	badgerdb "github.com/dgraph-io/badger/v3"
	"github.com/weisyn/v1/pkg/interfaces/infrastructure/log"
	
	"github.com/weisyn/v1/internal/core/diagnostics"
)

// BackupStatus å¤‡ä»½çŠ¶æ€
type BackupStatus string

const (
	// BackupStatusCompleted è¡¨ç¤ºå¤‡ä»½å·²æˆåŠŸå®Œæˆ
	BackupStatusCompleted BackupStatus = "completed"
	// BackupStatusFailed è¡¨ç¤ºå¤‡ä»½å¤±è´¥
	BackupStatusFailed BackupStatus = "failed"
	// BackupStatusVerified è¡¨ç¤ºå¤‡ä»½å·²éªŒè¯
	BackupStatusVerified BackupStatus = "verified"
)

// BackupType å¤‡ä»½ç±»å‹
type BackupType string

const (
	// BackupTypeAutomatic è¡¨ç¤ºè‡ªåŠ¨å¤‡ä»½
	BackupTypeAutomatic BackupType = "automatic"
	// BackupTypeManual è¡¨ç¤ºæ‰‹åŠ¨å¤‡ä»½
	BackupTypeManual BackupType = "manual"
	// BackupTypePreUpdate è¡¨ç¤ºæ›´æ–°å‰å¤‡ä»½
	BackupTypePreUpdate BackupType = "pre_update"
)

// BackupMetadata å¤‡ä»½å…ƒæ•°æ®
// åŒ…å«å¤‡ä»½çš„å…³é”®ä¿¡æ¯ï¼Œç”¨äºéªŒè¯å’Œæ¢å¤
type BackupMetadata struct {
	Timestamp     time.Time    `json:"timestamp"`      // å¤‡ä»½åˆ›å»ºæ—¶é—´
	Size          int64        `json:"size"`           // å¤‡ä»½æ–‡ä»¶å¤§å°
	KeyCount      int          `json:"key_count"`      // é”®çš„æ•°é‡
	DBVersion     string       `json:"db_version"`     // æ•°æ®åº“ç‰ˆæœ¬
	AppVersion    string       `json:"app_version"`    // åº”ç”¨ç¨‹åºç‰ˆæœ¬
	MachineName   string       `json:"machine_name"`   // æœºå™¨åç§°
	BackupReason  string       `json:"backup_reason"`  // å¤‡ä»½åŸå› 
	BackupType    BackupType   `json:"backup_type"`    // å¤‡ä»½ç±»å‹
	Status        BackupStatus `json:"status"`         // å¤‡ä»½çŠ¶æ€
	Hash          string       `json:"hash,omitempty"` // å¤‡ä»½æ–‡ä»¶çš„å“ˆå¸Œå€¼(å¯é€‰)
	FormatVersion int          `json:"format_version"` // å¤‡ä»½æ ¼å¼ç‰ˆæœ¬
}

// backupManager ç®¡ç†å¤‡ä»½æ“ä½œ
type backupManager struct {
	store     *Store
	backupDir string
	mutex     sync.Mutex
	logger    log.Logger
}

// newBackupManager åˆ›å»ºæ–°çš„å¤‡ä»½ç®¡ç†å™¨
func newBackupManager(store *Store, backupDir string) *backupManager {
	return &backupManager{
		store:     store,
		backupDir: backupDir,
		logger:    store.logger,
	}
}

// CreateBackup åˆ›å»ºæ•°æ®åº“å¤‡ä»½
// å°†æ•°æ®åº“å†…å®¹ä¿å­˜åˆ°æŒ‡å®šè·¯å¾„ï¼Œå¹¶åˆ›å»ºå…ƒæ•°æ®æ–‡ä»¶
func (s *Store) CreateBackup(ctx context.Context, destPath string) error {
	s.logger.Infof("åˆ›å»ºå¤‡ä»½åˆ°: %s", destPath)

	// ç¡®ä¿å¤‡ä»½ç›®å½•å­˜åœ¨
	backupDir := filepath.Dir(destPath)
	if err := os.MkdirAll(backupDir, 0700); err != nil {
		return fmt.Errorf("åˆ›å»ºå¤‡ä»½ç›®å½•å¤±è´¥: %w", err)
	}

	// åˆ›å»ºä¸´æ—¶å¤‡ä»½æ–‡ä»¶
	tempPath := destPath + ".tmp"
	backupFile, err := os.Create(tempPath)
	if err != nil {
		return fmt.Errorf("åˆ›å»ºä¸´æ—¶å¤‡ä»½æ–‡ä»¶å¤±è´¥: %w", err)
	}

	// å‡†å¤‡å…ƒæ•°æ®
	metadata := BackupMetadata{
		Timestamp:     time.Now(),
		DBVersion:     "3",             // BadgerDB v3ç‰ˆæœ¬
		AppVersion:    getAppVersion(), // ä»é…ç½®æˆ–ç¯å¢ƒè·å–
		MachineName:   getHostname(),
		BackupReason:  "å®šæœŸå¤‡ä»½",
		BackupType:    BackupTypeAutomatic,
		Status:        BackupStatusCompleted,
		FormatVersion: 1, // å½“å‰å¤‡ä»½æ ¼å¼ç‰ˆæœ¬
	}

	// è·å–æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯
	count := 0
	err = s.db.View(func(txn *badgerdb.Txn) error {
		opts := badgerdb.DefaultIteratorOptions
		opts.PrefetchValues = false
		it := txn.NewIterator(opts)
		defer it.Close() // Badger Iterator.Close() æ— è¿”å›å€¼

		for it.Rewind(); it.Valid(); it.Next() {
			count++
		}
		return nil
	})

	if err != nil {
		backupFile.Close()
		if removeErr := os.Remove(tempPath); removeErr != nil && !os.IsNotExist(removeErr) {
			s.logger.Warnf("åˆ é™¤ä¸´æ—¶å¤‡ä»½æ–‡ä»¶å¤±è´¥: %v", removeErr)
		}
		s.logger.Warnf("è·å–é”®æ•°é‡å¤±è´¥: %v", err)
		return fmt.Errorf("è·å–é”®æ•°é‡å¤±è´¥: %w", err)
	}

	metadata.KeyCount = count

	// æ‰§è¡Œå¤‡ä»½
	s.logger.Info("å¼€å§‹æ‰§è¡Œæ•°æ®å¤‡ä»½...")
	startTime := time.Now()

	// ğŸ”§ ä¼˜åŒ–ï¼šä½¿ç”¨å¸¦ç¼“å†²çš„å†™å…¥ï¼Œå‡å°‘ç³»ç»Ÿè°ƒç”¨ï¼Œæå‡æ€§èƒ½
	bufferedWriter := bufio.NewWriterSize(backupFile, 2*1024*1024) // 2MBç¼“å†²åŒº
	_, err = s.db.Backup(bufferedWriter, 0)
	if err != nil {
		bufferedWriter.Flush()
		backupFile.Close()
		if removeErr := os.Remove(tempPath); removeErr != nil && !os.IsNotExist(removeErr) {
			s.logger.Warnf("åˆ é™¤ä¸´æ—¶å¤‡ä»½æ–‡ä»¶å¤±è´¥: %v", removeErr)
		}
		s.logger.Errorf("æ‰§è¡Œå¤‡ä»½å¤±è´¥: %v", err)
		return fmt.Errorf("æ‰§è¡Œå¤‡ä»½å¤±è´¥: %w", err)
	}

	// åˆ·æ–°ç¼“å†²åŒº
	if err := bufferedWriter.Flush(); err != nil {
		backupFile.Close()
		if removeErr := os.Remove(tempPath); removeErr != nil && !os.IsNotExist(removeErr) {
			s.logger.Warnf("åˆ é™¤ä¸´æ—¶å¤‡ä»½æ–‡ä»¶å¤±è´¥: %v", removeErr)
		}
		s.logger.Errorf("åˆ·æ–°å¤‡ä»½ç¼“å†²åŒºå¤±è´¥: %v", err)
		return fmt.Errorf("åˆ·æ–°å¤‡ä»½ç¼“å†²åŒºå¤±è´¥: %w", err)
	}

	backupDuration := time.Since(startTime)

	// å…³é—­æ–‡ä»¶ä»¥ç¡®ä¿å†™å…¥å®Œæˆ
	if err := backupFile.Close(); err != nil {
		if removeErr := os.Remove(tempPath); removeErr != nil && !os.IsNotExist(removeErr) {
			s.logger.Warnf("åˆ é™¤ä¸´æ—¶å¤‡ä»½æ–‡ä»¶å¤±è´¥: %v", removeErr)
		}
		s.logger.Errorf("å…³é—­å¤‡ä»½æ–‡ä»¶å¤±è´¥: %v", err)
		return fmt.Errorf("å…³é—­å¤‡ä»½æ–‡ä»¶å¤±è´¥: %w", err)
	}

	// ğŸ”§ ä¼˜åŒ–ï¼šå¤‡ä»½å®Œæˆåç«‹å³è§¦å‘GCå’Œå†…å­˜é‡Šæ”¾ï¼ŒåŠ é€Ÿå†…å­˜å›æ”¶
	s.logger.Info("å¤‡ä»½å®Œæˆï¼Œå¼€å§‹é‡Šæ”¾å†…å­˜...")

	// è®°å½•å¤‡ä»½å‰çš„å†…å­˜çŠ¶æ€
	var beforeGC runtime.MemStats
	runtime.ReadMemStats(&beforeGC)
	beforeRSS := getRSSBytesForBackup()

	// æ‰§è¡ŒGCå’Œå†…å­˜é‡Šæ”¾
	runtime.GC()
	runtime.GC()         // æ‰§è¡Œä¸¤æ¬¡GCç¡®ä¿å……åˆ†å›æ”¶
	debug.FreeOSMemory() // å°†å†…å­˜è¿”è¿˜ç»™æ“ä½œç³»ç»Ÿ

	// ç­‰å¾…GCå®Œæˆ
	time.Sleep(100 * time.Millisecond)

	// è®°å½•å¤‡ä»½åçš„å†…å­˜çŠ¶æ€
	var afterGC runtime.MemStats
	runtime.ReadMemStats(&afterGC)
	afterRSS := getRSSBytesForBackup()

	freedHeapMB := int64(beforeGC.HeapAlloc-afterGC.HeapAlloc) / 1024 / 1024
	freedRSSMB := int64(beforeRSS-afterRSS) / 1024 / 1024

	if freedHeapMB > 0 || freedRSSMB > 0 {
		s.logger.Infof("å¤‡ä»½åå†…å­˜é‡Šæ”¾: HeapAlloc %dMB â†’ %dMB (é‡Šæ”¾ %dMB), RSS %dMB â†’ %dMB (é‡Šæ”¾ %dMB)",
			beforeGC.HeapAlloc/1024/1024, afterGC.HeapAlloc/1024/1024, freedHeapMB,
			beforeRSS/1024/1024, afterRSS/1024/1024, freedRSSMB)
	} else {
		s.logger.Debugf("å¤‡ä»½åå†…å­˜çŠ¶æ€: HeapAlloc %dMB, RSS %dMB",
			afterGC.HeapAlloc/1024/1024, afterRSS/1024/1024)
	}

	// è®¡ç®—å¤‡ä»½æ–‡ä»¶å“ˆå¸Œ
	hash, err := calculateFileHash(tempPath)
	if err != nil {
		if removeErr := os.Remove(tempPath); removeErr != nil && !os.IsNotExist(removeErr) {
			s.logger.Warnf("åˆ é™¤ä¸´æ—¶å¤‡ä»½æ–‡ä»¶å¤±è´¥: %v", removeErr)
		}
		s.logger.Warnf("è®¡ç®—å¤‡ä»½æ–‡ä»¶å“ˆå¸Œå¤±è´¥: %v", err)
	} else {
		metadata.Hash = hash
	}

	// è·å–æ–‡ä»¶å¤§å°
	fileInfo, err := os.Stat(tempPath)
	if err != nil {
		if removeErr := os.Remove(tempPath); removeErr != nil && !os.IsNotExist(removeErr) {
			s.logger.Warnf("åˆ é™¤ä¸´æ—¶å¤‡ä»½æ–‡ä»¶å¤±è´¥: %v", removeErr)
		}
		s.logger.Errorf("è·å–å¤‡ä»½æ–‡ä»¶ä¿¡æ¯å¤±è´¥: %v", err)
		return fmt.Errorf("è·å–å¤‡ä»½æ–‡ä»¶ä¿¡æ¯å¤±è´¥: %w", err)
	}
	metadata.Size = fileInfo.Size()

	// éªŒè¯å¤‡ä»½æ–‡ä»¶
	if err := verifyBackupFile(tempPath); err != nil {
		if removeErr := os.Remove(tempPath); removeErr != nil && !os.IsNotExist(removeErr) {
			s.logger.Warnf("åˆ é™¤ä¸´æ—¶å¤‡ä»½æ–‡ä»¶å¤±è´¥: %v", removeErr)
		}
		s.logger.Errorf("å¤‡ä»½éªŒè¯å¤±è´¥: %v", err)
		return fmt.Errorf("å¤‡ä»½éªŒè¯å¤±è´¥: %w", err)
	}

	metadata.Status = BackupStatusVerified

	// é‡å‘½åä¸´æ—¶æ–‡ä»¶ä¸ºç›®æ ‡æ–‡ä»¶
	if err := os.Rename(tempPath, destPath); err != nil {
		if removeErr := os.Remove(tempPath); removeErr != nil && !os.IsNotExist(removeErr) {
			s.logger.Warnf("åˆ é™¤ä¸´æ—¶å¤‡ä»½æ–‡ä»¶å¤±è´¥: %v", removeErr)
		}
		s.logger.Errorf("é‡å‘½åå¤‡ä»½æ–‡ä»¶å¤±è´¥: %v", err)
		return fmt.Errorf("é‡å‘½åå¤‡ä»½æ–‡ä»¶å¤±è´¥: %w", err)
	}

	// ä¿å­˜å…ƒæ•°æ®åˆ°æ–‡ä»¶
	metadataPath := destPath + ".meta"
	metadataJSON, err := json.MarshalIndent(metadata, "", "  ")
	if err != nil {
		s.logger.Warnf("åºåˆ—åŒ–å¤‡ä»½å…ƒæ•°æ®å¤±è´¥: %v", err)
	} else {
		if err := os.WriteFile(metadataPath, metadataJSON, 0600); err != nil {
			s.logger.Warnf("å†™å…¥å¤‡ä»½å…ƒæ•°æ®å¤±è´¥: %v", err)
		}
	}

	s.logger.Infof("æ•°æ®åº“å¤‡ä»½æˆåŠŸ: %s (å¤§å°: %d å­—èŠ‚, é”®æ•°é‡: %d, è€—æ—¶: %v)",
		destPath, metadata.Size, metadata.KeyCount, backupDuration)
	return nil
}

// StartAutomaticBackups å¯åŠ¨è‡ªåŠ¨å¤‡ä»½
// æ ¹æ®æŒ‡å®šçš„æ—¶é—´é—´éš”å®šæœŸå¤‡ä»½æ•°æ®åº“ï¼Œå¹¶ä¿ç•™æŒ‡å®šæ•°é‡çš„å¤‡ä»½
func (s *Store) StartAutomaticBackups(ctx context.Context, backupDir string, interval time.Duration, keepCount int) {
	s.logger.Infof("å¯åŠ¨è‡ªåŠ¨å¤‡ä»½ä»»åŠ¡ï¼Œé—´éš”ï¼š%vï¼Œä¿ç•™æ•°é‡ï¼š%d", interval, keepCount)

	// ç¡®ä¿å¤‡ä»½ç›®å½•å­˜åœ¨
	if err := os.MkdirAll(backupDir, 0700); err != nil {
		s.logger.Errorf("åˆ›å»ºå¤‡ä»½ç›®å½•å¤±è´¥: %v", err)
		return
	}

	// åˆ›å»ºå¤‡ä»½ç®¡ç†å™¨
	manager := newBackupManager(s, backupDir)

	// å¯åŠ¨å®šæœŸå¤‡ä»½ä»»åŠ¡
	go func() {
		// é¦–æ¬¡å¤‡ä»½å»¶è¿Ÿ1åˆ†é’Ÿï¼Œé¿å…å¯åŠ¨æ—¶ç«‹å³æ‰§è¡Œ
		initialDelay := time.NewTimer(1 * time.Minute)

		select {
		case <-initialDelay.C:
			// æ‰§è¡Œé¦–æ¬¡å¤‡ä»½
			if err := manager.performBackup(BackupTypeAutomatic, "å¯åŠ¨åé¦–æ¬¡è‡ªåŠ¨å¤‡ä»½"); err != nil {
				s.logger.Errorf("é¦–æ¬¡è‡ªåŠ¨å¤‡ä»½å¤±è´¥: %v", err)
			}
		case <-ctx.Done():
			initialDelay.Stop()
			return
		}

		// è®¾ç½®å®šæœŸå¤‡ä»½
		ticker := time.NewTicker(interval)
		defer ticker.Stop()

		for {
			select {
			case <-ticker.C:
				if err := manager.performBackup(BackupTypeAutomatic, "å®šæœŸè‡ªåŠ¨å¤‡ä»½"); err != nil {
					s.logger.Errorf("è‡ªåŠ¨å¤‡ä»½å¤±è´¥: %v", err)
				}

				// æ¸…ç†æ—§å¤‡ä»½
				if err := manager.cleanOldBackups(keepCount); err != nil {
					s.logger.Errorf("æ¸…ç†æ—§å¤‡ä»½å¤±è´¥: %v", err)
				}

			case <-ctx.Done():
				return
			}
		}
	}()
}

// performBackup æ‰§è¡Œå¤‡ä»½æ“ä½œ
func (bm *backupManager) performBackup(backupType BackupType, reason string) error {
	bm.mutex.Lock()
	defer bm.mutex.Unlock()

	timestamp := time.Now().Format("20060102_150405")
	backupName := fmt.Sprintf("badger_backup_%s_%s.bak", timestamp, string(backupType))
	backupPath := filepath.Join(bm.backupDir, backupName)

	bm.logger.Infof("æ‰§è¡Œ%så¤‡ä»½: %s", backupType, backupPath)

	// åˆ›å»ºå¤‡ä»½
	return bm.store.CreateBackup(context.Background(), backupPath)
}

// cleanOldBackups æ¸…ç†æ—§å¤‡ä»½ï¼Œåªä¿ç•™æŒ‡å®šæ•°é‡çš„æœ€æ–°å¤‡ä»½
func (bm *backupManager) cleanOldBackups(keepCount int) error {
	bm.mutex.Lock()
	defer bm.mutex.Unlock()

	bm.logger.Infof("æ¸…ç†æ—§å¤‡ä»½ï¼Œä¿ç•™æœ€æ–°çš„%dä¸ªå¤‡ä»½", keepCount)

	// è·å–æ‰€æœ‰å¤‡ä»½æ–‡ä»¶
	backups, err := bm.listBackupFiles()
	if err != nil {
		return fmt.Errorf("åˆ—å‡ºå¤‡ä»½æ–‡ä»¶å¤±è´¥: %w", err)
	}

	// å¦‚æœå¤‡ä»½æ•°é‡ä¸è¶…è¿‡ä¿ç•™æ•°é‡ï¼Œä¸éœ€è¦æ¸…ç†
	if len(backups) <= keepCount {
		bm.logger.Infof("å½“å‰å¤‡ä»½æ•°é‡(%d)ä¸è¶…è¿‡ä¿ç•™æ•°é‡(%d)ï¼Œæ— éœ€æ¸…ç†", len(backups), keepCount)
		return nil
	}

	// éœ€è¦åˆ é™¤çš„å¤‡ä»½æ•°é‡
	deleteCount := len(backups) - keepCount
	bm.logger.Infof("å°†åˆ é™¤%dä¸ªæ—§å¤‡ä»½", deleteCount)

	// åˆ é™¤æ—§å¤‡ä»½
	for i := 0; i < deleteCount; i++ {
		backupPath := backups[i]
		metadataPath := backupPath + ".meta"

		// åˆ é™¤å¤‡ä»½æ–‡ä»¶
		if err := os.Remove(backupPath); err != nil && !os.IsNotExist(err) {
			bm.logger.Warnf("åˆ é™¤æ—§å¤‡ä»½æ–‡ä»¶å¤±è´¥: %s, %v", backupPath, err)
		}

		// åˆ é™¤å…ƒæ•°æ®æ–‡ä»¶
		if err := os.Remove(metadataPath); err != nil && !os.IsNotExist(err) {
			bm.logger.Warnf("åˆ é™¤æ—§å¤‡ä»½å…ƒæ•°æ®æ–‡ä»¶å¤±è´¥: %s, %v", metadataPath, err)
		}

		bm.logger.Infof("å·²åˆ é™¤æ—§å¤‡ä»½: %s", backupPath)
	}

	return nil
}

// listBackupFiles åˆ—å‡ºæ‰€æœ‰å¤‡ä»½æ–‡ä»¶ï¼ŒæŒ‰æ—¶é—´æˆ³æ’åºï¼ˆä»æ—§åˆ°æ–°ï¼‰
func (bm *backupManager) listBackupFiles() ([]string, error) {
	// è¯»å–å¤‡ä»½ç›®å½•
	files, err := os.ReadDir(bm.backupDir)
	if err != nil {
		return nil, fmt.Errorf("è¯»å–å¤‡ä»½ç›®å½•å¤±è´¥: %w", err)
	}

	// è¿‡æ»¤å‡ºå¤‡ä»½æ–‡ä»¶
	var backups []string
	for _, file := range files {
		if !file.IsDir() && strings.HasPrefix(file.Name(), "badger_backup_") &&
			strings.HasSuffix(file.Name(), ".bak") {
			backups = append(backups, filepath.Join(bm.backupDir, file.Name()))
		}
	}

	// æŒ‰æ–‡ä»¶åæ’åºï¼ˆå«æ—¶é—´æˆ³ï¼Œæ‰€ä»¥è¿™å®é™…ä¸Šæ˜¯æŒ‰æ—¶é—´æ’åºï¼‰
	sort.Strings(backups)

	return backups, nil
}

// ListBackups åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„å¤‡ä»½
func (s *Store) ListBackups(backupDir string) ([]BackupMetadata, error) {
	s.logger.Infof("åˆ—å‡ºå¤‡ä»½ç›®å½•ä¸­çš„æ‰€æœ‰å¤‡ä»½: %s", backupDir)

	// åˆ›å»ºå¤‡ä»½ç®¡ç†å™¨
	manager := newBackupManager(s, backupDir)

	// è·å–æ‰€æœ‰å¤‡ä»½æ–‡ä»¶
	backupFiles, err := manager.listBackupFiles()
	if err != nil {
		return nil, fmt.Errorf("è·å–å¤‡ä»½æ–‡ä»¶åˆ—è¡¨å¤±è´¥: %w", err)
	}

	// è¯»å–å…ƒæ•°æ®
	var backups []BackupMetadata
	for _, backupFile := range backupFiles {
		metadataPath := backupFile + ".meta"

		// æ£€æŸ¥å…ƒæ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
		if _, err := os.Stat(metadataPath); os.IsNotExist(err) {
			// å…ƒæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°è¯•åˆ›å»ºä¸€ä¸ªåŸºæœ¬çš„å…ƒæ•°æ®
			fileInfo, err := os.Stat(backupFile)
			if err != nil {
				s.logger.Warnf("æ— æ³•è·å–å¤‡ä»½æ–‡ä»¶ä¿¡æ¯: %s, %v", backupFile, err)
				continue
			}

			// ä»æ–‡ä»¶åä¸­æå–æ—¶é—´æˆ³
			fileName := filepath.Base(backupFile)
			timestamp, backupType := extractBackupInfo(fileName)

			metadata := BackupMetadata{
				Timestamp:     timestamp,
				Size:          fileInfo.Size(),
				BackupType:    backupType,
				Status:        BackupStatusCompleted,
				FormatVersion: 1,
			}

			backups = append(backups, metadata)
		} else {
			// è¯»å–å…ƒæ•°æ®æ–‡ä»¶
			data, err := os.ReadFile(metadataPath)
			if err != nil {
				s.logger.Warnf("è¯»å–å¤‡ä»½å…ƒæ•°æ®å¤±è´¥: %s, %v", metadataPath, err)
				continue
			}

			var metadata BackupMetadata
			if err := json.Unmarshal(data, &metadata); err != nil {
				s.logger.Warnf("è§£æå¤‡ä»½å…ƒæ•°æ®å¤±è´¥: %s, %v", metadataPath, err)
				continue
			}

			backups = append(backups, metadata)
		}
	}

	// æŒ‰æ—¶é—´æˆ³æ’åºï¼Œæœ€æ–°çš„åœ¨å‰
	sort.Slice(backups, func(i, j int) bool {
		return backups[i].Timestamp.After(backups[j].Timestamp)
	})

	return backups, nil
}

// CreateManualBackup åˆ›å»ºæ‰‹åŠ¨å¤‡ä»½
func (s *Store) CreateManualBackup(ctx context.Context, backupDir, reason string) (string, error) {
	s.logger.Infof("åˆ›å»ºæ‰‹åŠ¨å¤‡ä»½ï¼ŒåŸå› : %s", reason)

	// ç¡®ä¿å¤‡ä»½ç›®å½•å­˜åœ¨
	if err := os.MkdirAll(backupDir, 0700); err != nil {
		return "", fmt.Errorf("åˆ›å»ºå¤‡ä»½ç›®å½•å¤±è´¥: %w", err)
	}

	// è®¾ç½®å¤‡ä»½åç§°
	timestamp := time.Now().Format("20060102_150405")
	backupName := fmt.Sprintf("badger_backup_%s_manual.bak", timestamp)
	backupPath := filepath.Join(backupDir, backupName)

	// åˆ›å»ºå¤‡ä»½
	if err := s.CreateBackup(ctx, backupPath); err != nil {
		return "", fmt.Errorf("åˆ›å»ºæ‰‹åŠ¨å¤‡ä»½å¤±è´¥: %w", err)
	}

	// æ›´æ–°å…ƒæ•°æ®
	metadataPath := backupPath + ".meta"
	if _, err := os.Stat(metadataPath); err == nil {
		data, err := os.ReadFile(metadataPath)
		if err == nil {
			var metadata BackupMetadata
			if err := json.Unmarshal(data, &metadata); err == nil {
				metadata.BackupType = BackupTypeManual
				metadata.BackupReason = reason

				// å†™å›æ›´æ–°åçš„å…ƒæ•°æ®
				if updatedData, err := json.MarshalIndent(metadata, "", "  "); err == nil {
					if err := os.WriteFile(metadataPath, updatedData, 0600); err != nil {
						s.logger.Warnf("æ›´æ–°å¤‡ä»½å…ƒæ•°æ®å¤±è´¥: %v", err)
					}
				} else {
					s.logger.Warnf("åºåˆ—åŒ–å¤‡ä»½å…ƒæ•°æ®å¤±è´¥: %v", err)
				}
			} else {
				s.logger.Warnf("è§£æå¤‡ä»½å…ƒæ•°æ®å¤±è´¥: %v", err)
			}
		} else {
			s.logger.Warnf("è¯»å–å¤‡ä»½å…ƒæ•°æ®å¤±è´¥: %v", err)
		}
	}

	return backupPath, nil
}

// getAppVersion è·å–åº”ç”¨ç¨‹åºç‰ˆæœ¬
func getAppVersion() string {
	// è¿™é‡Œåº”è¯¥ä»åº”ç”¨é…ç½®æˆ–ç¯å¢ƒå˜é‡ä¸­è·å–å®é™…ç‰ˆæœ¬
	return "1.0.0"
}

// getHostname è·å–ä¸»æœºå
func getHostname() string {
	hostname, err := os.Hostname()
	if err != nil {
		return "unknown"
	}
	return hostname
}

// calculateFileHash è®¡ç®—æ–‡ä»¶çš„SHA256å“ˆå¸Œå€¼
func calculateFileHash(filePath string) (string, error) {
	file, err := os.Open(filePath)
	if err != nil {
		return "", fmt.Errorf("æ‰“å¼€æ–‡ä»¶å¤±è´¥: %w", err)
	}
	defer file.Close() // æ–‡ä»¶å…³é—­é”™è¯¯é€šå¸¸å¯ä»¥å¿½ç•¥

	hasher := sha256.New()
	if _, err := io.Copy(hasher, file); err != nil {
		return "", fmt.Errorf("è®¡ç®—å“ˆå¸Œå¤±è´¥: %w", err)
	}

	return hex.EncodeToString(hasher.Sum(nil)), nil
}

// verifyBackupFile éªŒè¯å¤‡ä»½æ–‡ä»¶æ ¼å¼
func verifyBackupFile(filePath string) error {
	file, err := os.Open(filePath)
	if err != nil {
		return fmt.Errorf("æ‰“å¼€å¤‡ä»½æ–‡ä»¶å¤±è´¥: %w", err)
	}
	defer file.Close() // æ–‡ä»¶å…³é—­é”™è¯¯é€šå¸¸å¯ä»¥å¿½ç•¥

	// è·å–æ–‡ä»¶ä¿¡æ¯ - ç¡®ä¿æ–‡ä»¶å­˜åœ¨å¹¶å¯è®¿é—®
	_, err = file.Stat()
	if err != nil {
		return fmt.Errorf("è·å–æ–‡ä»¶ä¿¡æ¯å¤±è´¥: %w", err)
	}

	// ç©ºæ•°æ®åº“å¤‡ä»½ä¹Ÿæ˜¯åˆæ³•çš„ï¼Œåªæ£€æŸ¥æ–‡ä»¶å¯è¯»æ€§
	// ä¸å†æ£€æŸ¥æ–‡ä»¶å¤§å°æ˜¯å¦ä¸º0

	// è¯»å–æ–‡ä»¶å¤´éƒ¨åªæ˜¯ä¸ºäº†éªŒè¯æ–‡ä»¶å¯è¯»æ€§
	header := make([]byte, 4)
	_, err = file.Read(header)
	if err != nil && err != io.EOF {
		return fmt.Errorf("è¯»å–å¤‡ä»½æ–‡ä»¶å¤´å¤±è´¥: %w", err)
	}

	return nil
}

// extractBackupInfo ä»å¤‡ä»½æ–‡ä»¶åä¸­æå–ä¿¡æ¯
func extractBackupInfo(fileName string) (time.Time, BackupType) {
	// é»˜è®¤å€¼
	defaultTime := time.Now()
	defaultType := BackupTypeAutomatic

	// å°è¯•ä»æ–‡ä»¶åä¸­æå–æ—¶é—´æˆ³
	parts := strings.Split(fileName, "_")
	if len(parts) >= 3 {
		// æ ¼å¼ï¼šbadger_backup_YYYYMMDD_HHMMSS_type.bak
		dateStr := parts[2]
		timeStr := parts[3]

		// å°è¯•è§£ææ—¶é—´æˆ³
		if len(dateStr) == 8 && len(timeStr) >= 6 {
			year, _ := strconv.Atoi(dateStr[0:4])
			month, _ := strconv.Atoi(dateStr[4:6])
			day, _ := strconv.Atoi(dateStr[6:8])

			hour, _ := strconv.Atoi(timeStr[0:2])
			minute, _ := strconv.Atoi(timeStr[2:4])
			second, _ := strconv.Atoi(timeStr[4:6])

			if year > 0 && month > 0 && day > 0 {
				parsedTime := time.Date(year, time.Month(month), day, hour, minute, second, 0, time.Local)
				defaultTime = parsedTime
			}
		}

		// å°è¯•è§£æå¤‡ä»½ç±»å‹
		if len(parts) >= 5 {
			typeStr := strings.Split(parts[4], ".")[0]
			switch typeStr {
			case "manual":
				defaultType = BackupTypeManual
			case "pre_update":
				defaultType = BackupTypePreUpdate
			}
		}

		// ç‰¹æ®Šå¤„ç† - æ£€æŸ¥æ–‡ä»¶åä¸­æ˜¯å¦åŒ…å«"pre_update"å­—ç¬¦ä¸²
		fileNameLower := strings.ToLower(fileName)
		if strings.Contains(fileNameLower, "pre_update") {
			defaultType = BackupTypePreUpdate
		}
	}

	return defaultTime, defaultType
}

// getRSSBytesForBackup è·å–è¿›ç¨‹ RSSï¼ˆResident Set Sizeï¼‰å­—èŠ‚æ•°
// ç”¨äºå¤‡ä»½åçš„å†…å­˜ç›‘æ§
//
// âœ… ä¿®å¤ï¼šä½¿ç”¨ diagnostics.GetRSSBytes() è·å–å½“å‰ RSSï¼ˆè€Œä¸æ˜¯å³°å€¼ï¼‰
// åœ¨ macOS ä¸Šï¼Œè¯¥å‡½æ•°ä¼šä½¿ç”¨å¯å‘å¼ä¼°ç®—æ–¹æ³•ï¼Œè¿”å›æ›´æ¥è¿‘å®é™…å½“å‰ RSS çš„å€¼
func getRSSBytesForBackup() uint64 {
	// ä½¿ç”¨ diagnostics åŒ…ä¸­çš„ GetRSSBytes() å‡½æ•°
	// è¯¥å‡½æ•°åœ¨ macOS ä¸Šä¼šä½¿ç”¨å¯å‘å¼ä¼°ç®—ï¼Œè¿”å›æ›´å‡†ç¡®çš„å½“å‰ RSS
	return diagnostics.GetRSSBytes()
}
