# PoWè®¡ç®—å¤„ç†å™¨ï¼ˆPoW Compute Handlerï¼‰

ã€æ¨¡å—å®šä½ã€‘
ã€€ã€€æœ¬æ¨¡å—æ˜¯WESçŸ¿å·¥ç³»ç»Ÿçš„æ ¸å¿ƒPoWè®¡ç®—å¼•æ“ï¼Œè´Ÿè´£æ‰§è¡Œå·¥ä½œé‡è¯æ˜ç®—æ³•çš„è®¡ç®—å’ŒéªŒè¯ã€‚åœ¨PoW+ABSæ··åˆå…±è¯†æœºåˆ¶ä¸‹ï¼ŒPoWå¤„ç†å™¨ä¿æŒä¼ ç»ŸPoWçš„å®‰å…¨æ€§å’Œå»ä¸­å¿ƒåŒ–ç‰¹æ€§ï¼Œæä¾›é«˜æ•ˆçš„nonceè®¡ç®—ã€åŒºå—å¤´æŒ–çŸ¿å’ŒPoWéªŒè¯åŠŸèƒ½ï¼Œç¡®ä¿çŸ¿å·¥èƒ½å¤Ÿäº§ç”Ÿç¬¦åˆéš¾åº¦è¦æ±‚çš„æœ‰æ•ˆåŒºå—ã€‚

ã€è®¾è®¡åŸåˆ™ã€‘
- **ä¼ ç»ŸPoWå…¼å®¹**ï¼šå®Œå…¨å…¼å®¹ä¼ ç»ŸBitcoin-style PoWç®—æ³•ï¼Œä¿æŒå®‰å…¨æ€§
- **é«˜æ€§èƒ½è®¡ç®—**ï¼šä¼˜åŒ–ç®—æ³•å®ç°ï¼Œæä¾›é«˜æ•ˆçš„PoWè®¡ç®—æ€§èƒ½
- **å¯é…ç½®éš¾åº¦**ï¼šæ”¯æŒåŠ¨æ€éš¾åº¦è°ƒæ•´ï¼Œé€‚åº”ç½‘ç»œç®—åŠ›å˜åŒ–
- **å¤šçº¿ç¨‹å¹¶è¡Œ**ï¼šæ”¯æŒå¤šçº¿ç¨‹å¹¶è¡Œè®¡ç®—ï¼Œå……åˆ†åˆ©ç”¨CPUèµ„æº
- **ä¸­æ–­å¯æ§**ï¼šæ”¯æŒè®¡ç®—è¿‡ç¨‹çš„ä¼˜é›…ä¸­æ–­å’Œå–æ¶ˆæœºåˆ¶
- **éªŒè¯é«˜æ•ˆ**ï¼šæä¾›å¿«é€Ÿçš„PoWç»“æœéªŒè¯åŠŸèƒ½

ã€æ ¸å¿ƒèŒè´£ã€‘
1. **åŒºå—å¤´æŒ–çŸ¿**ï¼šå¯¹ç»™å®šåŒºå—å¤´è¿›è¡Œè½»é‡çº§PoWè®¡ç®—ï¼Œå¯»æ‰¾æ»¡è¶³å›ºå®šéš¾åº¦è¦æ±‚çš„nonce
2. **PoWéªŒè¯**ï¼šéªŒè¯åŒºå—å¤´çš„PoWæ˜¯å¦æ»¡è¶³æŒ‡å®šçš„å›ºå®šéš¾åº¦è¦æ±‚
3. **å“ˆå¸ŒæœåŠ¡é›†æˆ**ï¼šä½¿ç”¨fxä¾èµ–æ³¨å…¥çš„pb/blockchain/block/block_grpc.pb.goå“ˆå¸ŒæœåŠ¡
4. **PoWå¼•æ“ç®¡ç†**ï¼šç®¡ç†PoWè®¡ç®—å¼•æ“çš„å¯åŠ¨å’Œåœæ­¢ç”Ÿå‘½å‘¨æœŸ
5. **ä¸­æ–­æ§åˆ¶**ï¼šæ”¯æŒPoWè®¡ç®—è¿‡ç¨‹çš„ä¼˜é›…ä¸­æ–­å’Œå–æ¶ˆæ“ä½œ

## ğŸ“ **æ¨¡å—ç»„ç»‡æ¶æ„**

```text
pow_handler/
â”œâ”€â”€ ğŸ“– README.md              # æœ¬æ–‡æ¡£ï¼šPoWè®¡ç®—å¤„ç†å™¨è®¾è®¡è¯´æ˜
â”œâ”€â”€ âš¡ manager.go             # è–„å®ç°ï¼šä»…å®ç°æ¥å£æ–¹æ³•ï¼Œå§”æ‰˜ç»™å…·ä½“æ–¹æ³•æ–‡ä»¶
â”œâ”€â”€ â›ï¸ mine_block_header.go    # MineBlockHeader æ–¹æ³•å…·ä½“å®ç°
â”œâ”€â”€ âœ… verify_block_header.go  # VerifyBlockHeader æ–¹æ³•å…·ä½“å®ç°  
â”œâ”€â”€ ğŸ§® produce_block.go        # ProduceBlockFromTemplate æ–¹æ³•å…·ä½“å®ç°
â”œâ”€â”€ ğŸš€ start_engine.go         # StartPoWEngine æ–¹æ³•å…·ä½“å®ç°
â””â”€â”€ â¹ï¸ stop_engine.go          # StopPoWEngine æ–¹æ³•å…·ä½“å®ç°
```

> **æ³¨æ„**: æ­¤ç»“æ„ä¸¥æ ¼éµå¾ª `REFACTORING_ANALYSIS.md` ä¸­çš„æƒå¨è®¾è®¡ã€‚ç§»é™¤äº†ï¼š
> - `hash_computer.go`ï¼šä½¿ç”¨fxä¾èµ–æ³¨å…¥çš„pb/blockchain/block/block_grpc.pb.goå“ˆå¸ŒæœåŠ¡
> - `difficulty_manager.go`ï¼šé‡‡ç”¨ç®€å•å›ºå®šéš¾åº¦å€¼ï¼ˆå¦‚20ï¼‰
> - `parallel_miner.go`ï¼šç§»é™¤å¤šçº¿ç¨‹å¹¶è¡Œè®¡ç®—ï¼Œé‡‡ç”¨è½»é‡çº§å•çº¿ç¨‹PoW
> - `performance_monitor.go`ï¼šåŒºå—é“¾è‡ªè¿è¡Œç³»ç»Ÿä¸éœ€è¦æ€§èƒ½ç›‘æ§

## ğŸ—ï¸ **PoWå¤„ç†å™¨æ¶æ„è®¾è®¡**

### **PoWè®¡ç®—æµç¨‹æ¶æ„**

```mermaid
graph TB
    subgraph "PoWè®¡ç®—å¤„ç†å™¨ï¼ˆPoWHandlerï¼‰"
        subgraph "æŒ–çŸ¿è®¡ç®—æµç¨‹"
            MINE_HEADER[MineBlockHeader<br/>æŒ–çŸ¿åŒºå—å¤´] --> PARSE_TARGET[è§£æç›®æ ‡éš¾åº¦]
            PARSE_TARGET --> INIT_PARALLEL[åˆå§‹åŒ–å¹¶è¡Œè®¡ç®—]
            INIT_PARALLEL --> START_WORKERS[å¯åŠ¨å·¥ä½œçº¿ç¨‹]
            START_WORKERS --> COMPUTE_LOOP[PoWè®¡ç®—å¾ªç¯]
            COMPUTE_LOOP --> CHECK_SOLUTION[æ£€æŸ¥è§£ç­”]
            CHECK_SOLUTION -->|æ‰¾åˆ°æœ‰æ•ˆnonce| RETURN_RESULT[è¿”å›è®¡ç®—ç»“æœ]
            CHECK_SOLUTION -->|ç»§ç»­è®¡ç®—| COMPUTE_LOOP
        end
        
        subgraph "éªŒè¯å¤„ç†æµç¨‹"
            VERIFY_HEADER[VerifyBlockHeader<br/>éªŒè¯åŒºå—å¤´] --> EXTRACT_NONCE[æå–nonceå€¼]
            EXTRACT_NONCE --> COMPUTE_HASH[è®¡ç®—åŒºå—å“ˆå¸Œ]
            COMPUTE_HASH --> CHECK_DIFFICULTY[æ£€æŸ¥éš¾åº¦è¦æ±‚]
            CHECK_DIFFICULTY --> RETURN_VERIFY[è¿”å›éªŒè¯ç»“æœ]
        end
        
        subgraph "æ€§èƒ½ç›‘æ§æµç¨‹"
            MONITOR[PerformanceMonitor<br/>æ€§èƒ½ç›‘æ§] --> COLLECT_METRICS[æ”¶é›†æ€§èƒ½æŒ‡æ ‡]
            COLLECT_METRICS --> CALCULATE_HASHRATE[è®¡ç®—ç®—åŠ›]
            CALCULATE_HASHRATE --> UPDATE_STATS[æ›´æ–°ç»Ÿè®¡ä¿¡æ¯]
        end
    end
    
    subgraph "åº•å±‚ä¾èµ–"
        HASH_ENGINE[HashEngine<br/>å“ˆå¸Œå¼•æ“]
        DIFFICULTY_CALC[DifficultyCalculator<br/>éš¾åº¦è®¡ç®—å™¨]
        THREAD_POOL[ThreadPool<br/>çº¿ç¨‹æ± ]
        CRYPTO_LIB[CryptoLibrary<br/>å¯†ç å­¦åº“]
    end
    
    %% PoWå¤„ç†å™¨ä¸åº•å±‚ç»„ä»¶çš„äº¤äº’
    COMPUTE_LOOP --> HASH_ENGINE
    COMPUTE_HASH --> HASH_ENGINE
    PARSE_TARGET --> DIFFICULTY_CALC
    CHECK_DIFFICULTY --> DIFFICULTY_CALC
    START_WORKERS --> THREAD_POOL
    COLLECT_METRICS --> THREAD_POOL
    
    style MINE_HEADER fill:#E8F5E8
    style VERIFY_HEADER fill:#E3F2FD
    style MONITOR fill:#FFF3E0
    style HASH_ENGINE fill:#F3E5F5
```

## ğŸ”§ **æ ¸å¿ƒæ¥å£å®ç°**

### **PoWComputeHandleræ¥å£å®šä¹‰**

```go
// interfaces/miner.go - PoWè®¡ç®—å¤„ç†å™¨æ¥å£
type PoWComputeHandler interface {
    // æŒ–çŸ¿åŒºå—å¤´ï¼Œå¯»æ‰¾æ»¡è¶³éš¾åº¦è¦æ±‚çš„nonce
    MineBlockHeader(ctx context.Context, candidateData []byte) (*block.Block, error)
    
    // éªŒè¯åŒºå—å¤´çš„PoWæ˜¯å¦æ»¡è¶³éš¾åº¦è¦æ±‚
    VerifyBlockHeader(blockHeader *block.Header, difficulty uint32) (bool, error)
    
    // è·å–å½“å‰ç®—åŠ›ç»Ÿè®¡
    GetHashrateStatistics() (*HashrateStats, error)
    
    // è®¾ç½®æŒ–çŸ¿çº¿ç¨‹æ•°
    SetMiningThreads(threadCount int) error
}
```

### **PoWç®¡ç†å™¨å®ç°**

```go
// pow_handler/manager.go - PoWç®¡ç†å™¨å®ç°

type Manager struct {
    // æ ¸å¿ƒç»„ä»¶
    hashEngine        interfaces.HashEngine           // å“ˆå¸Œè®¡ç®—å¼•æ“
    difficultyManager interfaces.DifficultyManager    // éš¾åº¦ç®¡ç†å™¨
    threadPool        interfaces.ThreadPool           // çº¿ç¨‹æ± ç®¡ç†
    perfMonitor       *PerformanceMonitor             // æ€§èƒ½ç›‘æ§
    logger            log.Logger                      // æ—¥å¿—è®°å½•å™¨
    
    // æŒ–çŸ¿é…ç½®
    miningThreads     int                             // æŒ–çŸ¿çº¿ç¨‹æ•°
    maxNonce          uint64                          // æœ€å¤§nonceå€¼
    batchSize         uint64                          // è®¡ç®—æ‰¹æ¬¡å¤§å°
    
    // è¿è¡ŒçŠ¶æ€
    isRunning         atomic.Bool                     // è¿è¡ŒçŠ¶æ€
    cancelChan        chan struct{}                   // å–æ¶ˆé€šé“
    statsMutex        sync.RWMutex                    // ç»Ÿè®¡é”
}

func NewManager(
    hashEngine interfaces.HashEngine,
    difficultyManager interfaces.DifficultyManager,
    threadPool interfaces.ThreadPool,
    logger log.Logger,
    config *PoWConfig,
) *Manager {
    return &Manager{
        hashEngine:        hashEngine,
        difficultyManager: difficultyManager,
        threadPool:        threadPool,
        logger:            logger,
        miningThreads:     config.MiningThreads,
        maxNonce:          config.MaxNonce,
        batchSize:         config.BatchSize,
        perfMonitor:       NewPerformanceMonitor(),
        cancelChan:        make(chan struct{}),
    }
}

// PoWé…ç½®ç»“æ„ä½“
type PoWConfig struct {
    MiningThreads    int    `json:"mining_threads"`
    MaxNonce        uint64 `json:"max_nonce"`
    BatchSize       uint64 `json:"batch_size"`
    HashAlgorithm   string `json:"hash_algorithm"`
    EnableProfiling bool   `json:"enable_profiling"`
}
```

## â›ï¸ **åŒºå—å¤´æŒ–çŸ¿å®ç°**

### **mine_block_header.go - PoWæŒ–çŸ¿æ ¸å¿ƒå®ç°**

```go
// pow_handler/mine_block_header.go - åŒºå—å¤´æŒ–çŸ¿å®ç°

func (m *Manager) MineBlockHeader(ctx context.Context, candidateData []byte) (*block.Block, error) {
    m.logger.Info("å¼€å§‹PoWæŒ–çŸ¿è®¡ç®—")
    
    // 1. è§£æå€™é€‰åŒºå—æ•°æ®
    candidateBlock, err := m.parseCandidateBlock(candidateData)
    if err != nil {
        return nil, fmt.Errorf("è§£æå€™é€‰åŒºå—å¤±è´¥: %v", err)
    }
    
    // 2. è®¡ç®—ç›®æ ‡éš¾åº¦å€¼
    target, err := m.calculateTarget(candidateBlock.Header.Difficulty)
    if err != nil {
        return nil, fmt.Errorf("è®¡ç®—ç›®æ ‡éš¾åº¦å¤±è´¥: %v", err)
    }
    
    // 3. åˆå§‹åŒ–æŒ–çŸ¿ç¯å¢ƒ
    miningCtx, cancel := context.WithCancel(ctx)
    defer cancel()
    
    // 4. å¯åŠ¨å¹¶è¡ŒæŒ–çŸ¿
    resultChan := make(chan *MiningResult, 1)
    m.startParallelMining(miningCtx, candidateBlock, target, resultChan)
    
    // 5. ç­‰å¾…æŒ–çŸ¿ç»“æœ
    select {
    case result := <-resultChan:
        if result.Success {
            m.logger.Info("PoWæŒ–çŸ¿æˆåŠŸ")
            return m.buildMinedBlock(candidateBlock, result.Nonce), nil
        }
        return nil, fmt.Errorf("PoWæŒ–çŸ¿å¤±è´¥: %s", result.Error)
        
    case <-ctx.Done():
        m.logger.Info("PoWæŒ–çŸ¿è¢«å–æ¶ˆ")
        return nil, ctx.Err()
    }
}

func (m *Manager) startParallelMining(ctx context.Context, candidateBlock *block.Block, target []byte, resultChan chan<- *MiningResult) {
    // è®¡ç®—æ¯ä¸ªçº¿ç¨‹çš„nonceèŒƒå›´
    nonceRangePerThread := m.maxNonce / uint64(m.miningThreads)
    
    // å¯åŠ¨æŒ–çŸ¿å·¥ä½œçº¿ç¨‹
    for i := 0; i < m.miningThreads; i++ {
        threadID := i
        startNonce := uint64(threadID) * nonceRangePerThread
        endNonce := startNonce + nonceRangePerThread
        
        go func() {
            m.mineInRange(ctx, candidateBlock, target, startNonce, endNonce, resultChan)
        }()
    }
}

func (m *Manager) mineInRange(ctx context.Context, candidateBlock *block.Block, target []byte, startNonce, endNonce uint64, resultChan chan<- *MiningResult) {
    // è·å–åŒºå—å¤´çš„å‰¯æœ¬è¿›è¡Œä¿®æ”¹
    header := candidateBlock.Header
    headerBytes := m.serializeHeaderForHashing(header)
    
    m.logger.Info("å¼€å§‹nonceèŒƒå›´æŒ–çŸ¿")
    
    // æŒ–çŸ¿å¾ªç¯
    for nonce := startNonce; nonce < endNonce; nonce++ {
        // æ£€æŸ¥å–æ¶ˆä¿¡å·
        select {
        case <-ctx.Done():
            return
        default:
        }
        
        // è®¡ç®—å½“å‰nonceçš„å“ˆå¸Œ
        hash := m.computeHashWithNonce(headerBytes, nonce)
        
        // æ£€æŸ¥æ˜¯å¦æ»¡è¶³éš¾åº¦è¦æ±‚
        if m.isHashValidForTarget(hash, target) {
            // æ‰¾åˆ°æœ‰æ•ˆè§£
            result := &MiningResult{
                Success:    true,
                Nonce:      nonce,
                Hash:       hash,
                ThreadID:   nonce / (m.maxNonce / uint64(m.miningThreads)),
                Attempts:   nonce - startNonce + 1,
            }
            
            select {
            case resultChan <- result:
                m.logger.Info("æ‰¾åˆ°æœ‰æ•ˆnonce")
                return
            default:
                // ç»“æœé€šé“å·²æ»¡ï¼Œå…¶ä»–çº¿ç¨‹å·²æ‰¾åˆ°è§£
                return
            }
        }
        
        // æ›´æ–°æ€§èƒ½ç»Ÿè®¡ï¼ˆæ‰¹é‡æ›´æ–°ï¼‰
        if nonce%m.batchSize == 0 {
            m.perfMonitor.UpdateHashCount(m.batchSize)
        }
    }
    
    // èŒƒå›´å†…æœªæ‰¾åˆ°æœ‰æ•ˆè§£
    m.logger.Info("nonceèŒƒå›´å†…æœªæ‰¾åˆ°æœ‰æ•ˆè§£")
}

func (m *Manager) computeHashWithNonce(headerBytes []byte, nonce uint64) []byte {
    // å°†nonceæ·»åŠ åˆ°åŒºå—å¤´å­—èŠ‚ä¸­
    headerWithNonce := append(headerBytes, m.uint64ToBytes(nonce)...)
    
    // è®¡ç®—SHA256å“ˆå¸Œ
    return m.hashEngine.DoubleSHA256(headerWithNonce)
}

func (m *Manager) isHashValidForTarget(hash []byte, target []byte) bool {
    // æ¯”è¾ƒå“ˆå¸Œå€¼æ˜¯å¦å°äºç›®æ ‡å€¼
    return bytes.Compare(hash, target) <= 0
}

// æŒ–çŸ¿ç»“æœç»“æ„ä½“
type MiningResult struct {
    Success   bool     `json:"success"`
    Nonce     uint64   `json:"nonce"`
    Hash      []byte   `json:"hash"`
    ThreadID  uint64   `json:"thread_id"`
    Attempts  uint64   `json:"attempts"`
    Error     string   `json:"error,omitempty"`
}
```

## âœ… **PoWéªŒè¯å®ç°**

### **verify_block_header.go - PoWéªŒè¯å®ç°**

```go
// pow_handler/verify_block_header.go - PoWéªŒè¯å®ç°

func (m *Manager) VerifyBlockHeader(blockHeader *block.Header, difficulty uint32) (bool, error) {
    m.logger.Info("å¼€å§‹éªŒè¯åŒºå—å¤´PoW")
    
    // 1. éªŒè¯è¾“å…¥å‚æ•°
    if blockHeader == nil {
        return false, fmt.Errorf("åŒºå—å¤´ä¸èƒ½ä¸ºç©º")
    }
    
    // 2. è®¡ç®—ç›®æ ‡éš¾åº¦å€¼
    target, err := m.calculateTarget(difficulty)
    if err != nil {
        return false, fmt.Errorf("è®¡ç®—ç›®æ ‡éš¾åº¦å¤±è´¥: %v", err)
    }
    
    // 3. åºåˆ—åŒ–åŒºå—å¤´ç”¨äºå“ˆå¸Œè®¡ç®—
    headerBytes := m.serializeHeaderForHashing(blockHeader)
    
    // 4. è®¡ç®—åŒºå—å¤´çš„å“ˆå¸Œå€¼
    hash := m.hashEngine.DoubleSHA256(headerBytes)
    
    // 5. éªŒè¯å“ˆå¸Œæ˜¯å¦æ»¡è¶³éš¾åº¦è¦æ±‚
    isValid := m.isHashValidForTarget(hash, target)
    
    // 6. è®°å½•éªŒè¯ç»“æœ
    if isValid {
        m.logger.Info("åŒºå—å¤´PoWéªŒè¯æˆåŠŸ")
        m.perfMonitor.RecordValidVerification()
    } else {
        m.logger.Info("åŒºå—å¤´PoWéªŒè¯å¤±è´¥")
        m.perfMonitor.RecordInvalidVerification()
    }
    
    return isValid, nil
}

func (m *Manager) serializeHeaderForHashing(header *block.Header) []byte {
    // åºåˆ—åŒ–åŒºå—å¤´çš„æ‰€æœ‰å­—æ®µï¼ˆé™¤äº†nonceï¼Œå®ƒå•ç‹¬å¤„ç†ï¼‰
    var buffer bytes.Buffer
    
    // æŒ‰ç…§ç‰¹å®šé¡ºåºåºåˆ—åŒ–å­—æ®µ
    buffer.Write(header.ParentHash[:])
    buffer.Write(header.MerkleRoot[:])
    buffer.Write(m.uint64ToBytes(header.Timestamp))
    buffer.Write(m.uint32ToBytes(header.Difficulty))
    buffer.Write(m.uint64ToBytes(header.Height))
    
    // æ·»åŠ å…¶ä»–å¿…è¦å­—æ®µ...
    
    return buffer.Bytes()
}

func (m *Manager) calculateTarget(difficulty uint32) ([]byte, error) {
    // ä½¿ç”¨éš¾åº¦ç®¡ç†å™¨è®¡ç®—ç›®æ ‡å€¼
    return m.difficultyManager.CalculateTarget(difficulty)
}

// æ‰¹é‡éªŒè¯æ¥å£
func (m *Manager) VerifyMultipleHeaders(headers []*block.Header, difficulty uint32) ([]bool, error) {
    m.logger.Info("å¼€å§‹æ‰¹é‡éªŒè¯åŒºå—å¤´PoW")
    
    if len(headers) == 0 {
        return nil, fmt.Errorf("åŒºå—å¤´åˆ—è¡¨ä¸èƒ½ä¸ºç©º")
    }
    
    results := make([]bool, len(headers))
    
    // è®¡ç®—ç›®æ ‡éš¾åº¦å€¼ï¼ˆåªéœ€è®¡ç®—ä¸€æ¬¡ï¼‰
    target, err := m.calculateTarget(difficulty)
    if err != nil {
        return nil, fmt.Errorf("è®¡ç®—ç›®æ ‡éš¾åº¦å¤±è´¥: %v", err)
    }
    
    // å¹¶è¡ŒéªŒè¯å¤šä¸ªåŒºå—å¤´
    var wg sync.WaitGroup
    for i, header := range headers {
        wg.Add(1)
        go func(index int, h *block.Header) {
            defer wg.Done()
            
            headerBytes := m.serializeHeaderForHashing(h)
            hash := m.hashEngine.DoubleSHA256(headerBytes)
            results[index] = m.isHashValidForTarget(hash, target)
        }(i, header)
    }
    
    wg.Wait()
    
    // ç»Ÿè®¡éªŒè¯ç»“æœ
    validCount := 0
    for _, valid := range results {
        if valid {
            validCount++
        }
    }
    
    m.logger.Info("æ‰¹é‡éªŒè¯å®Œæˆ")
    
    return results, nil
}
```

## ğŸ§® **é«˜æ•ˆå“ˆå¸Œè®¡ç®—**

### **hash_computer.go - å“ˆå¸Œè®¡ç®—ä¼˜åŒ–å®ç°**

```go
// pow_handler/hash_computer.go - å“ˆå¸Œè®¡ç®—å®ç°

type HashComputer struct {
    algorithm    string                 // å“ˆå¸Œç®—æ³•ç±»å‹
    hashPool     sync.Pool             // å“ˆå¸Œå¯¹è±¡æ± 
    bufferPool   sync.Pool             // ç¼“å†²åŒºå¯¹è±¡æ± 
    logger       log.Logger
}

func NewHashComputer(algorithm string, logger log.Logger) *HashComputer {
    hc := &HashComputer{
        algorithm: algorithm,
        logger:    logger,
    }
    
    // åˆå§‹åŒ–å¯¹è±¡æ± 
    hc.hashPool.New = func() interface{} {
        switch algorithm {
        case "SHA256":
            return sha256.New()
        case "Blake2b":
            h, _ := blake2b.New256(nil)
            return h
        default:
            return sha256.New()
        }
    }
    
    hc.bufferPool.New = func() interface{} {
        return make([]byte, 0, 1024) // é¢„åˆ†é…1KBç¼“å†²åŒº
    }
    
    return hc
}

func (hc *HashComputer) DoubleSHA256(data []byte) []byte {
    // ä»å¯¹è±¡æ± è·å–å“ˆå¸Œå¯¹è±¡
    hasher := hc.hashPool.Get().(hash.Hash)
    defer func() {
        hasher.Reset()
        hc.hashPool.Put(hasher)
    }()
    
    // ç¬¬ä¸€æ¬¡å“ˆå¸Œ
    hasher.Write(data)
    firstHash := hasher.Sum(nil)
    
    // é‡ç½®å“ˆå¸Œå¯¹è±¡
    hasher.Reset()
    
    // ç¬¬äºŒæ¬¡å“ˆå¸Œ
    hasher.Write(firstHash)
    return hasher.Sum(nil)
}

func (hc *HashComputer) ComputeHashBatch(dataList [][]byte) [][]byte {
    results := make([][]byte, len(dataList))
    
    // å¹¶è¡Œè®¡ç®—å¤šä¸ªå“ˆå¸Œ
    var wg sync.WaitGroup
    semaphore := make(chan struct{}, runtime.NumCPU()) // é™åˆ¶å¹¶å‘æ•°
    
    for i, data := range dataList {
        wg.Add(1)
        go func(index int, d []byte) {
            defer wg.Done()
            
            semaphore <- struct{}{} // è·å–ä¿¡å·é‡
            defer func() { <-semaphore }() // é‡Šæ”¾ä¿¡å·é‡
            
            results[index] = hc.DoubleSHA256(d)
        }(i, data)
    }
    
    wg.Wait()
    return results
}

// SIMDä¼˜åŒ–çš„å“ˆå¸Œè®¡ç®—ï¼ˆå¦‚æœCPUæ”¯æŒï¼‰
func (hc *HashComputer) ComputeHashSIMD(data []byte) []byte {
    // æ£€æŸ¥CPUæ˜¯å¦æ”¯æŒSIMDæŒ‡ä»¤
    if hc.supportsSIMD() {
        return hc.computeHashWithSIMD(data)
    }
    
    // å›é€€åˆ°æ ‡å‡†å®ç°
    return hc.DoubleSHA256(data)
}

func (hc *HashComputer) supportsSIMD() bool {
    // æ£€æŸ¥CPUç‰¹æ€§æ”¯æŒ
    return cpu.X86.HasAVX2 || cpu.ARM64.HasSHA2
}

func (hc *HashComputer) computeHashWithSIMD(data []byte) []byte {
    // SIMDä¼˜åŒ–çš„å“ˆå¸Œè®¡ç®—å®ç°
    // è¿™é‡Œå¯ä»¥é›†æˆä¸“é—¨çš„SIMDå“ˆå¸Œåº“
    return hc.DoubleSHA256(data) // é»˜è®¤å®ç°
}
```

## ğŸš€ **å¹¶è¡ŒæŒ–çŸ¿ä¼˜åŒ–**

### **parallel_miner.go - å¹¶è¡ŒæŒ–çŸ¿å®ç°**

```go
// pow_handler/parallel_miner.go - å¹¶è¡ŒæŒ–çŸ¿å®ç°

type ParallelMiner struct {
    threadCount    int
    workQueue      chan MiningWork
    resultChan     chan MiningResult
    workers        []*MiningWorker
    perfMonitor    *PerformanceMonitor
    logger         log.Logger
}

type MiningWork struct {
    WorkID      int
    HeaderBytes []byte
    Target      []byte
    StartNonce  uint64
    EndNonce    uint64
}

type MiningWorker struct {
    workerID    int
    workChan    <-chan MiningWork
    resultChan  chan<- MiningResult
    hashEngine  interfaces.HashEngine
    stopChan    chan struct{}
    logger      log.Logger
}

func NewParallelMiner(threadCount int, hashEngine interfaces.HashEngine, logger log.Logger) *ParallelMiner {
    pm := &ParallelMiner{
        threadCount: threadCount,
        workQueue:   make(chan MiningWork, threadCount*2),
        resultChan:  make(chan MiningResult, threadCount),
        workers:     make([]*MiningWorker, threadCount),
        perfMonitor: NewPerformanceMonitor(),
        logger:      logger,
    }
    
    // åˆ›å»ºå·¥ä½œçº¿ç¨‹
    for i := 0; i < threadCount; i++ {
        pm.workers[i] = &MiningWorker{
            workerID:   i,
            workChan:   pm.workQueue,
            resultChan: pm.resultChan,
            hashEngine: hashEngine,
            stopChan:   make(chan struct{}),
            logger:     logger,
        }
    }
    
    return pm
}

func (pm *ParallelMiner) StartMining(ctx context.Context, headerBytes []byte, target []byte) <-chan MiningResult {
    pm.logger.Info("å¯åŠ¨å¹¶è¡ŒæŒ–çŸ¿")
    
    // å¯åŠ¨æ‰€æœ‰å·¥ä½œçº¿ç¨‹
    for _, worker := range pm.workers {
        go worker.Run(ctx)
    }
    
    // åˆ†å‘æŒ–çŸ¿ä»»åŠ¡
    go pm.distributeMiningWork(ctx, headerBytes, target)
    
    return pm.resultChan
}

func (pm *ParallelMiner) distributeMiningWork(ctx context.Context, headerBytes []byte, target []byte) {
    const maxNonce = uint64(1) << 32 // 4G nonceèŒƒå›´
    nonceRangePerWork := maxNonce / uint64(pm.threadCount*4) // å°†æ€»èŒƒå›´åˆ†æˆæ›´å¤šå°ä»»åŠ¡
    
    workID := 0
    for startNonce := uint64(0); startNonce < maxNonce; startNonce += nonceRangePerWork {
        endNonce := startNonce + nonceRangePerWork
        if endNonce > maxNonce {
            endNonce = maxNonce
        }
        
        work := MiningWork{
            WorkID:      workID,
            HeaderBytes: headerBytes,
            Target:      target,
            StartNonce:  startNonce,
            EndNonce:    endNonce,
        }
        
        select {
        case pm.workQueue <- work:
            workID++
        case <-ctx.Done():
            pm.logger.Info("æŒ–çŸ¿ä»»åŠ¡åˆ†å‘è¢«å–æ¶ˆ")
            return
        }
    }
    
    close(pm.workQueue)
}

func (worker *MiningWorker) Run(ctx context.Context) {
    worker.logger.Info("æŒ–çŸ¿å·¥ä½œçº¿ç¨‹å¯åŠ¨")
    defer worker.logger.Info("æŒ–çŸ¿å·¥ä½œçº¿ç¨‹é€€å‡º")
    
    for {
        select {
        case work, ok := <-worker.workChan:
            if !ok {
                // å·¥ä½œé˜Ÿåˆ—å·²å…³é—­
                return
            }
            
            // æ‰§è¡ŒæŒ–çŸ¿å·¥ä½œ
            result := worker.executeWork(ctx, work)
            if result.Success {
                // æ‰¾åˆ°æœ‰æ•ˆè§£ï¼Œç«‹å³é€šçŸ¥
                select {
                case worker.resultChan <- result:
                    worker.logger.Info("æ‰¾åˆ°æœ‰æ•ˆè§£")
                    return // å·¥ä½œå®Œæˆ
                case <-ctx.Done():
                    return
                }
            }
            
        case <-worker.stopChan:
            worker.logger.Info("æ”¶åˆ°åœæ­¢ä¿¡å·")
            return
            
        case <-ctx.Done():
            worker.logger.Info("ä¸Šä¸‹æ–‡å–æ¶ˆ")
            return
        }
    }
}

func (worker *MiningWorker) executeWork(ctx context.Context, work MiningWork) MiningResult {
    attempts := uint64(0)
    
    for nonce := work.StartNonce; nonce < work.EndNonce; nonce++ {
        attempts++
        
        // å®šæœŸæ£€æŸ¥å–æ¶ˆä¿¡å·
        if attempts%1000 == 0 {
            select {
            case <-ctx.Done():
                return MiningResult{Success: false, Error: "cancelled"}
            default:
            }
        }
        
        // è®¡ç®—å“ˆå¸Œ
        headerWithNonce := append(work.HeaderBytes, worker.uint64ToBytes(nonce)...)
        hash := worker.hashEngine.DoubleSHA256(headerWithNonce)
        
        // æ£€æŸ¥æ˜¯å¦æ»¡è¶³éš¾åº¦
        if bytes.Compare(hash, work.Target) <= 0 {
            return MiningResult{
                Success:  true,
                Nonce:    nonce,
                Hash:     hash,
                ThreadID: uint64(worker.workerID),
                Attempts: attempts,
            }
        }
    }
    
    return MiningResult{Success: false, Attempts: attempts}
}
```

## ğŸ“Š **æ€§èƒ½ç›‘æ§ç³»ç»Ÿ**

### **performance_monitor.go - æ€§èƒ½ç›‘æ§å®ç°**

```go
// pow_handler/performance_monitor.go - æ€§èƒ½ç›‘æ§å®ç°

type PerformanceMonitor struct {
    // åŸºç¡€ç»Ÿè®¡
    totalHashes       uint64    // æ€»è®¡ç®—å“ˆå¸Œæ•°
    startTime         time.Time // å¼€å§‹æ—¶é—´
    lastUpdateTime    time.Time // æœ€åæ›´æ–°æ—¶é—´
    
    // éªŒè¯ç»Ÿè®¡
    totalVerifications uint64   // æ€»éªŒè¯æ¬¡æ•°
    validVerifications uint64   // æœ‰æ•ˆéªŒè¯æ¬¡æ•°
    
    // çº¿ç¨‹ç»Ÿè®¡
    threadStats       map[int]*ThreadStats // æ¯çº¿ç¨‹ç»Ÿè®¡
    
    // æ€§èƒ½æŒ‡æ ‡
    currentHashrate   float64   // å½“å‰ç®—åŠ›
    averageHashrate   float64   // å¹³å‡ç®—åŠ›
    peakHashrate      float64   // å³°å€¼ç®—åŠ›
    
    mutex sync.RWMutex
}

type ThreadStats struct {
    ThreadID      int     `json:"thread_id"`
    HashCount     uint64  `json:"hash_count"`
    ValidSolutions uint64  `json:"valid_solutions"`
    LastActiveTime time.Time `json:"last_active_time"`
}

type HashrateStats struct {
    CurrentHashrate    float64            `json:"current_hashrate"`
    AverageHashrate    float64            `json:"average_hashrate"`
    PeakHashrate       float64            `json:"peak_hashrate"`
    TotalHashes        uint64             `json:"total_hashes"`
    TotalVerifications uint64             `json:"total_verifications"`
    ValidVerifications uint64             `json:"valid_verifications"`
    ThreadStatistics   map[int]*ThreadStats `json:"thread_statistics"`
    Uptime            time.Duration       `json:"uptime"`
}

func NewPerformanceMonitor() *PerformanceMonitor {
    return &PerformanceMonitor{
        startTime:      time.Now(),
        lastUpdateTime: time.Now(),
        threadStats:    make(map[int]*ThreadStats),
    }
}

func (pm *PerformanceMonitor) UpdateHashCount(count uint64) {
    pm.mutex.Lock()
    defer pm.mutex.Unlock()
    
    pm.totalHashes += count
    pm.lastUpdateTime = time.Now()
    
    // è®¡ç®—å½“å‰ç®—åŠ›
    pm.calculateCurrentHashrate()
}

func (pm *PerformanceMonitor) UpdateThreadStats(threadID int, hashCount uint64) {
    pm.mutex.Lock()
    defer pm.mutex.Unlock()
    
    if _, exists := pm.threadStats[threadID]; !exists {
        pm.threadStats[threadID] = &ThreadStats{
            ThreadID: threadID,
        }
    }
    
    pm.threadStats[threadID].HashCount += hashCount
    pm.threadStats[threadID].LastActiveTime = time.Now()
}

func (pm *PerformanceMonitor) RecordValidSolution(threadID int) {
    pm.mutex.Lock()
    defer pm.mutex.Unlock()
    
    if stats, exists := pm.threadStats[threadID]; exists {
        stats.ValidSolutions++
    }
}

func (pm *PerformanceMonitor) RecordValidVerification() {
    pm.mutex.Lock()
    defer pm.mutex.Unlock()
    
    pm.totalVerifications++
    pm.validVerifications++
}

func (pm *PerformanceMonitor) RecordInvalidVerification() {
    pm.mutex.Lock()
    defer pm.mutex.Unlock()
    
    pm.totalVerifications++
}

func (pm *PerformanceMonitor) calculateCurrentHashrate() {
    elapsed := time.Since(pm.startTime)
    if elapsed > 0 {
        pm.averageHashrate = float64(pm.totalHashes) / elapsed.Seconds()
    }
    
    // è®¡ç®—æœ€è¿‘1åˆ†é’Ÿçš„ç®—åŠ›ä½œä¸ºå½“å‰ç®—åŠ›
    recentDuration := time.Since(pm.lastUpdateTime)
    if recentDuration > time.Minute {
        pm.currentHashrate = pm.averageHashrate
    }
    
    // æ›´æ–°å³°å€¼ç®—åŠ›
    if pm.currentHashrate > pm.peakHashrate {
        pm.peakHashrate = pm.currentHashrate
    }
}

func (pm *PerformanceMonitor) GetStatistics() *HashrateStats {
    pm.mutex.RLock()
    defer pm.mutex.RUnlock()
    
    // å¤åˆ¶çº¿ç¨‹ç»Ÿè®¡
    threadStatsCopy := make(map[int]*ThreadStats)
    for id, stats := range pm.threadStats {
        threadStatsCopy[id] = &ThreadStats{
            ThreadID:       stats.ThreadID,
            HashCount:      stats.HashCount,
            ValidSolutions: stats.ValidSolutions,
            LastActiveTime: stats.LastActiveTime,
        }
    }
    
    return &HashrateStats{
        CurrentHashrate:    pm.currentHashrate,
        AverageHashrate:    pm.averageHashrate,
        PeakHashrate:       pm.peakHashrate,
        TotalHashes:        pm.totalHashes,
        TotalVerifications: pm.totalVerifications,
        ValidVerifications: pm.validVerifications,
        ThreadStatistics:   threadStatsCopy,
        Uptime:            time.Since(pm.startTime),
    }
}

func (pm *PerformanceMonitor) ResetStatistics() {
    pm.mutex.Lock()
    defer pm.mutex.Unlock()
    
    pm.totalHashes = 0
    pm.startTime = time.Now()
    pm.lastUpdateTime = time.Now()
    pm.totalVerifications = 0
    pm.validVerifications = 0
    pm.currentHashrate = 0
    pm.averageHashrate = 0
    pm.peakHashrate = 0
    pm.threadStats = make(map[int]*ThreadStats)
}
```

## âš™ï¸ **é…ç½®ä¸é›†æˆ**

### **fxä¾èµ–æ³¨å…¥é…ç½®**

```go
// pow_handler/module.go

var PoWHandlerModule = fx.Module("pow_handler",
    fx.Provide(NewManager),
    fx.Provide(NewHashComputer),
    fx.Provide(NewParallelMiner),
)

func NewManager(
    hashEngine interfaces.HashEngine,
    difficultyManager interfaces.DifficultyManager,
    threadPool interfaces.ThreadPool,
    logger log.Logger,
    config *PoWConfig,
) interfaces.PoWComputeHandler {
    return NewManager(hashEngine, difficultyManager, threadPool, logger, config)
}
```

### **é…ç½®å‚æ•°**

```json
{
  "miner": {
    "pow_handler": {
      "mining_threads": 8,
      "max_nonce": 4294967296,
      "batch_size": 10000,
      "hash_algorithm": "SHA256",
      "enable_profiling": true,
      "simd_optimization": true,
      "thread_affinity": true,
      "memory_pool_size": "64MB"
    }
  }
}
```

## ğŸ”š **æ€»ç»“**

**PoWè®¡ç®—å¤„ç†å™¨æ ¸å¿ƒç‰¹æ€§**ï¼š

1. **é«˜æ€§èƒ½è®¡ç®—**ï¼šå¤šçº¿ç¨‹å¹¶è¡ŒPoWè®¡ç®—ï¼Œå……åˆ†åˆ©ç”¨CPUèµ„æº
2. **ç®—æ³•å…¼å®¹æ€§**ï¼šæ”¯æŒå¤šç§å“ˆå¸Œç®—æ³•ï¼Œå…¼å®¹ä¼ ç»ŸPoWæœºåˆ¶
3. **SIMDä¼˜åŒ–**ï¼šåˆ©ç”¨CPU SIMDæŒ‡ä»¤é›†ä¼˜åŒ–å“ˆå¸Œè®¡ç®—æ€§èƒ½
4. **æ™ºèƒ½ä»»åŠ¡åˆ†å‘**ï¼šåŠ¨æ€ä»»åŠ¡åˆ†å‘ï¼Œä¼˜åŒ–å·¥ä½œè´Ÿè½½å¹³è¡¡
5. **å®æ—¶ç›‘æ§**ï¼šè¯¦ç»†çš„ç®—åŠ›ç»Ÿè®¡å’Œæ€§èƒ½ç›‘æ§
6. **å†…å­˜ä¼˜åŒ–**ï¼šå¯¹è±¡æ± åŒ–ï¼Œå‡å°‘å†…å­˜åˆ†é…å¼€é”€
7. **ä¸­æ–­æ§åˆ¶**ï¼šæ”¯æŒè®¡ç®—è¿‡ç¨‹çš„ä¼˜é›…ä¸­æ–­å’Œå–æ¶ˆ

**æ¶æ„è®¾è®¡ä¼˜åŠ¿**ï¼š
- èŒè´£å•ä¸€ï¼Œä¸“æ³¨PoWè®¡ç®—
- é«˜åº¦å¹¶è¡ŒåŒ–ï¼Œæ€§èƒ½ä¼˜å¼‚
- å†…å­˜å‹å¥½ï¼Œèµ„æºåˆ©ç”¨é«˜æ•ˆ
- ç›‘æ§å®Œå–„ï¼Œä¾¿äºæ€§èƒ½è°ƒä¼˜
- é…ç½®çµæ´»ï¼Œé€‚åº”ä¸åŒç¡¬ä»¶ç¯å¢ƒ
