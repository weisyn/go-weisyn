package facade

import (
	"context"
	"fmt"
	"math/rand"
	"strings"
	"sync"
	"time"

	pubsub "github.com/libp2p/go-libp2p-pubsub"
	libhost "github.com/libp2p/go-libp2p/core/host"
	libnetwork "github.com/libp2p/go-libp2p/core/network"
	peer "github.com/libp2p/go-libp2p/core/peer"
	libprotocol "github.com/libp2p/go-libp2p/core/protocol"
	"go.uber.org/zap"
	"google.golang.org/protobuf/proto"

	networkconfig "github.com/weisyn/v1/internal/config/network"
	networkInterfaces "github.com/weisyn/v1/internal/core/network/interfaces"
	pubimpl "github.com/weisyn/v1/internal/core/network/pubsub"
	regimpl "github.com/weisyn/v1/internal/core/network/registry"
	netsec "github.com/weisyn/v1/internal/core/network/security"
	stcodec "github.com/weisyn/v1/internal/core/network/stream"
	transportpb "github.com/weisyn/v1/pb/network/transport"
	"github.com/weisyn/v1/pkg/constants/protocols"
	cryptoi "github.com/weisyn/v1/pkg/interfaces/infrastructure/crypto"
	logiface "github.com/weisyn/v1/pkg/interfaces/infrastructure/log"
	metricsiface "github.com/weisyn/v1/pkg/interfaces/infrastructure/metrics"
	iface "github.com/weisyn/v1/pkg/interfaces/network"
)

// Facade Network é—¨é¢ç»Ÿä¸€å®ç°
// ç”¨é€”ï¼š
// - å®ç° networkInterfaces.InternalNetwork æ¥å£ï¼Œç»Ÿä¸€æä¾›åè®®æ³¨å†Œã€æµå¼å‘é€ä¸è®¢é˜…å‘å¸ƒèƒ½åŠ›
// - èšåˆå†…éƒ¨ç»„ä»¶å®Œæˆæ¶ˆæ¯ç¼–è§£ç ä¸åˆ†å‘ï¼Œä¸æš´éœ²ç”Ÿå‘½å‘¨æœŸä¸æŒ‡æ ‡
// è¯´æ˜ï¼š
// - ä¸åŒ…å«ç”Ÿå‘½å‘¨æœŸç®¡ç†ï¼ˆStart/Stopï¼‰ï¼›ç”±ä¸Šå±‚ DI ç®¡ç†
// - ä¸æš´éœ²å†…éƒ¨æŒ‡æ ‡æˆ–çŠ¶æ€ï¼›ä»…èšç„¦æ¶ˆæ¯ç¼–è§£ç ä¸åˆ†å‘
// - ä¸šåŠ¡åè®®ç”±å„é¢†åŸŸæ¨¡å—è‡ªè¡Œæ³¨å†Œï¼ŒNetwork ä¸ç»´æŠ¤ä¸šåŠ¡åè®®æ¸…å•
// - éµå¾ªä»£ç ç»„ç»‡è§„èŒƒï¼šå®ç°å†…éƒ¨æ¥å£ InternalNetworkï¼Œè€Œéç›´æ¥å®ç°å…¬å…±æ¥å£
type Facade struct {
	host   libhost.Host              // P2På®¿ä¸»ï¼Œç”¨äºè¿é€šæ€§ä¿éšœä¸æµæ“ä½œ
	reg    *regimpl.ProtocolRegistry // åè®®æ³¨å†Œè¡¨ï¼ˆä¾›è¯Šæ–­ä¸å¤„ç†å™¨æŸ¥æ‰¾ï¼‰
	logger logiface.Logger           // ç»“æ„åŒ–æ—¥å¿—å™¨

	// PubSub ç»„ä»¶
	tm    *pubimpl.TopicManager
	enc   *pubimpl.Encoder
	dec   *pubimpl.Decoder
	val   *pubimpl.Validator
	pub   *pubimpl.Publisher
	subs  map[string]iface.SubscribeHandler // æœ¬åœ°è®¢é˜…å¤„ç†å™¨
	subCF map[string]iface.SubscribeConfig  // è®¢é˜…é…ç½®å¿«ç…§
	regCF map[string]iface.RegisterConfig   // æ³¨å†Œé…ç½®å¿«ç…§
	// GossipSub ç»„ä»¶
	ps           *pubsub.PubSub
	topicHandles map[string]*pubsub.Topic
	subHandles   map[string]*pubsub.Subscription
	subCancels   map[string]context.CancelFunc

	// æ³¨å†ŒçŠ¶æ€ç®¡ç†ï¼ˆé˜²é‡å¤æ³¨å†Œï¼‰
	registeredProtocols map[string]bool // å·²æ³¨å†Œçš„æµå¼åè®®
	registeredTopics    map[string]bool // å·²æ³¨å†Œçš„è®¢é˜…ä¸»é¢˜

	// äº’æ–¥ä¿æŠ¤
	regMu sync.RWMutex // ä¿æŠ¤æ³¨å†ŒçŠ¶æ€ç®¡ç†
	subMu sync.RWMutex // ä¿æŠ¤ subs/subCF/regCF
	psMu  sync.Mutex   // ä¿æŠ¤ topicHandles/subHandles/subCancels

	// å…¥ç«™å¹¶å‘/èƒŒå‹
	streamSvc *stcodec.Service

	// é…ç½®ï¼ˆå¯é€‰ï¼‰
	cfg *networkconfig.Config

	// ç½‘ç»œå‘½åç©ºé—´ï¼ˆç”¨äºè‡ªåŠ¨ä¸ºåè®® ID å’Œ Topic æ·»åŠ  namespaceï¼‰
	networkNamespace string

	// ğŸ†• åè®®åå•†å™¨ï¼ˆMEDIUM-002 ä¿®å¤ï¼‰
	protocolNegotiator *ProtocolNegotiator

	// crypto services
	hashManager cryptoi.HashManager
	sigManager  cryptoi.SignatureManager

	// å®‰å…¨ä¿æŠ¤ç»„ä»¶ï¼ˆçœŸå®æ¥å…¥ï¼‰
	rateLimiter    *netsec.RateLimiter
	msgRateLimiter *netsec.MessageRateLimiter

	// æœ€å°å¯è§‚æµ‹æ€§
	pubCount   uint64
	dropCount  uint64
	callCount  uint64
	retryCount uint64

	// validatorCleanupStop ç”¨äºåœæ­¢ Validator æ¸…ç†åç¨‹
	validatorCleanupStop chan struct{}

	// ====================
	// forceConnectï¼šå¯æ§æ‹¨å·ï¼ˆä¸šåŠ¡èŠ‚ç‚¹ä¼˜å…ˆï¼‰
	// ====================
	forceConnectMu          sync.Mutex
	forceConnectReqCh       chan string
	forceConnectStopCtx     context.Context
	forceConnectStopCancel  context.CancelFunc
	forceConnectLastAt      time.Time
	forceConnectCfg         ForceConnectConfig
	forceConnectRand        *rand.Rand
}

// ForceConnectConfig forceConnectï¼ˆGossipSub Mesh æ‹‰æ´»ï¼‰é…ç½®
//
// ç›®æ ‡ï¼šé¿å…å¯¹ peerstore å…¨é‡æ‹¨å·é€ æˆ goroutine é£æš´ï¼›ä¸šåŠ¡èŠ‚ç‚¹ä¼˜å…ˆï¼Œå…¶ä½™èŠ‚ç‚¹æŠ½æ ·è¾…åŠ©å…¬ç½‘å‘ç°ã€‚
type ForceConnectConfig struct {
	Enabled           bool
	Cooldown          time.Duration
	Concurrency       int
	BudgetPerRound    int
	Tier2SampleBudget int
	Timeout           time.Duration

	BusinessPeers  []peer.ID
	BootstrapPeers []peer.ID
}

// SetForceConnectConfig è®¾ç½® forceConnect é…ç½®ï¼ˆç”±ä¸Šå±‚æ¨¡å—æ³¨å…¥ï¼‰
func (f *Facade) SetForceConnectConfig(cfg ForceConnectConfig) {
	if f == nil {
		return
	}
	f.forceConnectMu.Lock()
	defer f.forceConnectMu.Unlock()

	f.forceConnectCfg = cfg
	// é»˜è®¤å…œåº•
	if f.forceConnectCfg.Cooldown <= 0 {
		f.forceConnectCfg.Cooldown = 2 * time.Minute
	}
	if f.forceConnectCfg.Concurrency <= 0 {
		f.forceConnectCfg.Concurrency = 15
	}
	if f.forceConnectCfg.BudgetPerRound <= 0 {
		f.forceConnectCfg.BudgetPerRound = 50
	}
	if f.forceConnectCfg.Tier2SampleBudget < 0 {
		f.forceConnectCfg.Tier2SampleBudget = 0
	}
	if f.forceConnectCfg.Timeout <= 0 {
		f.forceConnectCfg.Timeout = 10 * time.Second
	}

	if f.logger != nil {
		f.logger.Infof("forceConnect config loaded enabled=%t cooldown=%s concurrency=%d budget=%d tier2_sample=%d business_peers=%d bootstrap_peers=%d",
			f.forceConnectCfg.Enabled,
			f.forceConnectCfg.Cooldown,
			f.forceConnectCfg.Concurrency,
			f.forceConnectCfg.BudgetPerRound,
			f.forceConnectCfg.Tier2SampleBudget,
			len(f.forceConnectCfg.BusinessPeers),
			len(f.forceConnectCfg.BootstrapPeers),
		)
	}
}

func (f *Facade) ensureForceConnectLoop() {
	if f == nil {
		return
	}
	f.forceConnectMu.Lock()
	defer f.forceConnectMu.Unlock()

	if f.forceConnectReqCh != nil {
		return
	}
	f.forceConnectReqCh = make(chan string, 4) // åˆå¹¶è§¦å‘ï¼Œé¿å…å¹¶å‘è§¦å‘å †ç§¯
	f.forceConnectStopCtx, f.forceConnectStopCancel = context.WithCancel(context.Background())
	f.forceConnectRand = rand.New(rand.NewSource(time.Now().UnixNano()))

	go f.forceConnectLoop()
}

// requestForceConnect è¯·æ±‚æ‰§è¡Œä¸€è½® forceConnectï¼ˆåˆå¹¶è§¦å‘ + cooldown èŠ‚æµï¼‰
func (f *Facade) requestForceConnect(reason string) {
	if f == nil {
		return
	}
	f.ensureForceConnectLoop()

	select {
	case f.forceConnectReqCh <- reason:
	default:
		// channel æ»¡äº†ï¼Œä¸¢å¼ƒï¼ˆåˆå¹¶è§¦å‘ï¼‰
	}
}

func (f *Facade) forceConnectLoop() {
	for {
		select {
		case <-f.forceConnectStopCtx.Done():
			return
		case reason := <-f.forceConnectReqCh:
			f.runForceConnectRound(reason)
		}
	}
}

// NewFacade åˆ›å»º Network é—¨é¢å®ä¾‹
func NewFacade(host libhost.Host, logger logiface.Logger, cfg *networkconfig.Config, hashMgr cryptoi.HashManager, sigMgr cryptoi.SignatureManager) *Facade {
	return NewFacadeWithNamespace(host, logger, cfg, hashMgr, sigMgr, "")
}

// NewFacadeWithNamespace åˆ›å»º Network é—¨é¢å®ä¾‹ï¼ˆå¸¦ namespaceï¼‰
func NewFacadeWithNamespace(host libhost.Host, logger logiface.Logger, cfg *networkconfig.Config, hashMgr cryptoi.HashManager, sigMgr cryptoi.SignatureManager, namespace string) *Facade {
	if logger == nil {
		logger = &noopLogger{} // å ä½æ—¥å¿—å™¨
	}

	// åˆå§‹åŒ–å®‰å…¨é™åˆ¶å™¨å‚æ•°ï¼ˆä»é…ç½®è¯»å–ï¼Œå¸¦é»˜è®¤å€¼å›é€€ï¼‰
	maxConns := 1000             // é»˜è®¤æœ€å¤§è¿æ¥æ•°
	maxPerIP := 50               // é»˜è®¤æ¯IPæœ€å¤§è¿æ¥æ•°
	maxMsgs := 100               // é»˜è®¤æ¯æ—¶é—´çª—å£æœ€å¤§æ¶ˆæ¯æ•°
	msgWindow := 1 * time.Minute // é»˜è®¤æ¶ˆæ¯çª—å£

	// ä»é…ç½®è¯»å–å®‰å…¨å‚æ•°ï¼ˆå¦‚æœé…ç½®å¯ç”¨ï¼‰
	if cfg != nil {
		if cfgMaxConns := cfg.GetMaxConnections(); cfgMaxConns > 0 {
			maxConns = cfgMaxConns
		}
		if cfgMaxPerIP := cfg.GetMaxConnectionsPerIP(); cfgMaxPerIP > 0 {
			maxPerIP = cfgMaxPerIP
		}
		if cfgMaxMsgs := cfg.GetMaxMessagesPerWindow(); cfgMaxMsgs > 0 {
			maxMsgs = cfgMaxMsgs
		}
		if cfgMsgWindow := cfg.GetMessageRateLimitWindow(); cfgMsgWindow > 0 {
			msgWindow = cfgMsgWindow
		}
	}

	f := &Facade{
		host:                 host,
		reg:                  regimpl.NewProtocolRegistry(),
		logger:               logger,
		tm:                   pubimpl.NewTopicManager(),
		enc:                  pubimpl.NewEncoder(),
		dec:                  pubimpl.NewDecoder(),
		val:                  pubimpl.NewValidator(),
		pub:                  pubimpl.NewPublisher(),
		subs:                 make(map[string]iface.SubscribeHandler),
		subCF:                make(map[string]iface.SubscribeConfig),
		regCF:                make(map[string]iface.RegisterConfig),
		registeredProtocols:  make(map[string]bool),
		registeredTopics:     make(map[string]bool),
		streamSvc:            stcodec.New(host),
		cfg:                  cfg,
		networkNamespace:     namespace,
		hashManager:          hashMgr,
		sigManager:           sigMgr,
		topicHandles:         make(map[string]*pubsub.Topic),
		subHandles:           make(map[string]*pubsub.Subscription),
		subCancels:           make(map[string]context.CancelFunc),
		rateLimiter:          netsec.NewRateLimiter(maxConns, maxPerIP),
		msgRateLimiter:       netsec.NewMessageRateLimiter(maxMsgs, msgWindow),
		validatorCleanupStop: make(chan struct{}),
		// ğŸ†• MEDIUM-002 ä¿®å¤ï¼šåˆå§‹åŒ–åè®®åå•†å™¨
		protocolNegotiator:   NewProtocolNegotiator(namespace, 30*time.Minute, 1000),
	}
	// å°†ç»Ÿä¸€å“ˆå¸ŒæœåŠ¡æ³¨å…¥ validator ç”¨äºå»é‡
	if f.hashManager != nil {
		f.val.WithHasher(func(b []byte) (string, error) {
			h := f.hashManager.SHA256(b)
			return fmt.Sprintf("%x", h), nil
		})
	}
	// æ³¨å…¥ç­¾åéªŒç­¾é’©å­ï¼šå½“å‰ä»…æ£€æŸ¥â€œç­¾åå­˜åœ¨â€ä»¥é¿å…ç¼ºå°‘å…¬é’¥å¯¼è‡´è¯¯åˆ¤
	f.val.WithVerifier(func(payload, sig []byte) (bool, error) {
		return len(sig) > 0, nil
	})
	// å¯åŠ¨ Validator å»é‡è¿‡æœŸæ¸…ç†åå°ä»»åŠ¡ï¼ˆè½»é‡ï¼Œå¯ç”± Facade.Stop() åœæ­¢ï¼‰
	go func(stopCh <-chan struct{}) {
		ticker := time.NewTicker(time.Minute)
		defer ticker.Stop()

		for {
			select {
			case <-ticker.C:
				if f.val != nil {
					f.val.CleanupExpiredEntries()
				}
			case <-stopCh:
				return
			}
		}
	}(f.validatorCleanupStop)
	// ğŸ”§ ä¸åœ¨è¿™é‡Œåˆå§‹åŒ–GossipSubï¼Œç­‰å¾…Hostå¯åŠ¨äº‹ä»¶è§¦å‘
	return f
}

// qualifyProtocolID ä¸ºåè®® ID æ·»åŠ  namespaceï¼ˆå¦‚æœé…ç½®äº† namespaceï¼‰
func (f *Facade) qualifyProtocolID(protoID string) string {
	if f.networkNamespace == "" {
		return protoID
	}
	return protocols.QualifyProtocol(protoID, f.networkNamespace)
}

// qualifyTopic ä¸º Topic æ·»åŠ  namespaceï¼ˆå¦‚æœé…ç½®äº† namespaceï¼‰
func (f *Facade) qualifyTopic(topic string) string {
	if f.networkNamespace == "" {
		return topic
	}
	return protocols.QualifyTopic(topic, f.networkNamespace)
}

// ç¼–è¯‘æœŸæ£€æŸ¥ï¼šç¡®ä¿ Facade å®ç°å†…éƒ¨æ¥å£ InternalNetwork
// éµå¾ªä»£ç ç»„ç»‡è§„èŒƒï¼šå®ç°å±‚å¿…é¡»å®ç°å†…éƒ¨æ¥å£ï¼Œä¸èƒ½ç›´æ¥å®ç°å…¬å…±æ¥å£
var _ networkInterfaces.InternalNetwork = (*Facade)(nil)

// initGossipSub åˆå§‹åŒ–æˆ–é‡æ–°åˆå§‹åŒ– GossipSub
func (f *Facade) initGossipSub() {
	if f.host == nil {
		f.logger.Errorf("âŒ initGossipSub: host is nil")
		return
	}

	if f.host == nil {
		f.logger.Errorf("âŒ initGossipSub: libp2p host is nil")
		return
	}

	f.logger.Infof("ğŸ”§ Creating GossipSub with optimized config for small networks")

	// ğŸ”§ ä¿®å¤ï¼šä¸ºå°ç½‘ç»œä¼˜åŒ–çš„GossipSubé…ç½®
	opts := []pubsub.Option{
		pubsub.WithPeerExchange(true),                          // å¯ç”¨peeräº¤æ¢
		pubsub.WithFloodPublish(true),                          // å¯ç”¨æ´ªæ³›å‘å¸ƒï¼Œæ”¯æŒå°ç½‘ç»œ
		pubsub.WithMessageSignaturePolicy(pubsub.StrictNoSign), // ç¦ç”¨æ¶ˆæ¯ç­¾ååŠ é€Ÿä¼ è¾“
	}

	if ps, err := pubsub.NewGossipSub(context.Background(), f.host, opts...); err == nil {
		f.ps = ps
		f.logger.Infof("ğŸ‰ gossipsub initialized successfully with optimized mesh config")

		// âœ… å¯æ§æ‹‰æ´»ï¼šåˆå¹¶è§¦å‘ + cooldown èŠ‚æµ + ä¸šåŠ¡èŠ‚ç‚¹ä¼˜å…ˆ
		f.requestForceConnect("gossipsub_init")
	} else {
		f.logger.Errorf("âŒ gossipsub init failed: %v", err)
	}
}

// ensureGossipSub ç¡®ä¿ GossipSub å·²åˆå§‹åŒ–ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼‰
func (f *Facade) ensureGossipSub() {
	if f.ps != nil {
		return // å·²ç»åˆå§‹åŒ–
	}

	f.logger.Infof("gossipsub not initialized, checking host status")

	// ğŸ”§ ä¿®å¤ï¼šé™é»˜ç­‰å¾…hostå¯åŠ¨å®Œæˆï¼Œä¸æŠ¥é”™
	if f.host == nil {
		return // é™é»˜ç­‰å¾…
	}

	// hostå·²å°±ç»ªï¼Œç›´æ¥åˆå§‹åŒ–GossipSub
	f.logger.Infof("âœ… host is ready, initializing gossipsub")
	f.initGossipSub()

	if f.ps == nil {
		f.logger.Errorf("âŒ gossipsub initialization failed even with ready host")
	} else {
		f.logger.Infof("âœ… gossipsub successfully initialized")
	}
}

// ForceInitializeGossipSub å¼ºåˆ¶åˆå§‹åŒ–GossipSubï¼ˆåœ¨Hostå¯åŠ¨åè°ƒç”¨ï¼‰
func (f *Facade) ForceInitializeGossipSub() {
	if f.ps != nil {
		f.logger.Infof("gossipsub already initialized")
		return
	}

	f.logger.Infof("ğŸ”§ å¼ºåˆ¶åˆå§‹åŒ–GossipSub")
	f.ensureGossipSub()

	// ğŸ”§ é‡è¦ï¼šGossipSubåˆå§‹åŒ–åï¼Œé‡æ–°å¤„ç†æ‰€æœ‰è®¢é˜…ä»¥ç¡®ä¿çœŸæ­£åŠ å…¥mesh
	if f.ps != nil {
		f.logger.Infof("ğŸ”§ GossipSubåˆå§‹åŒ–æˆåŠŸï¼Œç­‰å¾…å°±ç»ªåå¤„ç†è®¢é˜…")
		f.waitForGossipSubReady()
		f.reprocessAllSubscriptions()
	}
}

// waitForGossipSubReady ç­‰å¾…GossipSubå®Œå…¨å°±ç»ª
func (f *Facade) waitForGossipSubReady() {
	f.logger.Infof("ğŸ”§ æ£€æŸ¥GossipSubå°±ç»ªçŠ¶æ€")

	maxRetries := 50 // æœ€å¤šç­‰å¾…5ç§’
	for i := 0; i < maxRetries; i++ {
		if f.isGossipSubReady() {
			f.logger.Infof("âœ… GossipSubå·²å°±ç»ªï¼Œå¯ä»¥åŠ å…¥ä¸»é¢˜ (æ£€æŸ¥%dæ¬¡)", i+1)
			return
		}
		time.Sleep(100 * time.Millisecond)
	}
	f.logger.Warnf("âš ï¸ GossipSubå°±ç»ªæ£€æŸ¥è¶…æ—¶ï¼Œç»§ç»­æ‰§è¡Œ")
}

// isGossipSubReady æ£€æŸ¥GossipSubæ˜¯å¦å·²ç»å®Œå…¨å°±ç»ª
func (f *Facade) isGossipSubReady() bool {
	if f.ps == nil {
		return false
	}

	// å°è¯•åˆ›å»ºä¸€ä¸ªæµ‹è¯•ä¸»é¢˜æ¥éªŒè¯GossipSubçŠ¶æ€
	testTopic := "test.readiness.check.v1"
	if handle, err := f.ps.Join(testTopic); err == nil {
		// ç«‹å³å…³é—­æµ‹è¯•ä¸»é¢˜ï¼Œé¿å…æ±¡æŸ“
		if err := handle.Close(); err != nil {
			f.logger.Warnf("å…³é—­æµ‹è¯•ä¸»é¢˜å¤±è´¥: %v", err)
		}
		f.logger.Debugf("ğŸ”§ GossipSubå°±ç»ªæ£€æŸ¥é€šè¿‡")
		return true
	} else {
		f.logger.Debugf("ğŸ”§ GossipSubå°šæœªå°±ç»ª: %v", err)
		return false
	}
}

// reprocessAllSubscriptions é‡æ–°å¤„ç†æ‰€æœ‰è®¢é˜…ï¼Œç¡®ä¿å®ƒä»¬çœŸæ­£åŠ å…¥meshç½‘ç»œ
func (f *Facade) reprocessAllSubscriptions() {
	f.subMu.Lock()
	topics := make([]string, 0, len(f.subs))
	for topic := range f.subs {
		topics = append(topics, topic)
	}
	f.subMu.Unlock()

	f.logger.Infof("ğŸ”§ é‡æ–°å¤„ç† %d ä¸ªè®¢é˜…ä¸»é¢˜", len(topics))

	for _, topic := range topics {
		f.psMu.Lock()

		// æ£€æŸ¥æ˜¯å¦å·²ç»åŠ å…¥ä¸»é¢˜
		if _, ok := f.topicHandles[topic]; !ok {
			f.logger.Infof("ğŸ”§ ä¸ºä¸»é¢˜ %s åŠ å…¥meshç½‘ç»œ", topic)
			if t, e := f.ps.Join(topic); e == nil {
				f.topicHandles[topic] = t
				f.logger.Infof("âœ… æˆåŠŸåŠ å…¥ä¸»é¢˜mesh: %s", topic)
			} else {
				f.logger.Errorf("âŒ åŠ å…¥ä¸»é¢˜meshå¤±è´¥: %s, error: %v", topic, e)
			}
		}

		// æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰è®¢é˜…
		if _, exists := f.subHandles[topic]; !exists {
			f.logger.Infof("ğŸ”§ ä¸ºä¸»é¢˜ %s åˆ›å»ºè®¢é˜…", topic)
			if sub, e := f.ps.Subscribe(topic); e == nil {
				f.subHandles[topic] = sub
				ctx, cancel := context.WithCancel(context.Background())
				f.subCancels[topic] = cancel

				// å¯åŠ¨æ¶ˆæ¯å¤„ç†åç¨‹
				go func() {
					dec := f.dec
					for {
						msg, err := sub.Next(ctx)
						if err != nil {
							f.logger.Debugf("è®¢é˜…æ¶ˆæ¯æ¥æ”¶ç»“æŸ: topic=%s, error=%v", topic, err)
							return
						}
						if msg == nil {
							continue
						}
						data := msg.GetData()
						f.logger.Debugf("ğŸ“¨ æ”¶åˆ°gossipsubæ¶ˆæ¯: topic=%s, from=%s, size=%d", topic, msg.ReceivedFrom.String(), len(data))

						// ğŸ›¡ï¸ æ¶ˆæ¯é€Ÿç‡é™åˆ¶æ£€æŸ¥
						peerID := msg.ReceivedFrom.String()
						if f.msgRateLimiter != nil {
							if err := f.msgRateLimiter.CheckMessage(peerID); err != nil {
								f.logger.Warnf("æ¶ˆæ¯é€Ÿç‡é™åˆ¶æ‹’ç»: topic=%s, peer=%s, error=%v", topic, peerID, err)
								continue
							}
						}

						if f.val != nil {
							if ok, reason := f.val.Validate(topic, data); !ok {
								f.logger.With("topic", topic, "reason", reason).Debug("ğŸš« gossipsub message dropped")
								continue
							}
						}

						// è§£ç æ¶ˆæ¯
						if dec != nil {
							if payload, derr := dec.Decode(topic, data); derr == nil {
								f.logger.Debugf("âœ… æ¶ˆæ¯è§£ç æˆåŠŸ: topic=%s, original_size=%d, decoded_size=%d", topic, len(data), len(payload))
								data = payload
							} else {
								f.logger.Warnf("âš ï¸ æ¶ˆæ¯è§£ç å¤±è´¥: topic=%s, error=%v", topic, derr)
							}
						}

						// è°ƒç”¨å¤„ç†å™¨
						f.subMu.RLock()
						handler := f.subs[topic]
						f.subMu.RUnlock()

						if handler != nil {
							if handlerErr := handler(context.Background(), msg.ReceivedFrom, topic, data); handlerErr != nil {
								f.logger.Warnf("è®¢é˜…å¤„ç†å™¨æ‰§è¡Œå¤±è´¥: topic=%s, error=%v", topic, handlerErr)
							}
						} else {
							f.logger.Warnf("æœªæ‰¾åˆ°è®¢é˜…å¤„ç†å™¨: topic=%s", topic)
						}
					}
				}()
				f.logger.Infof("âœ… æˆåŠŸåˆ›å»ºä¸»é¢˜è®¢é˜…: %s", topic)
			} else {
				f.logger.Errorf("âŒ åˆ›å»ºä¸»é¢˜è®¢é˜…å¤±è´¥: %s, error: %v", topic, e)
			}
		}

		f.psMu.Unlock()
	}
}

// runForceConnectRound æ‰§è¡Œä¸€è½®å¯æ§æ‹¨å·ï¼Œç”¨äºâ€œæ‹‰æ´»â€ GossipSub meshï¼ˆä¸šåŠ¡èŠ‚ç‚¹ä¼˜å…ˆ + æŠ½æ ·è¾…åŠ©å…¬ç½‘å‘ç°ï¼‰ã€‚
//
// è®¾è®¡ç›®æ ‡ï¼š
//   - åˆ©ç”¨ host.Peerstore() / host.Network().Peers() ä¸­å·²æœ‰çš„ peer ä¿¡æ¯ï¼Œæ˜¾å¼å‘èµ· Dialï¼›
//   - é¿å…å¯¹è‡ªèº«æˆ–å·²è¿æ¥ peer åå¤æ‹¨å·ï¼›
//   - åœ¨ bootstrap/discovery æœºåˆ¶è¾ƒå¼±çš„å°ç½‘ç»œä¸­ï¼Œå¸®åŠ©èŠ‚ç‚¹å°½å¿«å½¢æˆè¿é€š meshã€‚
func (f *Facade) runForceConnectRound(reason string) {
	if f == nil || f.host == nil {
		return
	}
	f.forceConnectMu.Lock()
	cfg := f.forceConnectCfg
	lastAt := f.forceConnectLastAt
	now := time.Now()
	// cooldown èŠ‚æµ
	if cfg.Enabled && !lastAt.IsZero() && now.Sub(lastAt) < cfg.Cooldown {
		f.forceConnectMu.Unlock()
		if f.logger != nil {
			f.logger.Debugf("forceConnect skipped by cooldown reason=%s since_last=%s cooldown=%s",
				reason, now.Sub(lastAt), cfg.Cooldown)
		}
		return
	}
	// æ ‡è®°æœ¬è½®å¼€å§‹
	f.forceConnectLastAt = now
	f.forceConnectMu.Unlock()

	if !cfg.Enabled {
		if f.logger != nil {
			f.logger.Debugf("forceConnect disabled reason=%s", reason)
		}
		return
	}

	host := f.host
	selfID := host.ID()

	// æ”¶é›† topic peersï¼ˆTier1.5ï¼‰
	topicPeers := make([]peer.ID, 0, 64)
	f.psMu.Lock()
	for _, th := range f.topicHandles {
		if th == nil {
			continue
		}
		topicPeers = append(topicPeers, th.ListPeers()...)
	}
	f.psMu.Unlock()

	// peerstore peersï¼ˆTier2 å€™é€‰æ± ï¼‰
	peerstorePeers := host.Peerstore().Peers()

	targets, tierByPeer, skippedConnected, skippedNoAddr := f.buildForceConnectTargets(selfID, cfg, topicPeers, peerstorePeers)
	if len(targets) == 0 {
		if f.logger != nil {
			f.logger.Debugf("forceConnect no_targets reason=%s skipped_connected=%d skipped_no_addr=%d",
				reason, skippedConnected, skippedNoAddr)
		}
		return
	}

	start := time.Now()
	type result struct {
		ok bool
	}

	workers := cfg.Concurrency
	if workers <= 0 {
		workers = 15
	}
	if workers > len(targets) {
		workers = len(targets)
	}
	jobs := make(chan peer.AddrInfo, len(targets))
	results := make(chan result, len(targets))

	var wg sync.WaitGroup
	for i := 0; i < workers; i++ {
		wg.Add(1)
		go func() {
			defer wg.Done()
			for info := range jobs {
				// äºŒæ¬¡æ£€æŸ¥ï¼šé¿å…é‡å¤æ‹¨å·å·²è¿æ¥ peer
				if info.ID == "" || info.ID == selfID {
					results <- result{ok: false}
					continue
				}
				if host.Network().Connectedness(info.ID) == libnetwork.Connected {
					results <- result{ok: true}
					continue
				}
				ctx, cancel := context.WithTimeout(context.Background(), cfg.Timeout)
				err := host.Connect(ctx, info)
				cancel()
				if err != nil {
					if f.logger != nil {
						tier := tierByPeer[info.ID]
						f.logger.Debugf("forceConnect dial_failed peer=%s tier=%d reason=%s err=%v", info.ID.String(), tier, reason, err)
					}
					results <- result{ok: false}
					continue
				}
				// æˆåŠŸæ—¥å¿—ï¼šä»…ä¸šåŠ¡å…³é”®èŠ‚ç‚¹ï¼ˆTier0ï¼‰ç”¨ Infoï¼Œå…¶ä»– tier ç”¨ Debugï¼Œé¿å…åˆ·å±
				if f.logger != nil {
					tier := tierByPeer[info.ID]
					if tier == 0 {
						f.logger.Infof("forceConnect dial_success peer=%s tier=0 reason=%s", info.ID.String(), reason)
					} else {
						f.logger.Debugf("forceConnect dial_success peer=%s tier=%d reason=%s", info.ID.String(), tier, reason)
					}
				}
				results <- result{ok: true}
			}
		}()
	}

	for _, t := range targets {
		jobs <- t
	}
	close(jobs)
	wg.Wait()
	close(results)

	attempted := len(targets)
	succeeded := 0
	failed := 0
	for r := range results {
		if r.ok {
			succeeded++
		} else {
			failed++
		}
	}

	if f.logger != nil {
		f.logger.Infof("forceConnect round_done reason=%s attempted=%d success=%d failed=%d skipped_connected=%d skipped_no_addr=%d duration=%s",
			reason, attempted, succeeded, failed, skippedConnected, skippedNoAddr, time.Since(start))
	}
}

func (f *Facade) buildForceConnectTargets(
	selfID peer.ID,
	cfg ForceConnectConfig,
	topicPeers []peer.ID,
	peerstorePeers []peer.ID,
) (targets []peer.AddrInfo, tierByPeer map[peer.ID]int, skippedConnected int, skippedNoAddr int) {
	host := f.host

	seen := make(map[peer.ID]struct{}, 256)
	tierByPeer = make(map[peer.ID]int, 256)
	add := func(id peer.ID, tier int) {
		if id == "" || id == selfID {
			return
		}
		if _, ok := seen[id]; ok {
			return
		}
		seen[id] = struct{}{}

		if host.Network().Connectedness(id) == libnetwork.Connected {
			skippedConnected++
			return
		}
		addrs := host.Peerstore().Addrs(id)
		if len(addrs) == 0 {
			skippedNoAddr++
			return
		}
		tierByPeer[id] = tier
		targets = append(targets, peer.AddrInfo{ID: id, Addrs: addrs})
	}

	// Tier0: ä¸šåŠ¡å…³é”®èŠ‚ç‚¹ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
	for _, id := range cfg.BusinessPeers {
		add(id, 0)
		if cfg.BudgetPerRound > 0 && len(targets) >= cfg.BudgetPerRound {
			return targets, tierByPeer, skippedConnected, skippedNoAddr
		}
	}

	// Tier1: bootstrap peers
	for _, id := range cfg.BootstrapPeers {
		add(id, 1)
		if cfg.BudgetPerRound > 0 && len(targets) >= cfg.BudgetPerRound {
			return targets, tierByPeer, skippedConnected, skippedNoAddr
		}
	}

	// Tier1.5: topic peersï¼ˆå…³é”® topic çš„å·²è¿æ¥é›†åˆï¼‰
	for _, id := range topicPeers {
		add(id, 2)
		if cfg.BudgetPerRound > 0 && len(targets) >= cfg.BudgetPerRound {
			return targets, tierByPeer, skippedConnected, skippedNoAddr
		}
	}

	// Tier2: peerstore peers æŠ½æ ·ï¼ˆç”¨äºå…¬ç½‘å‘ç°/meshæ‹‰æ´»ï¼‰
	tier2Budget := cfg.Tier2SampleBudget
	if tier2Budget <= 0 {
		return targets, tierByPeer, skippedConnected, skippedNoAddr
	}
	if cfg.BudgetPerRound > 0 {
		remain := cfg.BudgetPerRound - len(targets)
		if remain <= 0 {
			return targets, tierByPeer, skippedConnected, skippedNoAddr
		}
		if tier2Budget > remain {
			tier2Budget = remain
		}
	}
	// é‡‡æ ·ï¼šæ‰“ä¹± peerstorePeersï¼Œå–å‰ tier2Budget ä¸ª
	cands := make([]peer.ID, 0, len(peerstorePeers))
	for _, id := range peerstorePeers {
		if id == "" || id == selfID {
			continue
		}
		if _, ok := seen[id]; ok {
			continue
		}
		cands = append(cands, id)
	}
	if len(cands) == 0 {
		return targets, tierByPeer, skippedConnected, skippedNoAddr
	}
	// shuffle
	f.forceConnectMu.Lock()
	r := f.forceConnectRand
	f.forceConnectMu.Unlock()
	if r == nil {
		r = rand.New(rand.NewSource(time.Now().UnixNano()))
	}
	r.Shuffle(len(cands), func(i, j int) { cands[i], cands[j] = cands[j], cands[i] })

	for i := 0; i < len(cands) && i < tier2Budget; i++ {
		add(cands[i], 3)
	}

	return targets, tierByPeer, skippedConnected, skippedNoAddr
}

// InitializeGossipSub å…¬å¼€æ–¹æ³•ï¼Œå…è®¸å¤–éƒ¨åœ¨Hostå¯åŠ¨å®Œæˆåä¸»åŠ¨åˆå§‹åŒ–GossipSub
func (f *Facade) InitializeGossipSub() {
	f.logger.Infof("ğŸ”§ InitializeGossipSub called")
	if f.ps == nil {
		f.logger.Infof("ğŸ”§ external trigger: initializing gossipsub")
		f.initGossipSub()
		if f.ps != nil {
			f.logger.Infof("âœ… InitializeGossipSub: gossipsub successfully initialized")
		} else {
			f.logger.Errorf("âŒ InitializeGossipSub: gossipsub initialization failed")
		}
	} else {
		f.logger.Infof("âœ… InitializeGossipSub: gossipsub already initialized, skipping")
	}
}

// ensureGossipSubWithRetry å¸¦é‡è¯•æœºåˆ¶çš„GossipSubåˆå§‹åŒ–
func (f *Facade) ensureGossipSubWithRetry(topic string) {
	if f.ps != nil {
		return // å·²ç»åˆå§‹åŒ–
	}

	f.logger.Infof("gossipsub not initialized for topic %s, attempting with retry", topic)

	// å¯åŠ¨åå°åç¨‹è¿›è¡Œé‡è¯•
	go func() {
		maxRetries := 10
		retryInterval := time.Second * 2

		for i := 0; i < maxRetries; i++ {
			if f.ps != nil {
				f.logger.Infof("gossipsub already initialized during retry for topic %s", topic)
				// æ£€æŸ¥ä¸»é¢˜æ˜¯å¦å·²åŠ å…¥ï¼Œå¦‚æœæ²¡æœ‰åˆ™åŠ å…¥
				f.psMu.Lock()
				if _, ok := f.topicHandles[topic]; !ok {
					if t, e := f.ps.Join(topic); e == nil {
						f.topicHandles[topic] = t
						f.logger.Infof("successfully joined topic %s after gossipsub retry init", topic)
					} else {
						f.logger.Warnf("failed to join topic %s: %v", topic, e)
					}
				} else {
					f.logger.Infof("topic %s already joined", topic)
				}

				// ğŸ”§ ä¿®å¤ï¼šåˆ›å»ºå®é™…çš„æ¶ˆæ¯è®¢é˜…ï¼ˆè¿™æ˜¯å…³é”®çš„ç¼ºå¤±éƒ¨åˆ†ï¼ï¼‰
				if _, exists := f.subHandles[topic]; !exists {
					if sub, e := f.ps.Subscribe(topic); e == nil {
						f.subHandles[topic] = sub
						ctx, cancel := context.WithCancel(context.Background())
						f.subCancels[topic] = cancel
						f.logger.Infof("âœ… åˆ›å»ºæ¶ˆæ¯è®¢é˜…æˆåŠŸ: %s", topic)

						// ğŸ”§ ä¿®å¤ï¼šè®¢é˜…æˆåŠŸåå»¶è¿Ÿå¼ºåˆ¶è¿æ¥peersï¼Œç¡®ä¿å…¶ä»–èŠ‚ç‚¹ä¹Ÿå¯åŠ¨å®Œæˆ
						go func() {
							time.Sleep(10 * time.Second) // ç­‰å¾…å…¶ä»–èŠ‚ç‚¹å¯åŠ¨å®Œæˆ
							f.requestForceConnect("gossipsub_retry_subscribe")
						}()

						// å¯åŠ¨æ¶ˆæ¯å¤„ç†å¾ªç¯
						go func() {
							f.subMu.RLock()
							h := f.subs[topic]
							f.subMu.RUnlock()

							dec := f.dec
							for {
								msg, err := sub.Next(ctx)
								if err != nil {
									f.logger.Debugf("è®¢é˜…æ¶ˆæ¯æ¥æ”¶ç»“æŸ: topic=%s, error=%v", topic, err)
									return
								}
								if msg == nil {
									continue
								}
								data := msg.GetData()
								f.logger.Debugf("ğŸ“¨ æ”¶åˆ°gossipsubæ¶ˆæ¯: topic=%s, from=%s, size=%d", topic, msg.ReceivedFrom.String(), len(data))

								// ğŸ›¡ï¸ æ¶ˆæ¯é€Ÿç‡é™åˆ¶æ£€æŸ¥
								peerID := msg.ReceivedFrom.String()
								if f.msgRateLimiter != nil {
									if err := f.msgRateLimiter.CheckMessage(peerID); err != nil {
										f.logger.Warnf("æ¶ˆæ¯é€Ÿç‡é™åˆ¶æ‹’ç»: topic=%s, peer=%s, error=%v", topic, peerID, err)
										continue
									}
								}

								if f.val != nil {
									if ok, reason := f.val.Validate(topic, data); !ok {
										f.logger.With("topic", topic, "reason", reason).Debug("ğŸš« gossipsub message dropped")
										continue
									}
								}
								if dec != nil {
									if payload, derr := dec.Decode(topic, data); derr == nil {
										data = payload
									}
								}

								if h != nil {
									if handlerErr := h(context.Background(), msg.ReceivedFrom, topic, data); handlerErr != nil {
										f.logger.Warnf("è®¢é˜…å¤„ç†å™¨æ‰§è¡Œå¤±è´¥: topic=%s, error=%v", topic, handlerErr)
									}
								} else {
									f.logger.Warnf("æœªæ‰¾åˆ°è®¢é˜…å¤„ç†å™¨: topic=%s", topic)
								}
							}
						}()
					} else {
						f.logger.Warnf("åˆ›å»ºæ¶ˆæ¯è®¢é˜…å¤±è´¥: topic=%s, error=%v", topic, e)
					}
				}
				f.psMu.Unlock()
				return
			}

			f.logger.Infof("retry %d/%d: attempting gossipsub initialization for topic %s", i+1, maxRetries, topic)
			f.initGossipSub()

			if f.ps != nil {
				f.logger.Infof("gossipsub successfully initialized on retry %d for topic %s", i+1, topic)

				// é‡æ–°å°è¯•è®¢é˜…è¿™ä¸ªä¸»é¢˜
				f.psMu.Lock()
				if _, ok := f.topicHandles[topic]; !ok {
					if t, e := f.ps.Join(topic); e == nil {
						f.topicHandles[topic] = t
						f.logger.Infof("successfully joined topic %s after gossipsub retry init", topic)
					}
				}
				f.psMu.Unlock()
				return
			}

			if i < maxRetries-1 {
				time.Sleep(retryInterval)
			}
		}

		f.logger.Warnf("failed to initialize gossipsub after %d retries for topic %s", maxRetries, topic)
	}()
}

// ==================== åè®®æ³¨å†Œï¼ˆæµå¼ï¼‰ ====================

// RegisterStreamHandler æ³¨å†Œæµå¼åè®®å¤„ç†å™¨
func (f *Facade) RegisterStreamHandler(protoID string, handler iface.MessageHandler, opts ...iface.RegisterOption) error {
	// ğŸ›¡ï¸ è‡ªåŠ¨ä¸ºåè®® ID æ·»åŠ  namespaceï¼ˆå¦‚æœé…ç½®äº† namespaceï¼‰
	qualifiedProtoID := f.qualifyProtocolID(protoID)
	ids := []string{qualifiedProtoID}
	if qualifiedProtoID != protoID {
		// å…¼å®¹æ—§èŠ‚ç‚¹ï¼šåŒæ—¶æ³¨å†ŒæœªåŠ  namespace çš„åŸå§‹åè®® ID
		ids = append(ids, protoID)
	}

	// æ£€æŸ¥é‡å¤æ³¨å†Œ
	f.regMu.Lock()
	for _, id := range ids {
		if f.registeredProtocols[id] {
			f.regMu.Unlock()
			f.logger.With("protocol_id", id).Warn("åè®®å·²æ³¨å†Œï¼Œæ‹’ç»é‡å¤æ³¨å†Œ")
			return fmt.Errorf("åè®® %s å·²æ³¨å†Œï¼Œä¸å…è®¸é‡å¤æ³¨å†Œ", id)
		}
	}
	// æ ‡è®°ä¸ºå·²æ³¨å†Œï¼ˆqualified + originalï¼‰
	for _, id := range ids {
		f.registeredProtocols[id] = true
	}
	f.regMu.Unlock()

	f.logger.With("protocol_id", qualifiedProtoID, "original", protoID).Info("registering stream handler")

	// è§£ææ³¨å†Œé€‰é¡¹
	var cfg iface.RegisterConfig
	for _, o := range opts {
		if o != nil {
			o(&cfg)
		}
	}
	f.subMu.Lock()
	for _, id := range ids {
		f.regCF[id] = cfg
	}
	f.subMu.Unlock()

	// å¹¶å‘/èƒŒå‹ï¼šæŒ‰ç…§æ¯åè®®ä¿¡å·é‡é™åˆ¶
	if cfg.MaxConcurrency > 0 {
		f.streamSvc.SetConcurrencyLimit(cfg.MaxConcurrency)
	}
	sem := f.streamSvc.GetSemaphore()
	wrap := regimpl.NewHandlerWrapper()
	// å¯é€‰é»˜è®¤è¶…æ—¶ï¼šæŒ‰éœ€å¯ç”¨ï¼ˆæ­¤å¤„ä¿æŒ0ï¼Œå¾…é…ç½®æ¥å…¥ï¼‰

	// åè®®æ³¨å†Œä¸ºä½é¢‘æ“ä½œï¼Œä¿ç•™ä¸€æ¡ Info æ—¥å¿—ï¼›ä½†ä¸å†æ‰“å‡ºâ€œTRACEâ€å­—æ ·ï¼Œé¿å…ä¸çº§åˆ«è¯­ä¹‰æ··æ·†ã€‚
	f.logger.Infof("æ³¨å†Œåè®®å¤„ç†å™¨: %s", string(qualifiedProtoID))

	registerOne := func(bindProtoID string) {
		if f.reg != nil {
			f.logger.Debugf("æ³¨å†Œåˆ°å†…éƒ¨æ³¨å†Œè¡¨: %s", string(bindProtoID))
			if err := f.reg.Register(bindProtoID, wrap.Wrap(handler)); err != nil {
				f.logger.Warnf("æ³¨å†Œåè®®åˆ°å†…éƒ¨æ³¨å†Œè¡¨å¤±è´¥: %v", err)
			}
		}
		// å…¥ç«™æ¡¥æ¥ï¼šè¯»å–ä¸€å¸§è¯·æ±‚ï¼Œè°ƒç”¨ handlerï¼Œå›å†™ä¸€å¸§å“åº”
		f.host.SetStreamHandler(libprotocol.ID(bindProtoID), func(s libnetwork.Stream) {
			remote := s.Conn().RemotePeer()
			ctx := context.Background()
			f.logger.With("protocol_id", bindProtoID, "remote_peer", remote.String()).Debug("handling inbound stream")

			// ğŸ›¡ï¸ è¿æ¥é€Ÿç‡é™åˆ¶æ£€æŸ¥
			peerIDStr := remote.String()
			if f.rateLimiter != nil {
				// ä½¿ç”¨ peerID ä½œä¸º"IP"æ ‡è¯†ï¼ˆç®€åŒ–å®ç°ï¼Œå®é™…å¯ä» multiaddr æå–çœŸå®IPï¼‰
				if err := f.rateLimiter.CheckConnection(peerIDStr, peerIDStr); err != nil {
					f.logger.Warnf("è¿æ¥é€Ÿç‡é™åˆ¶æ‹’ç»: protocol=%s, peer=%s, error=%v", bindProtoID, peerIDStr, err)
					if err := s.Reset(); err != nil {
						f.logger.Warnf("é‡ç½®æµå¤±è´¥: %v", err)
					}
					return
				}
				defer f.rateLimiter.RemoveConnection(peerIDStr, peerIDStr)
			}

			// èƒŒå‹ï¼šå°è¯•è·å–ä¿¡å·é‡
			if sem != nil {
				if err := sem.Acquire(ctx); err != nil {
					f.logger.With("protocol_id", protoID, "remote_peer", remote.String(), "error", err.Error()).Warn("backpressure acquire failed")
					if err := s.Reset(); err != nil {
						f.logger.Warnf("é‡ç½®æµå¤±è´¥: %v", err)
					}
					return
				}
				defer sem.Release()
			}

			// è¯»å–è¯·æ±‚å¸§
			ft, payload, err := stcodec.DecodeFrame(s)
			if err != nil {
				f.logger.With("protocol_id", protoID, "remote_peer", remote.String(), "error", err.Error()).Warn("decode frame failed")
				if err := s.Reset(); err != nil {
					f.logger.Warnf("é‡ç½®æµå¤±è´¥: %v", err)
				}
				return
			}
			_ = ft // åè®®å±‚å¯æ ¹æ®ç±»å‹åŒºåˆ†è¯·æ±‚/å¿ƒè·³ï¼Œè¿™é‡Œç®€å•å¿½ç•¥

			// è§£æ RpcRequest å¹¶æå– payload
			var reqPB transportpb.RpcRequest
			if uErr := proto.Unmarshal(payload, &reqPB); uErr != nil {
				f.logger.With("protocol_id", protoID, "error", uErr.Error()).Warn("rpc request unmarshal failed")
				if err := s.Reset(); err != nil {
					f.logger.Warnf("é‡ç½®æµå¤±è´¥: %v", err)
				}
				return
			}
			appReq := reqPB.GetEnvelope().GetPayload()
			// é…ç½®çš„å¤§å°é™åˆ¶ï¼ˆè‹¥è®¾ç½®ï¼‰
			if f.cfg != nil && f.cfg.GetMaxMessageSize() > 0 {
				if int64(len(appReq)) > f.cfg.GetMaxMessageSize() {
					f.logger.With("protocol_id", protoID, "size", len(appReq), "max", f.cfg.GetMaxMessageSize()).Warn("inbound payload too large")
					if err := s.Reset(); err != nil {
						f.logger.Warnf("é‡ç½®æµå¤±è´¥: %v", err)
					}
					return
				}
			}

			// è°ƒç”¨å¤„ç†å™¨ï¼ˆä½¿ç”¨åŒ…è£…å™¨å¢å¼ºå¥å£®æ€§ï¼‰
			respData, handlerErr := wrap.Wrap(handler)(ctx, remote, appReq)

			// æ„å»º RpcResponse
		respPB := &transportpb.RpcResponse{RequestId: reqPB.GetRequestId()}
		if handlerErr != nil {
			respPB.Status = transportpb.RpcResponse_ERROR
			respPB.ErrorCode = 1 // ç¤ºä¾‹é”™è¯¯ç 
			respPB.ErrorMessage = handlerErr.Error()
		} else {
			respPB.Status = transportpb.RpcResponse_OK
			respPB.Envelope = &transportpb.Envelope{Version: 1, ProtocolId: protoID, Payload: respData, Encoding: "raw", Compression: "none"}
		}

		// åºåˆ—åŒ–å¹¶å›å†™å“åº”å¸§
		bytesOut, mErr := proto.Marshal(respPB)
		if mErr != nil {
			f.logger.With("protocol_id", protoID, "error", mErr.Error()).Warn("rpc response marshal failed")
			if err := s.Reset(); err != nil {
				f.logger.Warnf("é‡ç½®æµå¤±è´¥: %v", err)
			}
			return
		}
		if encErr := stcodec.EncodeFrame(s, stcodec.FrameTypeResponse, bytesOut); encErr != nil {
			f.logger.With("protocol_id", protoID, "remote_peer", remote.String(), "error", encErr.Error()).Warn("encode response failed")
		}
		if err := s.Close(); err != nil {
			f.logger.Warnf("å…³é—­æµå¤±è´¥: %v", err)
		}
		})
	}

	for _, id := range ids {
		registerOne(id)
	}

	f.logger.With("protocol_id", protoID).Info("stream handler registered successfully")
	return nil
}

// UnregisterStreamHandler æ³¨é”€æµå¼åè®®å¤„ç†å™¨
func (f *Facade) UnregisterStreamHandler(protoID string) error {
	qualifiedProtoID := f.qualifyProtocolID(protoID)
	ids := []string{qualifiedProtoID}
	if qualifiedProtoID != protoID {
		ids = append(ids, protoID)
	}

	// æ¸…ç†æ³¨å†ŒçŠ¶æ€
	f.regMu.Lock()
	for _, id := range ids {
		delete(f.registeredProtocols, id)
	}
	f.regMu.Unlock()

	if f.reg != nil {
		for _, id := range ids {
			if err := f.reg.Unregister(id); err != nil {
				f.logger.Warnf("æ³¨é”€åè®®æ³¨å†Œå¤±è´¥: %v", err)
			}
		}
	}
	f.subMu.Lock()
	for _, id := range ids {
		delete(f.regCF, id)
	}
	f.subMu.Unlock()
	for _, id := range ids {
		f.host.RemoveStreamHandler(libprotocol.ID(id))
	}

	f.logger.With("protocol_id", protoID).Info("unregistered stream handler")
	return nil
}

// ==================== è®¢é˜…æ³¨å†Œï¼ˆPubSubï¼‰ ====================

// Subscribe è®¢é˜…æŒ‡å®šä¸»é¢˜
func (f *Facade) Subscribe(topic string, handler iface.SubscribeHandler, opts ...iface.SubscribeOption) (unsubscribe func() error, err error) {
	// ğŸ›¡ï¸ è‡ªåŠ¨ä¸º Topic æ·»åŠ  namespaceï¼ˆå¦‚æœé…ç½®äº† namespaceï¼‰
	qualifiedTopic := f.qualifyTopic(topic)

	// æ£€æŸ¥é‡å¤è®¢é˜…
	f.regMu.Lock()
	if f.registeredTopics[qualifiedTopic] {
		f.regMu.Unlock()
		f.logger.With("topic", qualifiedTopic).Warn("ä¸»é¢˜å·²è®¢é˜…ï¼Œæ‹’ç»é‡å¤è®¢é˜…")
		return nil, fmt.Errorf("ä¸»é¢˜ %s å·²è®¢é˜…ï¼Œä¸å…è®¸é‡å¤è®¢é˜…", qualifiedTopic)
	}
	// æ ‡è®°ä¸ºå·²è®¢é˜…
	f.registeredTopics[qualifiedTopic] = true
	f.regMu.Unlock()

	f.logger.With("topic", qualifiedTopic, "original", topic).Info("subscribing to topic")

	// è§£æè®¢é˜…é€‰é¡¹
	var cfg iface.SubscribeConfig
	for _, o := range opts {
		if o != nil {
			o(&cfg)
		}
	}
	// ä»å…¨å±€é…ç½®è¡¥å……é»˜è®¤é™åˆ¶
	if f.cfg != nil {
		if cfg.MaxMessageSize <= 0 && f.cfg.GetMaxMessageSize() > 0 {
			cfg.MaxMessageSize = int(f.cfg.GetMaxMessageSize())
		}
	}
	f.subMu.Lock()
	f.subCF[qualifiedTopic] = cfg
	f.subs[qualifiedTopic] = handler
	f.subMu.Unlock()

	// é…ç½® validator è§„åˆ™ï¼ˆå¤§å°/ç­¾å/é¢‘ç‡/å»é‡ï¼‰
	if f.val != nil {
		rateLimit := 100 // é»˜è®¤é€Ÿç‡
		if cfg.EnableRateLimit {
			rateLimit = 100 // å¯æ ¹æ®éœ€è¦è°ƒæ•´
		}
		dedupTTL := time.Minute
		if f.cfg != nil && f.cfg.GetDeduplicationCacheTTL() > 0 {
			dedupTTL = time.Duration(f.cfg.GetDeduplicationCacheTTL()) * time.Second
		}

		f.val.ConfigureTopic(qualifiedTopic, pubimpl.TopicRules{
			MaxMessageSize:   cfg.MaxMessageSize,
			RequireSignature: cfg.EnableSignatureVerification,
			RatePerSec:       rateLimit,
			DedupTTL:         dedupTTL,
		})

		f.logger.With(
			"topic", qualifiedTopic,
			"max_size", cfg.MaxMessageSize,
			"require_signature", cfg.EnableSignatureVerification,
			"rate_limit", cfg.EnableRateLimit,
		).Debug("validator configured")
	}

	// æ³¨å†Œåˆ° TopicManager
	if f.tm != nil {
		if tmErr := f.tm.Subscribe(qualifiedTopic); tmErr != nil {
			f.logger.With("topic", qualifiedTopic, "error", tmErr.Error()).Warn("topic manager subscription failed")
		}
	}

	// ğŸ”§ ä¿®å¤ï¼šç¡®ä¿ GossipSub å·²åˆå§‹åŒ–
	f.ensureGossipSub()

	// å»ºç«‹ GossipSub è®¢é˜…
	if f.ps == nil {
		f.logger.Infof("gossipsub not ready, host may not be started yet")
		goto DONE
	}

	if f.ps != nil {
		f.psMu.Lock()

		// ç¡®ä¿ä¸»é¢˜å·²åŠ å…¥ï¼ˆå¯èƒ½åœ¨retryä¸­å·²ç»åŠ å…¥ï¼‰
		if _, ok := f.topicHandles[qualifiedTopic]; !ok {
			if t, e := f.ps.Join(qualifiedTopic); e == nil {
				f.topicHandles[qualifiedTopic] = t
				f.logger.Infof("âœ… æˆåŠŸåŠ å…¥ä¸»é¢˜: %s", qualifiedTopic)
			} else {
				f.psMu.Unlock()
				f.logger.With("topic", qualifiedTopic, "error", e.Error()).Warn("gossipsub join failed")
				goto DONE
			}
		}

		// ğŸ”§ ä¿®å¤ï¼šå³ä½¿ä¸»é¢˜å·²å­˜åœ¨ï¼Œä¹Ÿè¦åˆ›å»ºè®¢é˜…ï¼ˆå¦‚æœè¿˜æ²¡æœ‰è®¢é˜…ï¼‰
		if _, exists := f.subHandles[qualifiedTopic]; !exists {
			if sub, e := f.ps.Subscribe(qualifiedTopic); e == nil {
				f.subHandles[qualifiedTopic] = sub
				ctx, cancel := context.WithCancel(context.Background())
				f.subCancels[qualifiedTopic] = cancel
				f.psMu.Unlock()

				f.logger.Infof("âœ… ä¸»æµç¨‹åˆ›å»ºæ¶ˆæ¯è®¢é˜…æˆåŠŸ: %s", qualifiedTopic)

				// ğŸ”§ ä¿®å¤ï¼šè®¢é˜…æˆåŠŸåå»¶è¿Ÿå¼ºåˆ¶è¿æ¥peersï¼Œç¡®ä¿å…¶ä»–èŠ‚ç‚¹ä¹Ÿå¯åŠ¨å®Œæˆ
				go func() {
					time.Sleep(10 * time.Second) // ç­‰å¾…å…¶ä»–èŠ‚ç‚¹å¯åŠ¨å®Œæˆ
					f.requestForceConnect("gossipsub_subscribe")
				}()

				go func() {
					// ä½¿ç”¨å¸¦ namespace çš„å®Œæ•´ä¸»é¢˜åç§°è¿›è¡Œè§£ç ä¸æ ¡éªŒï¼Œé¿å… Envelope.Topic ä¸é€»è¾‘ä¸»é¢˜ä¸ä¸€è‡´
					dec := f.dec
					for {
						msg, err := sub.Next(ctx)
						if err != nil {
							f.logger.Debugf("è®¢é˜…æ¶ˆæ¯æ¥æ”¶ç»“æŸ: topic=%s, error=%v", topic, err)
							return
						}
						if msg == nil {
							continue
						}
						data := msg.GetData()
						f.logger.Debugf("ğŸ“¨ æ”¶åˆ°gossipsubæ¶ˆæ¯: topic=%s, from=%s, size=%d", topic, msg.ReceivedFrom.String(), len(data))

						// ğŸ›¡ï¸ æ¶ˆæ¯é€Ÿç‡é™åˆ¶æ£€æŸ¥
						peerID := msg.ReceivedFrom.String()
						if f.msgRateLimiter != nil {
							if err := f.msgRateLimiter.CheckMessage(peerID); err != nil {
								f.logger.Warnf("æ¶ˆæ¯é€Ÿç‡é™åˆ¶æ‹’ç»: topic=%s, peer=%s, error=%v", qualifiedTopic, peerID, err)
								continue
							}
						}

						if f.val != nil {
							// ä½¿ç”¨ qualifiedTopic è¿›è¡Œæ ¡éªŒï¼Œä¿æŒä¸é…ç½®çš„ Topic è§„åˆ™ä¸€è‡´
							if ok, reason := f.val.Validate(qualifiedTopic, data); !ok {
								f.logger.With("topic", qualifiedTopic, "reason", reason).Debug("ğŸš« gossipsub message dropped")
								continue
							} else {
								f.logger.With("topic", qualifiedTopic).Debug("âœ… gossipsub message validated")
							}
						}
						if dec != nil {
							// ğŸ¯ ä½¿ç”¨ DecodeTopic è§£ç ç»“æ„åŒ– Topic
							decodedTopic, payload, derr := dec.DecodeTopic(data)
							if derr == nil {
								f.logger.Debugf("âœ… æ¶ˆæ¯è§£ç æˆåŠŸ: decoded_topic=%s, original_size=%d, decoded_size=%d", decodedTopic.String(), len(data), len(payload))
								data = payload
								// æ ¡éªŒè§£ç åçš„ topic æ˜¯å¦ä¸æœŸæœ›çš„ qualifiedTopic åŒ¹é…
								expectedTopic := parseLegacyTopicString(qualifiedTopic)
								if decodedTopic.Domain != expectedTopic.Domain ||
									decodedTopic.Name != expectedTopic.Name ||
									decodedTopic.Version != expectedTopic.Version {
									f.logger.Warnf("âš ï¸ topic mismatch: decoded=%s, expect=%s", decodedTopic.String(), qualifiedTopic)
									continue
								}
							} else {
								f.logger.Warnf("âš ï¸ æ¶ˆæ¯è§£ç å¤±è´¥: topic=%s, error=%v", qualifiedTopic, derr)
								continue
							}
						}
						f.subMu.RLock()
						h := f.subs[qualifiedTopic]
						f.subMu.RUnlock()
						if h != nil {
							if handlerErr := h(context.Background(), msg.ReceivedFrom, qualifiedTopic, data); handlerErr != nil {
								f.logger.Warnf("è®¢é˜…å¤„ç†å™¨æ‰§è¡Œå¤±è´¥: topic=%s, error=%v", qualifiedTopic, handlerErr)
							}
						} else {
							f.logger.Warnf("æœªæ‰¾åˆ°è®¢é˜…å¤„ç†å™¨: topic=%s", topic)
						}
					}
				}()
			} else {
				f.psMu.Unlock()
				f.logger.With("topic", topic, "error", e.Error()).Warn("gossipsub subscribe failed")
				goto DONE
			}
		} else {
			f.psMu.Unlock()
			f.logger.Infof("topic %s subscription already exists", topic)
		}
	}
DONE:
	f.logger.With("topic", topic).Info("subscription successful")

	return func() error {
		// è¿™é‡Œå¿…é¡»ä¸ Subscribe æ—¶ä½¿ç”¨çš„ key å®Œå…¨ä¸€è‡´ï¼Œç»Ÿä¸€ä½¿ç”¨ qualifiedTopic
		f.logger.With("topic", qualifiedTopic, "original", topic).Info("unsubscribing from topic")

		if f.tm != nil {
			if tmErr := f.tm.Unsubscribe(qualifiedTopic); tmErr != nil {
				f.logger.With("topic", qualifiedTopic, "error", tmErr.Error()).Warn("topic manager unsubscription failed")
			}
		}

		// å–æ¶ˆ GossipSub è®¢é˜…
		f.psMu.Lock()
		if cancel, ok := f.subCancels[qualifiedTopic]; ok && cancel != nil {
			cancel()
		}
		if sub, ok := f.subHandles[qualifiedTopic]; ok && sub != nil {
			sub.Cancel()
		}
		delete(f.subCancels, qualifiedTopic)
		delete(f.subHandles, qualifiedTopic)
		if t, ok := f.topicHandles[qualifiedTopic]; ok && t != nil {
			if err := t.Close(); err != nil {
				f.logger.Warnf("å…³é—­ä¸»é¢˜å¥æŸ„å¤±è´¥: %v", err)
			}
			delete(f.topicHandles, qualifiedTopic)
		}
		f.psMu.Unlock()

		// æ¸…ç†æ³¨å†ŒçŠ¶æ€
		f.regMu.Lock()
		delete(f.registeredTopics, qualifiedTopic)
		f.regMu.Unlock()

		// æ¸…ç†æœ¬åœ°çŠ¶æ€
		f.subMu.Lock()
		delete(f.subs, qualifiedTopic)
		delete(f.subCF, qualifiedTopic)
		f.subMu.Unlock()

		// æ¸…ç†validatorè§„åˆ™
		if f.val != nil {
			f.val.RemoveTopic(qualifiedTopic)
		}

		f.logger.With("topic", qualifiedTopic, "original", topic).Info("unsubscription completed")
		return nil
	}, nil
}

// ==================== å‘é€ API ====================

// Call æµå¼è¯·æ±‚-å“åº”ï¼ˆç‚¹å¯¹ç‚¹ï¼‰
func (f *Facade) Call(ctx context.Context, to peer.ID, protoID string, req []byte, opts *iface.TransportOptions) ([]byte, error) {
	// ğŸ›¡ï¸ è‡ªåŠ¨ä¸ºåè®® ID æ·»åŠ  namespaceï¼ˆå¦‚æœé…ç½®äº† namespaceï¼‰
	qualifiedProtoID := f.qualifyProtocolID(protoID)
	f.callCount++
	
	// ğŸ†• MEDIUM-002 ä¿®å¤ï¼šä½¿ç”¨åè®®åå•†å™¨é€‰æ‹©æœ€ä¼˜åè®®
	var selectedProto string
	var usedQualified, needFallbackAttempt bool
	if f.protocolNegotiator != nil {
		selectedProto, usedQualified, needFallbackAttempt = f.protocolNegotiator.SelectProtocol(to, protoID, qualifiedProtoID)
	} else {
		selectedProto = qualifiedProtoID
		usedQualified = qualifiedProtoID != protoID
		needFallbackAttempt = usedQualified
	}

	f.logger.Infof("starting call: protocol_id=%s selected=%s target_peer=%s request_size=%d", 
		qualifiedProtoID, selectedProto, to.String(), len(req))
	// é…ç½®å¤§å°é™åˆ¶
	if f.cfg != nil && f.cfg.GetMaxMessageSize() > 0 {
		if int64(len(req)) > f.cfg.GetMaxMessageSize() {
			return nil, fmt.Errorf("request too large: %d > %d", len(req), f.cfg.GetMaxMessageSize())
		}
	}
	resolved := stcodec.ResolveTransportOptions(opts)
	maxRetries, connectTO, writeTO, readTO := resolved.MaxRetries, resolved.ConnectTimeout, resolved.WriteTimeout, resolved.ReadTimeout
	retryDelay, backoff := resolved.RetryDelay, resolved.BackoffFactor
	attempt := 0
	requestID := time.Now().Format("20060102T150405.000000000")
	hadFallback := false
	for {
		if attempt > 0 {
			f.retryCount++
			f.logger.With("protocol_id", protoID, "target_peer", to.String(), "attempt", attempt).Warn("retrying call")
		}
		// è¿æ¥/å»ºæµé˜¶æ®µä½¿ç”¨ connectTOï¼ˆå¦‚æœæä¾›ï¼‰ï¼Œé¿å…"ä¸Šå±‚ ctx æ—  deadline æ—¶æ— é™ç­‰å¾…"
		connectCtx := ctx
		var connectCancel context.CancelFunc = func() {}
		if connectTO > 0 {
			connectCtx, connectCancel = context.WithTimeout(ctx, connectTO)
		}

		// ç¡®ä¿è¿æ¥
		netw := f.host.Network()
		if netw != nil && netw.Connectedness(to) != libnetwork.Connected {
			if _, err := netw.DialPeer(connectCtx, to); err != nil {
				f.logger.Warnf("ç¡®ä¿è¿æ¥å¤±è´¥: %v", err)
			}
		}
		
		// ğŸ†• ä½¿ç”¨é€‰å®šçš„åè®®
		stream, err := f.host.NewStream(connectCtx, to, libprotocol.ID(selectedProto))
		if err != nil && needFallbackAttempt && selectedProto != protoID {
			// å…¼å®¹æ—§èŠ‚ç‚¹ï¼šå¯¹ç«¯å¯èƒ½åªæ”¯æŒæœªåŠ  namespace çš„åŸå§‹åè®® ID
			f.logger.With(
				"protocol_id", selectedProto,
				"original", protoID,
				"target_peer", to.String(),
				"error", err.Error(),
			).Warn("qualified protocol not supported by peer, falling back to original protocol id")
			stream, err = f.host.NewStream(connectCtx, to, libprotocol.ID(protoID))
			if err == nil {
				hadFallback = true
				usedQualified = false
			}
		}
		// é‡Šæ”¾ connectTO å®šæ—¶å™¨èµ„æºï¼ˆå»ºæµæˆåŠŸ/å¤±è´¥éƒ½åº”é‡Šæ”¾ï¼‰
		connectCancel()
		if err != nil {
			if attempt < maxRetries {
				sleep := computeBackoff(retryDelay, backoff, attempt)
				select {
				case <-time.After(sleep):
					attempt++
					continue
				case <-ctx.Done():
					return nil, ctx.Err()
				}
			}
			return nil, err
		}
		// Build RpcRequest with Envelope (pbä¼˜å…ˆåŸåˆ™)
		env := &transportpb.Envelope{
			Version:       1,
			ProtocolId:    protoID,
			Payload:       req,
			Encoding:      "pb", // æ˜ç¡®ä½¿ç”¨protobuf
			Compression:   "none",
			CorrelationId: requestID,
			ContentType:   "application/x-protobuf", // pbå†…å®¹ç±»å‹
			Timestamp:     uint64(time.Now().UnixMilli()),
		}
		reqPB := &transportpb.RpcRequest{RequestId: requestID, Envelope: env}
		bytesIn, mErr := proto.Marshal(reqPB)
		if mErr != nil {
			if err := stream.Close(); err != nil {
				f.logger.Warnf("å…³é—­æµå¤±è´¥: %v", err)
			}
			return nil, mErr
		}
		if writeTO > 0 {
			if err := stream.SetDeadline(time.Now().Add(writeTO)); err != nil {
				f.logger.Warnf("è®¾ç½®å†™å…¥è¶…æ—¶å¤±è´¥: %v", err)
			}
		}
		if err := stcodec.EncodeFrame(stream, stcodec.FrameTypeRequest, bytesIn); err != nil {
			if err := stream.Close(); err != nil {
				f.logger.Warnf("å…³é—­æµå¤±è´¥: %v", err)
			}
			if attempt < maxRetries {
				sleep := computeBackoff(retryDelay, backoff, attempt)
				select {
				case <-time.After(sleep):
					attempt++
					continue
				case <-ctx.Done():
					return nil, ctx.Err()
				}
			}
			return nil, err
		}
		if err := stream.CloseWrite(); err != nil {
			f.logger.Warnf("å…³é—­å†™å…¥æµå¤±è´¥: %v", err)
		}
		if readTO > 0 {
			if err := stream.SetDeadline(time.Now().Add(readTO)); err != nil {
				f.logger.Warnf("è®¾ç½®è¯»å–è¶…æ—¶å¤±è´¥: %v", err)
			}
		}
		_, payload, rerr := stcodec.DecodeFrame(stream)
		if err := stream.Close(); err != nil {
			f.logger.Warnf("å…³é—­æµå¤±è´¥: %v", err)
		}
		if rerr != nil {
			if attempt < maxRetries {
				sleep := computeBackoff(retryDelay, backoff, attempt)
				select {
				case <-time.After(sleep):
					attempt++
					continue
				case <-ctx.Done():
					return nil, ctx.Err()
				}
			}
			return nil, rerr
		}
		var respPB transportpb.RpcResponse
		if uErr := proto.Unmarshal(payload, &respPB); uErr != nil {
			if attempt < maxRetries {
				sleep := computeBackoff(retryDelay, backoff, attempt)
				select {
				case <-time.After(sleep):
					attempt++
					continue
				case <-ctx.Done():
					return nil, ctx.Err()
				}
			}
			return nil, uErr
		}
		if respPB.GetStatus() != transportpb.RpcResponse_OK {
			return nil, fmt.Errorf("rpc error: code=%d msg=%s", respPB.GetErrorCode(), respPB.GetErrorMessage())
		}
		if env := respPB.GetEnvelope(); env != nil {
			// ğŸ†• MEDIUM-002 ä¿®å¤ï¼šè®°å½•åè®®åå•†ç»“æœ
			if f.protocolNegotiator != nil {
				f.protocolNegotiator.RecordResult(to, usedQualified, hadFallback)
			}
			f.logger.Infof("call completed successfully: protocol_id=%s target_peer=%s response_size=%d attempts=%d fallback=%v", 
				protoID, to.String(), len(env.GetPayload()), attempt+1, hadFallback)
			return env.GetPayload(), nil
		}
		return nil, fmt.Errorf("empty rpc response envelope")
	}
}

// OpenStream æ‰“å¼€é•¿æµï¼ˆç”¨äºå¤§ä½“é‡æ•°æ®ä¼ è¾“ç­‰å°‘é‡åœºæ™¯ï¼‰
func (f *Facade) OpenStream(ctx context.Context, to peer.ID, protoID string, opts *iface.TransportOptions) (iface.StreamHandle, error) {
	// ç¡®ä¿è¿æ¥
	netw := f.host.Network()
	if netw != nil && netw.Connectedness(to) != libnetwork.Connected {
		if _, err := netw.DialPeer(ctx, to); err != nil {
			f.logger.Warnf("ç¡®ä¿è¿æ¥å¤±è´¥: %v", err)
		}
	}
	rs, err := f.host.NewStream(ctx, to, libprotocol.ID(protoID))
	if err != nil {
		return nil, err
	}
	return &streamHandleAdapter{stream: rs}, nil
}

// Publish å‘å¸ƒæ¶ˆæ¯åˆ°æŒ‡å®šä¸»é¢˜ï¼ˆå‘å¸ƒ-è®¢é˜…ï¼‰
func (f *Facade) Publish(ctx context.Context, topic string, data []byte, opts *iface.PublishOptions) error {
	// ğŸ›¡ï¸ è‡ªåŠ¨ä¸º Topic æ·»åŠ  namespaceï¼ˆå¦‚æœé…ç½®äº† namespaceï¼‰
	qualifiedTopic := f.qualifyTopic(topic)
	f.logger.With("topic", qualifiedTopic, "original", topic, "message_size", len(data)).Info("publishing message")
	// é»˜è®¤å¤§å°é™åˆ¶ï¼ˆé…ç½®ï¼‰
	limit := 0
	if opts != nil && opts.MaxMessageSize > 0 {
		limit = opts.MaxMessageSize
	} else if f.cfg != nil && f.cfg.GetMaxMessageSize() > 0 {
		limit = int(f.cfg.GetMaxMessageSize())
	}
	if limit > 0 && len(data) > limit {
		f.dropCount++
		f.logger.With("topic", qualifiedTopic, "message_size", len(data), "max_size", limit).Warn("message too large")
		return nil
	}
	payload := data
	shouldMarkCompressed := false
	// ç®€åŒ–å‹ç¼©é€»è¾‘ï¼ŒåŸºäºæ¶ˆæ¯å¤§å°åˆ¤æ–­
	if f.cfg != nil && int64(len(payload)) > f.cfg.GetMaxMessageSize()/4 {
		shouldMarkCompressed = true
	}
	if opts != nil && opts.CompressionEnabled && opts.MaxMessageSize > 0 && len(payload) > opts.MaxMessageSize {
		shouldMarkCompressed = true
	}
	// ç›´æ¥ä½¿ç”¨ Encoder è¿›è¡Œ Envelope å°è£…ä¸ç¼–ç 
	enc, encErr := f.enc.Encode(qualifiedTopic, payload)
	if encErr != nil {
		f.logger.With("topic", qualifiedTopic, "error", encErr.Error()).Warn("encoding failed")
		return encErr
	}
	// é…ç½®è¦æ±‚å‹ç¼©æ—¶ï¼Œä»…æ ‡è®° compression=gzipï¼ˆå…ˆä¸æ”¹å˜ payloadï¼‰
	if shouldMarkCompressed {
		var env transportpb.Envelope
		if err := proto.Unmarshal(enc, &env); err == nil {
			env.Compression = "gzip"
			if b, mErr := proto.Marshal(&env); mErr == nil {
				enc = b
			}
		}
	}
	if f.val != nil {
		ok, reason := f.val.Validate(qualifiedTopic, enc)
		if !ok {
			f.dropCount++
			f.logger.With("topic", qualifiedTopic, "reason", reason).Warn("validation failed")
			return nil
		}
	}

	// ç¡®ä¿ GossipSub å·²åˆå§‹åŒ–
	f.ensureGossipSub()

	// GossipSub å¹¿æ’­
	if f.ps != nil {
		// æ·»åŠ è¯Šæ–­ä¿¡æ¯ï¼šæ£€æŸ¥ä¸»é¢˜è¿æ¥çš„peers
		peers := f.ps.ListPeers(qualifiedTopic)
		f.logger.Infof("ğŸ” å‡†å¤‡å‘å¸ƒåˆ°ä¸»é¢˜ %s, è¿æ¥çš„peersæ•°é‡: %d", qualifiedTopic, len(peers))
		if len(peers) > 0 {
			f.logger.Infof("ğŸ“¡ ä¸»é¢˜ %s è¿æ¥çš„peers: %v", qualifiedTopic, peers)
		} else {
			f.logger.Warnf("âš ï¸ ä¸»é¢˜ %s æ²¡æœ‰è¿æ¥çš„peers! æ¶ˆæ¯å¯èƒ½æ— æ³•ä¼ é€’ç»™å…¶ä»–èŠ‚ç‚¹", qualifiedTopic)
		}

		f.psMu.Lock()
		if t, ok := f.topicHandles[qualifiedTopic]; ok && t != nil {
			f.psMu.Unlock()
			if err := t.Publish(ctx, enc); err != nil {
				f.logger.With("topic", qualifiedTopic, "error", err.Error()).Warn("gossipsub publish failed")
			}
		} else {
			f.psMu.Unlock()
			if err := f.ps.Publish(qualifiedTopic, enc); err != nil {
				f.logger.With("topic", qualifiedTopic, "error", err.Error()).Warn("gossipsub direct publish failed")
			}
		}
	}
	// æœ¬åœ°ç»Ÿè®¡ä¸å›ç¯é€šçŸ¥
	if f.pub != nil {
		if err := f.pub.Publish(qualifiedTopic, enc); err != nil {
			f.logger.Warnf("å‘å¸ƒæ¶ˆæ¯å¤±è´¥: %v", err)
		}
	}
	f.subMu.RLock()
	h := f.subs[qualifiedTopic]
	f.subMu.RUnlock()
	if h != nil {
		// ğŸ”§ ä¿®å¤ï¼šæ£€æŸ¥æ˜¯å¦ä¸ºå•èŠ‚ç‚¹ç¯å¢ƒï¼Œå†³å®šæ˜¯å¦æ‰§è¡Œæœ¬åœ°å›ç¯å¤„ç†
		peers := f.ps.ListPeers(qualifiedTopic)
		if len(peers) <= 1 {
			// å•èŠ‚ç‚¹ç¯å¢ƒï¼šæ‰§è¡Œæœ¬åœ°å›ç¯å¤„ç†ï¼Œç”¨äºå•èŠ‚ç‚¹æµ‹è¯•
			f.logger.Debugf("å•èŠ‚ç‚¹ç¯å¢ƒï¼Œæ‰§è¡Œæœ¬åœ°å›ç¯å¤„ç†: topic=%s, peers=%d", qualifiedTopic, len(peers))

			// ğŸ”§ ä¿®å¤ï¼šæœ¬åœ°å›ç¯æ—¶éœ€è¦å…ˆè§£ç æ•°æ®ï¼Œé¿å…protobufè§£æé”™è¯¯
			decodedPayload, decErr := f.dec.Decode(qualifiedTopic, enc)
			if decErr != nil {
				f.logger.With("topic", qualifiedTopic, "error", decErr.Error()).Warn("local handler decode failed")
			} else {
				if localErr := h(ctx, peer.ID(""), qualifiedTopic, decodedPayload); localErr != nil {
					f.logger.With("topic", qualifiedTopic, "error", localErr.Error()).Warn("local handler failed")
				}
			}
		} else {
			// å¤šèŠ‚ç‚¹ç¯å¢ƒï¼šè·³è¿‡æœ¬åœ°å›ç¯å¤„ç†ï¼Œé¿å…é‡å¤å¤„ç†
			// èŠ‚ç‚¹ä¼šé€šè¿‡ç½‘ç»œæ¥æ”¶å¹¶å¤„ç†è‡ªå·±å‘å¸ƒçš„æ¶ˆæ¯
			f.logger.Debugf("å¤šèŠ‚ç‚¹ç¯å¢ƒï¼Œè·³è¿‡æœ¬åœ°å›ç¯å¤„ç†: topic=%s, peers=%d", topic, len(peers))
		}
	}
	f.pubCount++
	f.logger.With("topic", topic, "final_size", len(enc), "compressed_mark", shouldMarkCompressed).Info("message published successfully")
	return nil
}

// PublishTopic åŸºäºç»“æ„åŒ– Topic å®šä¹‰å‘å¸ƒæ¶ˆæ¯ã€‚
//
// ğŸ¯ ç ´åæ€§é‡æ„ï¼šç›´æ¥ä½¿ç”¨ç»“æ„åŒ– Topic å­—æ®µï¼Œä¸å†è½¬æ¢ä¸ºå­—ç¬¦ä¸²
func (f *Facade) PublishTopic(ctx context.Context, t protocols.Topic, data []byte, opts *iface.PublishOptions) error {
	// ğŸ›¡ï¸ è‡ªåŠ¨ä¸º Topic æ·»åŠ  namespaceï¼ˆå¦‚æœé…ç½®äº† namespaceï¼‰
	qualifiedTopic := t.WithNamespace(f.networkNamespace)

	qualifiedTopicStr := qualifiedTopic.String()
	if qualifiedTopicStr == "" {
		return fmt.Errorf("PublishTopic: invalid topic definition: %+v", t)
	}

	f.logger.With(
		"topic", qualifiedTopicStr,
		"namespace", qualifiedTopic.Namespace,
		"domain", qualifiedTopic.Domain,
		"name", qualifiedTopic.Name,
		"version", qualifiedTopic.Version,
		"message_size", len(data),
	).Info("publishing message")

	// é»˜è®¤å¤§å°é™åˆ¶ï¼ˆé…ç½®ï¼‰
	limit := 0
	if opts != nil && opts.MaxMessageSize > 0 {
		limit = opts.MaxMessageSize
	} else if f.cfg != nil && f.cfg.GetMaxMessageSize() > 0 {
		limit = int(f.cfg.GetMaxMessageSize())
	}
	if limit > 0 && len(data) > limit {
		f.dropCount++
		f.logger.With("topic", qualifiedTopicStr, "message_size", len(data), "max_size", limit).Warn("message too large")
		return nil
	}

	payload := data
	shouldMarkCompressed := false
	if f.cfg != nil && int64(len(payload)) > f.cfg.GetMaxMessageSize()/4 {
		shouldMarkCompressed = true
	}
	if opts != nil && opts.CompressionEnabled && opts.MaxMessageSize > 0 && len(payload) > opts.MaxMessageSize {
		shouldMarkCompressed = true
	}

	// ğŸ¯ ä½¿ç”¨ EncodeTopic ç›´æ¥ç¼–ç ç»“æ„åŒ– Topic
	enc, encErr := f.enc.EncodeTopic(qualifiedTopic, payload)
	if encErr != nil {
		f.logger.With("topic", qualifiedTopicStr, "error", encErr.Error()).Warn("encoding failed")
		return encErr
	}

	// é…ç½®è¦æ±‚å‹ç¼©æ—¶ï¼Œä»…æ ‡è®° compression=gzipï¼ˆå…ˆä¸æ”¹å˜ payloadï¼‰
	if shouldMarkCompressed {
		var env transportpb.Envelope
		if err := proto.Unmarshal(enc, &env); err == nil {
			env.Compression = "gzip"
			if b, mErr := proto.Marshal(&env); mErr == nil {
				enc = b
			}
		}
	}

	if f.val != nil {
		ok, reason := f.val.Validate(qualifiedTopicStr, enc)
		if !ok {
			f.dropCount++
			f.logger.With("topic", qualifiedTopicStr, "reason", reason).Warn("validation failed")
			return nil
		}
	}

	// ç¡®ä¿ GossipSub å·²åˆå§‹åŒ–
	f.ensureGossipSub()

	// GossipSub å¹¿æ’­
	if f.ps != nil {
		peers := f.ps.ListPeers(qualifiedTopicStr)
		f.logger.Infof("ğŸ” å‡†å¤‡å‘å¸ƒåˆ°ä¸»é¢˜ %s, è¿æ¥çš„peersæ•°é‡: %d", qualifiedTopicStr, len(peers))
		if len(peers) > 0 {
			f.logger.Infof("ğŸ“¡ ä¸»é¢˜ %s è¿æ¥çš„peers: %v", qualifiedTopicStr, peers)
		} else {
			f.logger.Warnf("âš ï¸ ä¸»é¢˜ %s æ²¡æœ‰è¿æ¥çš„peers! æ¶ˆæ¯å¯èƒ½æ— æ³•ä¼ é€’ç»™å…¶ä»–èŠ‚ç‚¹", qualifiedTopicStr)
		}

		f.psMu.Lock()
		if t, ok := f.topicHandles[qualifiedTopicStr]; ok && t != nil {
			f.psMu.Unlock()
			if err := t.Publish(ctx, enc); err != nil {
				f.logger.With("topic", qualifiedTopicStr, "error", err.Error()).Warn("gossipsub publish failed")
			}
		} else {
			f.psMu.Unlock()
			if err := f.ps.Publish(qualifiedTopicStr, enc); err != nil {
				f.logger.With("topic", qualifiedTopicStr, "error", err.Error()).Warn("gossipsub direct publish failed")
			}
		}
	}

	// æœ¬åœ°ç»Ÿè®¡ä¸å›ç¯é€šçŸ¥
	if f.pub != nil {
		if err := f.pub.Publish(qualifiedTopicStr, enc); err != nil {
			f.logger.Warnf("å‘å¸ƒæ¶ˆæ¯å¤±è´¥: %v", err)
		}
	}

	f.subMu.RLock()
	h := f.subs[qualifiedTopicStr]
	f.subMu.RUnlock()
	if h != nil {
		peers := f.ps.ListPeers(qualifiedTopicStr)
		if len(peers) <= 1 {
			f.logger.Debugf("å•èŠ‚ç‚¹ç¯å¢ƒï¼Œæ‰§è¡Œæœ¬åœ°å›ç¯å¤„ç†: topic=%s, peers=%d", qualifiedTopicStr, len(peers))

			// ğŸ¯ ä½¿ç”¨ DecodeTopic è§£ç 
			decodedTopic, decodedPayload, decErr := f.dec.DecodeTopic(enc)
			if decErr != nil {
				f.logger.With("topic", qualifiedTopicStr, "error", decErr.Error()).Warn("local handler decode failed")
			} else {
				if localErr := h(ctx, peer.ID(""), decodedTopic.String(), decodedPayload); localErr != nil {
					f.logger.With("topic", qualifiedTopicStr, "error", localErr.Error()).Warn("local handler failed")
				}
			}
		} else {
			f.logger.Debugf("å¤šèŠ‚ç‚¹ç¯å¢ƒï¼Œè·³è¿‡æœ¬åœ°å›ç¯å¤„ç†: topic=%s, peers=%d", qualifiedTopicStr, len(peers))
		}
	}

	f.pubCount++
	f.logger.With("topic", qualifiedTopicStr, "final_size", len(enc), "compressed_mark", shouldMarkCompressed).Info("message published successfully")
	return nil
}

// SubscribeTopic åŸºäºç»“æ„åŒ– Topic å®šä¹‰è®¢é˜…ä¸»é¢˜ã€‚
//
// ğŸ¯ ç ´åæ€§é‡æ„ï¼šç›´æ¥ä½¿ç”¨ç»“æ„åŒ– Topicï¼Œå†…éƒ¨è½¬æ¢ä¸ºå­—ç¬¦ä¸²ç”¨äº GossipSub
func (f *Facade) SubscribeTopic(t protocols.Topic, handler iface.SubscribeHandler, opts ...iface.SubscribeOption) (func() error, error) {
	// âš ï¸ é‡è¦ï¼šé¿å…â€œåŒé‡ namespace åŒ–â€
	//
	// - Subscribe(topicStr) å†…éƒ¨ä¼šå¯¹å­—ç¬¦ä¸² topic åš qualifyTopic()ï¼ˆå³ weisyn.{ns}.xxxï¼‰
	// - å¦‚æœè¿™é‡Œå…ˆ WithNamespace å†ä¼ ç»™ Subscribeï¼Œä¼šå¯¼è‡´å†æ¬¡ QualifyTopic â†’ weisyn.{ns}.{ns}.xxx
	//
	// å› æ­¤è¿™é‡Œ**åªå–åŸºç¡€ topic å­—ç¬¦ä¸²**ï¼Œè®© Subscribe è´Ÿè´£åšä¸€æ¬¡ï¼ˆä¸”ä»…ä¸€æ¬¡ï¼‰å‘½åç©ºé—´åŒ–ã€‚
	topicStr := t.String()
	if topicStr == "" {
		return nil, fmt.Errorf("SubscribeTopic: invalid topic definition: %+v", t)
	}
	// æš‚æ—¶ä»è°ƒç”¨ Subscribeï¼Œä½†åç»­ä¼šå®Œå…¨ç§»é™¤ Subscribe æ–¹æ³•
	return f.Subscribe(topicStr, handler, opts...)
}

// parseLegacyTopicString è§£ææ—§æ ¼å¼çš„ topic å­—ç¬¦ä¸²ä¸ºç»“æ„åŒ– Topicï¼ˆè¾…åŠ©å‡½æ•°ï¼‰
func parseLegacyTopicString(topic string) protocols.Topic {
	parts := strings.Split(topic, ".")
	if len(parts) < 4 || parts[0] != "weisyn" {
		return protocols.Topic{}
	}
	if len(parts) == 5 {
		return protocols.Topic{
			Namespace: parts[1],
			Domain:    parts[2],
			Name:      parts[3],
			Version:   parts[4],
		}
	} else if len(parts) == 4 {
		return protocols.Topic{
			Domain:  parts[1],
			Name:    parts[2],
			Version: parts[3],
		}
	}
	return protocols.Topic{}
}

// ==================== è‡ªæ£€/è¯Šæ–­ï¼ˆéæŒ‡æ ‡ï¼‰ ====================

// ListProtocols åˆ—å‡ºå·²æ³¨å†Œçš„åè®®ä¿¡æ¯ï¼ˆç”¨äºè¯Šæ–­ï¼‰
func (f *Facade) ListProtocols() []iface.ProtocolInfo {
	if f.reg == nil {
		return nil
	}
	return f.reg.List()
}

// GetProtocolInfo è·å–æŒ‡å®šåè®®çš„è¯¦ç»†ä¿¡æ¯ï¼ˆç”¨äºè¯Šæ–­ï¼‰
func (f *Facade) GetProtocolInfo(protoID string) *iface.ProtocolInfo {
	if f.reg == nil {
		return nil
	}
	info, ok := f.reg.Info(protoID)
	if !ok {
		return nil
	}
	return info
}

// ==================== è¾…åŠ© ====================

func computeBackoff(base time.Duration, factor float64, attempt int) time.Duration {
	if base <= 0 {
		return 0
	}
	mul := 1.0
	for i := 0; i < attempt; i++ {
		mul *= factor
	}
	return time.Duration(float64(base) * mul)
}

// Stop åœæ­¢ç½‘ç»œé—¨é¢åŠå…¶å®‰å…¨ç»„ä»¶
func (f *Facade) Stop() {
	if f.rateLimiter != nil {
		f.rateLimiter.Stop()
	}
	if f.msgRateLimiter != nil {
		f.msgRateLimiter.Stop()
	}
	// åœæ­¢ Validator æ¸…ç†åç¨‹
	if f.validatorCleanupStop != nil {
		close(f.validatorCleanupStop)
		f.validatorCleanupStop = nil
	}

	// åœæ­¢ forceConnect loop
	f.forceConnectMu.Lock()
	if f.forceConnectStopCancel != nil {
		f.forceConnectStopCancel()
		f.forceConnectStopCancel = nil
	}
	f.forceConnectReqCh = nil
	f.forceConnectMu.Unlock()
}

// ==================== StreamHandle é€‚é…å™¨ï¼ˆå†…éƒ¨ä½¿ç”¨ï¼‰ ====================

// streamHandleAdapter å°† libp2p.Stream é€‚é…ä¸º iface.StreamHandle
type streamHandleAdapter struct {
	stream libnetwork.Stream
}

func (s *streamHandleAdapter) Read(p []byte) (int, error)    { return s.stream.Read(p) }
func (s *streamHandleAdapter) Write(p []byte) (int, error)   { return s.stream.Write(p) }
func (s *streamHandleAdapter) Close() error                  { return s.stream.Close() }
func (s *streamHandleAdapter) CloseWrite() error             { return s.stream.CloseWrite() }
func (s *streamHandleAdapter) Reset() error                  { return s.stream.Reset() }
func (s *streamHandleAdapter) SetDeadline(t time.Time) error { return s.stream.SetDeadline(t) }

// ==================== è¾…åŠ©ï¼šå ä½æ—¥å¿—å™¨ ====================

// noopLogger å ä½æ—¥å¿—å™¨ï¼ˆå½“ logger ä¸º nil æ—¶ä½¿ç”¨ï¼‰
type noopLogger struct{}

func (l *noopLogger) Debug(msg string)                          {}
func (l *noopLogger) Debugf(format string, args ...interface{}) {}
func (l *noopLogger) Info(msg string)                           {}
func (l *noopLogger) Infof(format string, args ...interface{})  {}
func (l *noopLogger) Warn(msg string)                           {}
func (l *noopLogger) Warnf(format string, args ...interface{})  {}
func (l *noopLogger) Error(msg string)                          {}
func (l *noopLogger) Errorf(format string, args ...interface{}) {}
func (l *noopLogger) Fatal(msg string)                          {}
func (l *noopLogger) Fatalf(format string, args ...interface{}) {}
func (l *noopLogger) With(args ...interface{}) logiface.Logger  { return l }
func (l *noopLogger) Sync() error                               { return nil }
func (l *noopLogger) GetZapLogger() *zap.Logger                 { return zap.NewNop() }

// GetTopicPeers è·å–æŒ‡å®šä¸»é¢˜è¿æ¥çš„èŠ‚ç‚¹åˆ—è¡¨
func (f *Facade) GetTopicPeers(topic string) []peer.ID {
	f.psMu.Lock()
	defer f.psMu.Unlock()

	// âœ… ä¸ Subscribe/Publish ç»Ÿä¸€ï¼šæŸ¥è¯¢æ—¶ä¹Ÿåš namespace åŒ–ï¼ˆå¹‚ç­‰ï¼‰
	// è¿™èƒ½ä¿è¯ï¼šè°ƒç”¨æ–¹ä¼ å…¥ weisyn.consensus.latest_block.v1 ä¹Ÿèƒ½æŸ¥åˆ°å·² join çš„ weisyn.{ns}.consensus.latest_block.v1
	qualifiedTopic := f.qualifyTopic(topic)
	f.logger.Infof("ğŸ” GetTopicPeers è¢«è°ƒç”¨: topic=%s qualified=%s", topic, qualifiedTopic)

	if f.ps == nil {
		f.logger.Infof("âŒ GossipSubæœªåˆå§‹åŒ–ï¼Œæ— æ³•è·å–ä¸»é¢˜èŠ‚ç‚¹åˆ—è¡¨: %s", topic)
		return []peer.ID{}
	}

	f.logger.Infof("âœ… GossipSubå·²åˆå§‹åŒ–ï¼ŒtopicHandlesæ•°é‡: %d", len(f.topicHandles))

	// è·å–ä¸»é¢˜handle
	topicHandle, exists := f.topicHandles[qualifiedTopic]
	if !exists {
		f.logger.Infof("âŒ ä¸»é¢˜æœªåŠ å…¥ï¼Œæ— æ³•è·å–èŠ‚ç‚¹åˆ—è¡¨: %s (qualified=%s), å¯ç”¨ä¸»é¢˜: %v", topic, qualifiedTopic, func() []string {
			var topics []string
			for t := range f.topicHandles {
				topics = append(topics, t)
			}
			return topics
		}())
		return []peer.ID{}
	}

	f.logger.Infof("âœ… æ‰¾åˆ°ä¸»é¢˜handle: %s", qualifiedTopic)

	// è·å–è¿æ¥åˆ°è¯¥ä¸»é¢˜çš„èŠ‚ç‚¹
	peers := topicHandle.ListPeers()
	f.logger.Infof("ğŸ“Š ä¸»é¢˜ %s è¿æ¥çš„èŠ‚ç‚¹æ•°é‡: %d", qualifiedTopic, len(peers))

	// æ‰“å°èŠ‚ç‚¹IDè¯¦æƒ…
	for i, peerID := range peers {
		f.logger.Infof("  - èŠ‚ç‚¹%d: %s", i+1, peerID.String())
	}

	return peers
}

// IsSubscribed æ£€æŸ¥æ˜¯å¦å·²è®¢é˜…æŒ‡å®šä¸»é¢˜
func (f *Facade) IsSubscribed(topic string) bool {
	f.regMu.RLock()
	defer f.regMu.RUnlock()

	// æ£€æŸ¥æ˜¯å¦åœ¨å·²æ³¨å†Œä¸»é¢˜åˆ—è¡¨ä¸­
	return f.registeredTopics[topic]
}

// CheckProtocolSupport æ£€æŸ¥å¯¹ç­‰èŠ‚ç‚¹æ˜¯å¦æ”¯æŒæŒ‡å®šåè®®
func (f *Facade) CheckProtocolSupport(ctx context.Context, peerID peer.ID, protocol string) (bool, error) {
	if f.host == nil {
		return false, fmt.Errorf("libp2p host not available")
	}

	// æ£€æŸ¥èŠ‚ç‚¹æ˜¯å¦å·²è¿æ¥
	netw := f.host.Network()
	if netw != nil && netw.Connectedness(peerID) != libnetwork.Connected {
		// å°è¯•è¿æ¥åˆ°ç›®æ ‡èŠ‚ç‚¹ï¼ˆå¦‚æœæœªè¿æ¥ï¼‰
		if _, err := netw.DialPeer(ctx, peerID); err != nil {
			return false, fmt.Errorf("failed to connect to peer %s: %v", peerID, err)
		}
	}

	// è·å–èŠ‚ç‚¹æ”¯æŒçš„åè®®
	protocols, err := f.host.Peerstore().GetProtocols(peerID)
	if err != nil {
		return false, fmt.Errorf("failed to get protocols for peer %s: %v", peerID, err)
	}

	// namespace è¿ç§»æœŸå…¼å®¹ï¼šåŒæ—¶æ£€æŸ¥ original ä¸ qualified ä¸¤ç§åè®®ID
	candidates := map[string]struct{}{}
	if protocol != "" {
		candidates[protocol] = struct{}{}
	}
	if qp := f.qualifyProtocolID(protocol); qp != "" {
		candidates[qp] = struct{}{}
	}
	// è‹¥ä¼ å…¥çš„æ˜¯ qualifiedï¼Œåˆ™è¡¥ä¸€ä¸ª dequalifyï¼ˆä»…å½“åŒ¹é…æœ¬èŠ‚ç‚¹ namespace æ—¶æ‰å»é™¤ï¼‰
	if f.networkNamespace != "" && strings.HasPrefix(protocol, "/weisyn/"+f.networkNamespace+"/") {
		orig := "/weisyn/" + protocol[len("/weisyn/"+f.networkNamespace):] // keep the leading "/" from the remainder
		candidates[orig] = struct{}{}
	}

	// æ£€æŸ¥æ˜¯å¦æ”¯æŒç›®æ ‡åè®®ï¼ˆå€™é€‰é›†ä»»ä¸€å‘½ä¸­å³è®¤ä¸ºæ”¯æŒï¼‰
	for _, p := range protocols {
		if _, ok := candidates[string(p)]; ok {
			f.logger.Debugf("èŠ‚ç‚¹ %s æ”¯æŒåè®®: %s", peerID, string(p))
			return true, nil
		}
	}

	f.logger.Debugf("èŠ‚ç‚¹ %s ä¸æ”¯æŒåè®®: %sï¼ˆcandidates=%vï¼‰ï¼Œæ”¯æŒçš„åè®®: %v", peerID, protocol, func() []string {
		out := make([]string, 0, len(candidates))
		for c := range candidates {
			out = append(out, c)
		}
		return out
	}(), protocols)
	return false, nil
}

// ============================================================================
// å†…å­˜ç›‘æ§æ¥å£å®ç°ï¼ˆMemoryReporterï¼‰
// ============================================================================

// ModuleName è¿”å›æ¨¡å—åç§°ï¼ˆå®ç° MemoryReporter æ¥å£ï¼‰
func (f *Facade) ModuleName() string {
	return "network"
}

// CollectMemoryStats æ”¶é›† Network æ¨¡å—çš„å†…å­˜ç»Ÿè®¡ä¿¡æ¯ï¼ˆå®ç° MemoryReporter æ¥å£ï¼‰
//
// æ˜ å°„è§„åˆ™ï¼ˆæ ¹æ® memory-standards.mdï¼‰ï¼š
// - Objects: å½“å‰è¿æ¥æ•° / session æ•°
// - ApproxBytes: ç½‘ç»œç¼“å†²åŒºä¼°ç®—ï¼ˆæ¥æ”¶/å‘é€é˜Ÿåˆ—ï¼‰
// - CacheItems: åè®®æ³¨å†Œè¡¨ã€ä¸»é¢˜è®¢é˜…ç­‰ç¼“å­˜æ¡ç›®
// - QueueLength: å†…éƒ¨ message é˜Ÿåˆ—é•¿åº¦
func (f *Facade) CollectMemoryStats() metricsiface.ModuleMemoryStats {
	// ç»Ÿè®¡è¿æ¥æ•°ï¼ˆä» host.Network() è·å–çœŸå®è¿æ¥æ•°é‡ï¼‰
	connCount := int64(0)
	if f.host != nil {
		if netw := f.host.Network(); netw != nil {
			conns := netw.Conns()
			connCount = int64(len(conns))
		}
	}

	// ç»Ÿè®¡è®¢é˜…æ•°é‡
	f.subMu.RLock()
	subCount := int64(len(f.subs))
	f.subMu.RUnlock()

	// ç»Ÿè®¡æ³¨å†Œçš„åè®®å’Œä¸»é¢˜æ•°é‡
	f.regMu.RLock()
	protocolCount := int64(len(f.registeredProtocols))
	topicCount := int64(len(f.registeredTopics))
	f.regMu.RUnlock()

	// ç»Ÿè®¡ GossipSub ä¸»é¢˜å’Œè®¢é˜…å¥æŸ„
	f.psMu.Lock()
	topicHandleCount := int64(len(f.topicHandles))
	subHandleCount := int64(len(f.subHandles))
	f.psMu.Unlock()

	objects := connCount + subCount

	// ğŸ“Œ æš‚ä¸å¯¹ç½‘ç»œç¼“å†²åŒºåš bytes çº§åˆ«ä¼°ç®—ï¼Œä»¥é¿å…ä½¿ç”¨å›ºå®šå¸¸æ•°è¯¯å¯¼åˆ†æã€‚
	// å®é™…å†…å­˜å ç”¨è¯·ç»“åˆï¼š
	// - runtime.MemStats
	// - objects/cacheItemsï¼ˆè¿æ¥æ•°ã€è®¢é˜…æ•°ã€åè®®/ä¸»é¢˜æ•°ï¼‰
	approxBytes := int64(0)

	// ç¼“å­˜æ¡ç›®ï¼šåè®®æ³¨å†Œè¡¨ã€ä¸»é¢˜è®¢é˜…ç­‰
	cacheItems := protocolCount + topicCount + topicHandleCount + subHandleCount

	// é˜Ÿåˆ—é•¿åº¦ï¼šå†…éƒ¨æ¶ˆæ¯é˜Ÿåˆ—é•¿åº¦ï¼ˆä¼°ç®—ï¼Œå®é™…åº”è¯¥ä» streamSvc è·å–ï¼‰
	queueLength := int64(0) // ç®€åŒ–ä¼°ç®—

	return metricsiface.ModuleMemoryStats{
		Module:      "network",
		Layer:       "L2-Infrastructure",
		Objects:     objects,
		ApproxBytes: approxBytes,
		CacheItems:  cacheItems,
		QueueLength: queueLength,
	}
}
