package discovery

import (
	"context"
	"fmt"
	"strings"
	"sync"
	"time"

	lphost "github.com/libp2p/go-libp2p/core/host"
	libnetwork "github.com/libp2p/go-libp2p/core/network"
	libpeer "github.com/libp2p/go-libp2p/core/peer"
	"github.com/libp2p/go-libp2p/core/peerstore"
	mdns "github.com/libp2p/go-libp2p/p2p/discovery/mdns"
	ma "github.com/multiformats/go-multiaddr"
	manet "github.com/multiformats/go-multiaddr/net"

	p2pcfg "github.com/weisyn/v1/internal/config/p2p"
	"github.com/weisyn/v1/internal/core/p2p/interfaces"
	"github.com/weisyn/v1/pkg/constants/events"
	"github.com/weisyn/v1/pkg/interfaces/infrastructure/event"
	logiface "github.com/weisyn/v1/pkg/interfaces/infrastructure/log"
	p2pi "github.com/weisyn/v1/pkg/interfaces/p2p"
	metricsutil "github.com/weisyn/v1/pkg/utils/metrics"
	"github.com/weisyn/v1/pkg/types"
)

// Service Discovery æœåŠ¡å®ç°
//
// ç»Ÿä¸€è°ƒåº¦ Bootstrap / mDNS / Rendezvous ç­‰å‘ç°æ’ä»¶
type Service struct {
	host     lphost.Host
	opts     *p2pcfg.Options
	logger   logiface.Logger
	eventBus event.EventBus
	mdnsSvc  mdns.Service
	// rendezvousRouting é€šè¿‡å†…éƒ¨æ¥å£åä½œçš„ Rendezvous è·¯ç”±èƒ½åŠ›ï¼ˆç”± Routing å­ç³»ç»Ÿæ³¨å…¥ï¼‰
	rendezvousRouting interfaces.RendezvousRouting
	ctx               context.Context
	cancel            context.CancelFunc

	// è°ƒåº¦å™¨ç›¸å…³
	schedulerCancel context.CancelFunc
	dhtLoopCancel   context.CancelFunc
	mu              sync.RWMutex

	// è¯Šæ–­æŒ‡æ ‡å›è°ƒï¼ˆå¯é€‰ï¼‰
	recordBootstrapAttempt   func()
	recordBootstrapSuccess   func()
	recordMDNSPeerFound      func()
	recordMDNSConnectSuccess func()
	recordMDNSConnectFail    func()
	updateLastBootstrapTS    func()
	updateLastMDNSTS         func()

	// åœ°å€ç®¡ç†å™¨
	addrManager *AddrManager

	// å®ä¾‹æ•°æ®ç›®å½•ï¼ˆç”¨äºæ„å»ºå­˜å‚¨è·¯å¾„ï¼‰
	instanceDataDir string

	// Phase 3: é—´éš”é‡ç½®æœºåˆ¶
	schedulerResetChan chan struct{} // bootstrapè°ƒåº¦å™¨é‡ç½®é€šé“
	dhtResetChan       chan struct{} // DHT rendezvousé‡ç½®é€šé“
	lastResetAt        time.Time     // æœ€åä¸€æ¬¡é‡ç½®æ—¶é—´ï¼ˆç”¨äºå†·å´ï¼‰
	resetMu            sync.Mutex    // é‡ç½®æ“ä½œä¿æŠ¤é”

	// ğŸ†• 2025-12-18: Peer ID ä¸åŒ¹é…æ²»æ„ˆç¼“å­˜
	// é¿å…å¯¹åŒä¸€ (expected, addr) ç»„åˆé‡å¤è¾“å‡º WARN æ—¥å¿—
	peerMismatchCache   map[string]time.Time // key: "expected:addr" -> é¦–æ¬¡æ²»æ„ˆæ—¶é—´
	peerMismatchMu      sync.RWMutex
	peerMismatchTotal   int64 // æ€»æ²»æ„ˆæ¬¡æ•°ï¼ˆç”¨äºç»Ÿè®¡ï¼‰
	peerMismatchUnique  int64 // å”¯ä¸€ç»„åˆæ¬¡æ•°
}

var _ p2pi.Discovery = (*Service)(nil)

// healPeerIDMismatch å°è¯•å¯¹ "peer id mismatch" åšæœ¬åœ°è‡ªæ„ˆï¼š
// - ä» expected peer çš„ peerstore ä¸­ç§»é™¤è¯¥ addrï¼ˆé¿å…ç»§ç»­è¿é”™äºº/æ±¡æŸ“é€‰ä¸¾&åŒæ­¥å€™é€‰ï¼‰
// - å°†è¯¥ addr å½’æ¡£åˆ° actual peerï¼ˆä»é”™è¯¯æ–‡æœ¬ä¸­è§£æå‡ºçš„ remote key matchesï¼‰
//
// è¯´æ˜ï¼š
// - è¿™æ˜¯ "addr->peer æ˜ å°„çº é”™" çš„ç³»ç»Ÿè·¯å¾„ä¿®å¤ç‚¹ï¼Œå±äºç”Ÿäº§çº§é—­ç¯ï¼›å¦åˆ™ä¼šé•¿æœŸå‡ºç°"æ‹¨å·åˆ°æŸåœ°å€ä½†å¯¹ç«¯ peerID ä¸ä¸€è‡´"ã€‚
// - è¿™é‡Œä½¿ç”¨ TempAddrTTL å†™å…¥ actual peerï¼Œé¿å…æŠŠé”™è¯¯çš„ DHT addr æ°¸ä¹…å›ºåŒ–ã€‚
//
// ğŸ†• 2025-12-18 ä¼˜åŒ–ï¼š
// - æ·»åŠ ç¼“å­˜é¿å…å¯¹åŒä¸€ (expected, addr) ç»„åˆé‡å¤è¾“å‡º WARN æ—¥å¿—
// - é¦–æ¬¡å‘ç°: WARNï¼Œåç»­å‘ç°: DEBUG
// - æ·»åŠ ç»Ÿè®¡è®¡æ•°
func (s *Service) healPeerIDMismatch(expected libpeer.ID, addr ma.Multiaddr, dialErr error) bool {
	if s == nil || s.host == nil || expected == "" || addr == nil || dialErr == nil {
		return false
	}
	msg := dialErr.Error()
	if !strings.Contains(msg, "peer id mismatch") || !strings.Contains(msg, "remote key matches") {
		return false
	}

	// å°è¯•è§£æ actual peerï¼š"... remote key matches <peerID>"
	actualStr := ""
	if idx := strings.Index(msg, "remote key matches"); idx >= 0 {
		rest := strings.TrimSpace(msg[idx+len("remote key matches"):])
		// æˆªæ–­åˆ°ç¬¬ä¸€ä¸ªç©ºç™½/é€—å·/æ‹¬å·/æ–¹æ‹¬å·
		for i, r := range rest {
			if r == ' ' || r == ',' || r == ')' || r == ']' || r == '\n' || r == '\r' || r == '\t' {
				rest = rest[:i]
				break
			}
		}
		actualStr = strings.TrimSpace(rest)
	}
	if actualStr == "" {
		return false
	}
	actual, err := libpeer.Decode(actualStr)
	if err != nil || actual == "" {
		return false
	}
	if actual == expected {
		// ç†è®ºä¸Šä¸ä¼šå‡ºç°ï¼Œä½†é˜²å¾¡ä¸€ä¸‹é¿å…è¯¯åˆ 
		return false
	}

	// ğŸ†• æ£€æŸ¥ç¼“å­˜ï¼šæ˜¯å¦å·²ç»å¤„ç†è¿‡è¿™ä¸ª (expected, addr) ç»„åˆ
	cacheKey := expected.String() + ":" + addr.String()
	isFirstTime := false

	s.peerMismatchMu.Lock()
	if s.peerMismatchCache == nil {
		s.peerMismatchCache = make(map[string]time.Time)
	}
	if _, exists := s.peerMismatchCache[cacheKey]; !exists {
		// é¦–æ¬¡å‘ç°
		s.peerMismatchCache[cacheKey] = time.Now()
		s.peerMismatchUnique++
		isFirstTime = true
	}
	s.peerMismatchTotal++
	totalCount := s.peerMismatchTotal
	uniqueCount := s.peerMismatchUnique
	s.peerMismatchMu.Unlock()

	// 1) ä» expected çš„åœ°å€é›†ä¸­ç§»é™¤è¯¥ addr
	current := s.host.Peerstore().Addrs(expected)
	filtered := make([]ma.Multiaddr, 0, len(current))
	for _, a := range current {
		if a == nil {
			continue
		}
		if a.Equal(addr) {
			continue
		}
		filtered = append(filtered, a)
	}
	// æ¸…ç©ºå†å›å¡«ï¼ˆlibp2p æ²¡æœ‰ "remove single addr" çš„é€šç”¨æ¥å£ï¼‰
	s.host.Peerstore().ClearAddrs(expected)
	if len(filtered) > 0 {
		s.host.Peerstore().AddAddrs(expected, filtered, peerstore.PermanentAddrTTL)
	}

	// 2) å°†è¯¥ addr å½’æ¡£åˆ° actual peerï¼ˆä¸´æ—¶ TTLï¼Œç­‰å¾…åç»­å¥åº·æ¢æµ‹/æ¡æ‰‹æ ¡éªŒå†æ¬¡ç¡®è®¤ï¼‰
	s.host.Peerstore().AddAddrs(actual, []ma.Multiaddr{addr}, peerstore.TempAddrTTL)

	// ğŸ†• åŒºåˆ†é¦–æ¬¡å’Œé‡å¤å‘ç°çš„æ—¥å¿—çº§åˆ«
	if s.logger != nil {
		if isFirstTime {
			// é¦–æ¬¡å‘ç°ï¼šWARNï¼ˆä¾¿äºè¿ç»´å…³æ³¨ï¼‰
			s.logger.Warnf(
				"p2p.discovery.peer_id_mismatch_healed expected=%s actual=%s addr=%s (first_time=true, total=%d, unique=%d)",
				expected.String()[:12], actual.String()[:12], addr.String(), totalCount, uniqueCount,
			)
		} else {
			// é‡å¤å‘ç°ï¼šDEBUGï¼ˆé¿å…åˆ·å±ï¼‰
			s.logger.Debugf(
				"p2p.discovery.peer_id_mismatch_healed expected=%s actual=%s addr=%s (first_time=false, total=%d)",
				expected.String()[:12], actual.String()[:12], addr.String(), totalCount,
			)
		}
	}
	return true
}

// GetPeerMismatchStats è¿”å› peer ID ä¸åŒ¹é…æ²»æ„ˆçš„ç»Ÿè®¡ä¿¡æ¯
//
// ğŸ†• 2025-12-18ï¼šç”¨äºç›‘æ§å’Œè¯Šæ–­
func (s *Service) GetPeerMismatchStats() (total int64, unique int64) {
	s.peerMismatchMu.RLock()
	defer s.peerMismatchMu.RUnlock()
	return s.peerMismatchTotal, s.peerMismatchUnique
}

// CleanupPeerMismatchCache æ¸…ç†è¿‡æœŸçš„ peer ID ä¸åŒ¹é…ç¼“å­˜æ¡ç›®
//
// ğŸ†• 2025-12-18ï¼šå®šæœŸæ¸…ç†ï¼Œé¿å…ç¼“å­˜æ— é™å¢é•¿
// ä¿ç•™æœ€è¿‘ 1 å°æ—¶å†…çš„æ¡ç›®
func (s *Service) CleanupPeerMismatchCache() {
	s.peerMismatchMu.Lock()
	defer s.peerMismatchMu.Unlock()

	if s.peerMismatchCache == nil {
		return
	}

	cutoff := time.Now().Add(-1 * time.Hour)
	for key, ts := range s.peerMismatchCache {
		if ts.Before(cutoff) {
			delete(s.peerMismatchCache, key)
		}
	}
}

// healPeerIDMismatchFromAggregateError å°è¯•ä» â€œall dials failedâ€ çš„èšåˆé”™è¯¯æ–‡æœ¬ä¸­æå– addr å¹¶åšçº é”™ã€‚
// å…¸å‹è¡Œæ ¼å¼ï¼š
//   - [/ip4/.../tcp/28683] failed to negotiate security protocol: peer id mismatch: expected <A>, but remote key matches <B>
func (s *Service) healPeerIDMismatchFromAggregateError(expected libpeer.ID, dialErr error) {
	if s == nil || s.host == nil || expected == "" || dialErr == nil {
		return
	}
	msg := dialErr.Error()
	if !strings.Contains(msg, "peer id mismatch") || !strings.Contains(msg, "remote key matches") {
		return
	}
	lines := strings.Split(msg, "\n")
	for _, ln := range lines {
		ln = strings.TrimSpace(ln)
		if !strings.Contains(ln, "peer id mismatch") || !strings.Contains(ln, "remote key matches") {
			continue
		}
		// æå– "* [<addr>]" æ®µ
		lb := strings.Index(ln, "[")
		rb := strings.Index(ln, "]")
		if lb < 0 || rb <= lb {
			continue
		}
		addrStr := strings.TrimSpace(ln[lb+1 : rb])
		if addrStr == "" {
			continue
		}
		maddr, err := ma.NewMultiaddr(addrStr)
		if err != nil {
			continue
		}
		_ = s.healPeerIDMismatch(expected, maddr, fmt.Errorf("%s", ln))
	}
}

// NewService åˆ›å»º Discovery æœåŠ¡
func NewService() *Service {
	return &Service{
		// Phase 3: åˆå§‹åŒ–é‡ç½®é€šé“
		schedulerResetChan: make(chan struct{}, 1), // å¸¦ç¼“å†²é¿å…é˜»å¡
		dhtResetChan:       make(chan struct{}, 1),
	}
}

// Initialize åˆå§‹åŒ– Discovery æœåŠ¡ï¼ˆéœ€è¦ Host å’Œé…ç½®ï¼‰
func (s *Service) Initialize(host lphost.Host, opts *p2pcfg.Options, logger logiface.Logger, eb event.EventBus) error {
	if host == nil {
		return fmt.Errorf("host is required")
	}

	s.host = host
	s.opts = opts
	s.logger = logger
	s.eventBus = eb
	s.ctx, s.cancel = context.WithCancel(context.Background())

	// åˆå§‹åŒ–åœ°å€ç®¡ç†å™¨ï¼ˆP2P åŸºç¡€è®¾æ–½ï¼Œå†…éƒ¨å®ç°ï¼Œç”¨æˆ·æ— éœ€é…ç½®ï¼‰
	//
	// ä½¿ç”¨ç»è¿‡ç”Ÿäº§éªŒè¯çš„é»˜è®¤é…ç½®ï¼š
	// - DHT åœ°å€ TTL: 30åˆ†é’Ÿï¼ˆé¢‘ç¹åˆ·æ–°ï¼Œä¿è¯å¯è¾¾æ€§ï¼‰
	// - è¿æ¥æˆåŠŸåœ°å€ TTL: 24å°æ—¶ï¼ˆç¨³å®šèŠ‚ç‚¹é•¿æœŸä¿ç•™ï¼‰
	// - å¤±è´¥åœ°å€ TTL: 5åˆ†é’Ÿï¼ˆå¿«é€Ÿæ·˜æ±°ä¸å¯è¾¾èŠ‚ç‚¹ï¼‰
	// - æŒä¹…åŒ–åˆ°: {instanceDataDir}/p2p/addrs/ï¼ˆè‡ªåŠ¨åˆ›å»ºï¼‰
	if host != nil {
		// æ„å»ºå­˜å‚¨è·¯å¾„ï¼šä¼˜å…ˆä½¿ç”¨å®ä¾‹æ•°æ®ç›®å½•ï¼Œå›é€€åˆ°å·¥ä½œåŒºæ ¹ç›®å½•
		var badgerDir string
		if s.instanceDataDir != "" {
			// ä½¿ç”¨é“¾ä¸“å±æ•°æ®ç›®å½•ï¼šdata/test/test-public-xxx/p2p/addrs
			badgerDir = fmt.Sprintf("%s/p2p/addrs", s.instanceDataDir)
		} else {
			// å›é€€æ–¹æ¡ˆï¼ˆå…¼å®¹æ—§è¡Œä¸ºï¼‰ï¼šdata/p2p/<hostID>/addrs
			hostID := host.ID().String()
			badgerDir = fmt.Sprintf("data/p2p/%s/addrs", hostID)
			if logger != nil {
				logger.Warnf("âš ï¸ instanceDataDir æœªè®¾ç½®ï¼ŒAddrManager ä½¿ç”¨å›é€€è·¯å¾„: %s", badgerDir)
			}
		}

		// å†…éƒ¨é»˜è®¤é…ç½®ï¼ˆæ— éœ€ç”¨æˆ·æ‰‹å·¥ JSONï¼ŒæŒ‰èŠ‚ç‚¹è§’è‰²è‡ªåŠ¨æ¨å¯¼ï¼‰
		// - å¯¹ bootstrap/DHT serverï¼šå…è®¸æ›´å¤§çš„ peer ä¸Šé™ï¼Œä½†ä»ç„¶å¿…é¡»æœ‰ç•Œï¼ˆé¿å… 4GB å®¹å™¨ OOMï¼‰
		// - å¯¹æ™®é€šèŠ‚ç‚¹ï¼šä¸Šé™æ›´å°
		isBootLike := false
		if s.opts != nil {
			if strings.ToLower(strings.TrimSpace(s.opts.DHTMode)) == "server" {
				isBootLike = true
			}
			if s.opts.Profile == p2pcfg.ProfileServer {
				isBootLike = true
			}
		}
		maxTrackedPeers := 5000
		refreshBudget := 500
		maxAddrsPerPeer := 8
		// ğŸ†• ä¼˜åŒ–ï¼šå¤§å¹…é™ä½é˜Ÿåˆ—ä¸Šé™ï¼Œé˜²æ­¢å†…å­˜æ³„æ¼ï¼ˆä»5000é™åˆ°50ï¼‰
		maxRediscoveryQueue := 50
		if isBootLike {
			maxTrackedPeers = 20000
			refreshBudget = 1500
			// bootstrapèŠ‚ç‚¹ç¨å¤§ä½†ä¹Ÿè¦æ§åˆ¶ï¼ˆä»10000é™åˆ°100ï¼‰
			maxRediscoveryQueue = 100
		}

		// å†…éƒ¨å›ºå®šé…ç½®ï¼ˆç»è¿‡ç”Ÿäº§éªŒè¯çš„æœ€ä½³å®è·µï¼‰+ æœ‰ç•ŒåŒ–å‚æ•°
		amCfg := AddrManagerConfig{
			TTL: AddrTTL{
				// ğŸ†• P0-009: DHT åœ°å€ TTL è¿‡çŸ­ä¼šå¯¼è‡´ refresh çª—å£è¿‡å°ï¼ˆFindPeer è¿ç»­å¤±è´¥å³è¿‡æœŸ -> addrs=0 -> ç½‘ç»œå­¤å²›ï¼‰
				// å°† DHT TTL æ‹‰é•¿åˆ° 2hï¼Œä¸º refresh/rediscovery æä¾›æ›´å®½çš„å®¹é”™çª—å£ã€‚
				DHT:       2 * time.Hour,
				Connected: 24 * time.Hour,
				Bootstrap: peerstore.PermanentAddrTTL,
				Failed:    5 * time.Minute,
			},
			MaxConcurrentLookups:   10,
			LookupTimeout:          30 * time.Second,
			RefreshInterval:        10 * time.Minute,
			// ğŸ†• P0-009: æå‰åˆ·æ–°ï¼Œé¿å…æ¥è¿‘è¿‡æœŸæ—¶å†æŸ¥è¯¢å¯¼è‡´â€œåªå‰© 1-2 æ¬¡æœºä¼šâ€
			RefreshThreshold:       30 * time.Minute,
			MaxTrackedPeers:        maxTrackedPeers,
			RefreshBudget:          refreshBudget,
			MaxAddrsPerPeer:        maxAddrsPerPeer,
			MaxPendingLookups:      maxTrackedPeers, // ä¸ peer ä¸Šé™åŒé‡çº§å³å¯
			MaxRediscoveryQueue:    maxRediscoveryQueue,
			EnablePersistence:      true,
			PersistenceBackend:     "badger",
			BadgerDir:              badgerDir,
			NamespacePrefix:        "peer_addrs/v1/",
			PruneInterval:          1 * time.Hour,
			RecordTTL:              7 * 24 * time.Hour,
			RediscoveryInterval:    30 * time.Second,
			RediscoveryMaxRetries:  10,
			RediscoveryBackoffBase: 1 * time.Minute,
		}

		// æ³¨æ„ï¼šè¿™é‡ŒrendezvousRoutingè¿˜æœªæ³¨å…¥ï¼Œä¼šåœ¨SetRendezvousRoutingæ—¶å¯ç”¨
		s.addrManager = NewAddrManager(host, nil, amCfg, logger)

		if logger != nil {
			logger.Infof(
				"âœ… AddrManager å·²åˆå§‹åŒ–ï¼ˆå†…éƒ¨å®ç°ï¼Œè‡ªåŠ¨ç®¡ç†èŠ‚ç‚¹åœ°å€ï¼‰ï¼Œå­˜å‚¨è·¯å¾„: %s (maxTrackedPeers=%d refreshBudget=%d maxAddrsPerPeer=%d)",
				badgerDir, maxTrackedPeers, refreshBudget, maxAddrsPerPeer,
			)
		}

		// âœ… å°† bootstrap peers æ ‡è®°ä¸ºæ°¸ä¹…ä¿ç•™ï¼ˆé¿å…æœ‰ç•ŒåŒ–è¯¯æ·˜æ±°å…³é”®èŠ‚ç‚¹ï¼‰
		if s.opts != nil && len(s.opts.BootstrapPeers) > 0 {
			peers := s.filterBootstrapPeers(s.opts.BootstrapPeers)
			for _, p := range peers {
				m, err := ma.NewMultiaddr(p)
				if err != nil {
					continue
				}
				ai, err := libpeer.AddrInfoFromP2pAddr(m)
				if err != nil || ai == nil || ai.ID == "" || len(ai.Addrs) == 0 {
					continue
				}
				s.addrManager.AddBootstrapAddr(ai.ID, ai.Addrs)
			}
		}

		// âœ… æ³¨å†Œåˆ° MemoryDoctorï¼ˆç”¨äºé‡‡æ · peerstore/é˜Ÿåˆ—è§„æ¨¡ï¼‰
		metricsutil.RegisterMemoryReporter(s.addrManager)
	}

	// ğŸ”§ Phase 3: è®¢é˜…Discoveryé—´éš”é‡ç½®äº‹ä»¶
	if eb != nil {
		err := eb.Subscribe(events.EventTypeDiscoveryIntervalReset, func(data interface{}) {
			// è§¦å‘schedulerå’ŒDHTå¾ªç¯é‡ç½®
			select {
			case s.schedulerResetChan <- struct{}{}:
			default: // å¦‚æœé€šé“å·²æ»¡ï¼Œå¿½ç•¥ï¼ˆé˜²æ­¢é˜»å¡ï¼‰
			}

			select {
			case s.dhtResetChan <- struct{}{}:
			default: // å¦‚æœé€šé“å·²æ»¡ï¼Œå¿½ç•¥
			}

			if s.logger != nil {
				if resetData, ok := data.(*types.DiscoveryResetEventData); ok {
					s.logger.Infof("ğŸ”„ æ”¶åˆ°Discoveryé—´éš”é‡ç½®äº‹ä»¶: reason=%s trigger=%s", resetData.Reason, resetData.Trigger)
				} else {
					s.logger.Info("ğŸ”„ æ”¶åˆ°Discoveryé—´éš”é‡ç½®äº‹ä»¶")
				}
			}
		})

		if err != nil && logger != nil {
			logger.Warnf("è®¢é˜…Discoveryé—´éš”é‡ç½®äº‹ä»¶å¤±è´¥: %v", err)
		} else if logger != nil {
			logger.Debug("âœ… å·²è®¢é˜…Discoveryé—´éš”é‡ç½®äº‹ä»¶")
		}
	}

	return nil
}

// SetRendezvousRouting è®¾ç½® Rendezvous è·¯ç”±å®ç°ï¼ˆç”± Runtime åœ¨åˆå§‹åŒ– Routing åè°ƒç”¨ï¼‰
func (s *Service) SetRendezvousRouting(r interfaces.RendezvousRouting) {
	s.mu.Lock()
	defer s.mu.Unlock()
	s.rendezvousRouting = r

	// æ›´æ–°åœ°å€ç®¡ç†å™¨çš„routingå¼•ç”¨
	if s.addrManager != nil {
		s.addrManager.routing = r
	}
}

// SetInstanceDataDir è®¾ç½®å®ä¾‹æ•°æ®ç›®å½•ï¼ˆç”¨äºæ„å»º AddrManager å­˜å‚¨è·¯å¾„ï¼‰
//
// åº”è¯¥åœ¨ Initialize ä¹‹å‰è°ƒç”¨ï¼Œä»¥ä¾¿ AddrManager ä½¿ç”¨æ­£ç¡®çš„è·¯å¾„ã€‚
// å¦‚æœåœ¨ Initialize ä¹‹åè°ƒç”¨ï¼Œéœ€è¦é‡æ–°åˆå§‹åŒ– AddrManagerã€‚
func (s *Service) SetInstanceDataDir(dataDir string) {
	s.mu.Lock()
	defer s.mu.Unlock()
	s.instanceDataDir = dataDir
}

// SetDiagnosticsCallbacks è®¾ç½®è¯Šæ–­æŒ‡æ ‡å›è°ƒï¼ˆå¯é€‰ï¼‰
func (s *Service) SetDiagnosticsCallbacks(
	recordBootstrapAttempt func(),
	recordBootstrapSuccess func(),
	recordMDNSPeerFound func(),
	recordMDNSConnectSuccess func(),
	recordMDNSConnectFail func(),
	updateLastBootstrapTS func(),
	updateLastMDNSTS func(),
) {
	s.mu.Lock()
	defer s.mu.Unlock()
	s.recordBootstrapAttempt = recordBootstrapAttempt
	s.recordBootstrapSuccess = recordBootstrapSuccess
	s.recordMDNSPeerFound = recordMDNSPeerFound
	s.recordMDNSConnectSuccess = recordMDNSConnectSuccess
	s.recordMDNSConnectFail = recordMDNSConnectFail
	s.updateLastBootstrapTS = updateLastBootstrapTS
	s.updateLastMDNSTS = updateLastMDNSTS
}

// Start å¯åŠ¨å‘ç°æœåŠ¡
func (s *Service) Start(ctx context.Context) error {
	if s.host == nil {
		return fmt.Errorf("discovery service not initialized")
	}

	// é¢„è¿‡æ»¤ bootstrap peersï¼šé¿å…æ— æ•ˆ multiaddr/å ä½ç¬¦å¯¼è‡´ discovery å¾ªç¯åˆ·å±ï¼Œ
	// å¹¶ç¡®ä¿åç»­è°ƒåº¦å™¨ä»…å¯¹â€œå¯è§£æâ€çš„åœ°å€è¿›è¡Œæ‹¨å·ã€‚
	var validBootstrapPeers []string
	if s.opts != nil && len(s.opts.BootstrapPeers) > 0 {
		validBootstrapPeers = s.filterBootstrapPeers(s.opts.BootstrapPeers)
	}

	// æ‰“å° Discovery å…³é”®é…ç½®å¿«ç…§ï¼Œä¾¿äºç°åœºæ’éšœ
	if s.logger != nil && s.opts != nil {
		s.logger.Infof(
			"p2p.discovery.config enable_mdns=%t enable_dht=%t bootstrap_peers=%d discovery_interval=%s advertise_interval=%s rendezvous_ns=%s min_peers=%d max_peers=%d",
			s.opts.EnableMDNS,
			s.opts.EnableDHT,
			len(validBootstrapPeers),
			s.opts.DiscoveryInterval,
			s.opts.AdvertiseInterval,
			s.getRendezvousNamespace(),
			s.opts.MinPeers,
			s.opts.MaxPeers,
		)
	}

	// å¯åŠ¨ mDNSï¼ˆå¦‚æœå¯ç”¨ï¼‰
	if s.opts != nil && s.opts.EnableMDNS {
		if err := s.startMDNS(); err != nil {
			if s.logger != nil {
				s.logger.Warnf("p2p.discovery.mdns start failed: %v", err)
			}
			// mDNS å¤±è´¥ä¸é˜»æ–­å…¶ä»–å‘ç°æœºåˆ¶
		}
	}

	// å¯åŠ¨ Bootstrap è°ƒåº¦å™¨å¾ªç¯ï¼ˆå¸¦é€€é¿ç­–ç•¥ï¼‰
	if s.opts != nil && len(validBootstrapPeers) > 0 {
		schedulerCtx, schedulerCancel := context.WithCancel(s.ctx)
		s.schedulerCancel = schedulerCancel
		go s.schedulerLoop(schedulerCtx, validBootstrapPeers)
	} else if s.logger != nil && s.opts != nil && len(s.opts.BootstrapPeers) > 0 {
		// é…ç½®é‡Œå£°æ˜äº† bootstrap peersï¼Œä½†å…¨éƒ¨æ— æ•ˆ/å ä½ç¬¦ï¼šç»™å‡ºä¸€æ¬¡æ€§ã€å¯æ“ä½œçš„å‘Šè­¦ã€‚
		s.logger.Warnf(
			"p2p.discovery.bootstrap disabled: all configured bootstrap_peers are invalid/placeholder (configured=%d, valid=0). "+
				"this node will likely stay isolated unless you enable mDNS (enable_mdns=true) or manually connect via wes_admin_connectPeer / POST /api/v1/admin/p2p/connect",
			len(s.opts.BootstrapPeers),
		)
	}

	// å¯åŠ¨ DHT Rendezvous å‘ç°å¾ªç¯ï¼ˆå¦‚æœå¯ç”¨ DHTï¼‰
	if s.opts != nil && s.opts.EnableDHT {
		// å•èŠ‚ç‚¹ / å­¤ç«‹ç½‘ç»œæ¨¡å¼ï¼šæ˜¾å¼å…³é—­ DHT rendezvous å¾ªç¯ï¼Œé¿å…åœ¨æ˜çŸ¥åªæœ‰ä¸€ä¸ªèŠ‚ç‚¹çš„ç¯å¢ƒä¸‹ç©ºè·‘
		if s.opts.DiscoverySingleNodeMode || s.opts.DiscoveryExpectedMinPeers == 0 {
			if s.logger != nil {
				s.logger.Infof("p2p.discovery.dht_rendezvous skipped: single_node_mode=%t expected_min_peers=%d",
					s.opts.DiscoverySingleNodeMode, s.opts.DiscoveryExpectedMinPeers)
			}
		} else {
			s.mu.RLock()
			rendezvous := s.rendezvousRouting
			s.mu.RUnlock()

			if rendezvous != nil {
				ns := s.getRendezvousNamespace()
				if ns != "" {
					dhtLoopCtx, dhtLoopCancel := context.WithCancel(s.ctx)
					s.dhtLoopCancel = dhtLoopCancel
					go s.findPeersLoop(dhtLoopCtx, ns)
				}
			} else if s.logger != nil {
				s.logger.Warnf("p2p.discovery.dht_rendezvous disabled: rendezvous routing not available")
			}
		}
	}

	// å¯åŠ¨åœ°å€ç®¡ç†å™¨
	if s.addrManager != nil {
		s.addrManager.Start()
	}

	// ğŸ†• 2025-12-18: å¯åŠ¨ peer mismatch ç¼“å­˜æ¸…ç†åç¨‹
	go s.peerMismatchCacheCleanupLoop(s.ctx)

	if s.logger != nil {
		s.logger.Infof("p2p.discovery service started")
	}

	return nil
}

// peerMismatchCacheCleanupLoop å®šæœŸæ¸…ç† peer mismatch ç¼“å­˜
//
// ğŸ†• 2025-12-18: æ¯ 30 åˆ†é’Ÿæ¸…ç†ä¸€æ¬¡è¿‡æœŸæ¡ç›®ï¼Œé¿å…ç¼“å­˜æ— é™å¢é•¿
func (s *Service) peerMismatchCacheCleanupLoop(ctx context.Context) {
	ticker := time.NewTicker(30 * time.Minute)
	defer ticker.Stop()

	for {
		select {
		case <-ctx.Done():
			return
		case <-ticker.C:
			s.CleanupPeerMismatchCache()
			if s.logger != nil {
				total, unique := s.GetPeerMismatchStats()
				s.logger.Debugf("p2p.discovery.peer_mismatch_cache_cleanup total_healed=%d unique_combinations=%d", total, unique)
			}
		}
	}
}

// Stop åœæ­¢å‘ç°æœåŠ¡
func (s *Service) Stop(ctx context.Context) error {
	// åœæ­¢è°ƒåº¦å™¨å¾ªç¯
	if s.schedulerCancel != nil {
		s.schedulerCancel()
		s.schedulerCancel = nil
	}

	// åœæ­¢ DHT Rendezvous å¾ªç¯
	if s.dhtLoopCancel != nil {
		s.dhtLoopCancel()
		s.dhtLoopCancel = nil
	}

	// åœæ­¢ä¸» context
	if s.cancel != nil {
		s.cancel()
	}

	if s.mdnsSvc != nil {
		if err := s.mdnsSvc.Close(); err != nil {
			if s.logger != nil {
				s.logger.Warnf("p2p.discovery.mdns close failed: %v", err)
			}
		}
		s.mdnsSvc = nil
	}

	// åœæ­¢åœ°å€ç®¡ç†å™¨
	if s.addrManager != nil {
		s.addrManager.Stop()
	}

	if s.logger != nil {
		s.logger.Infof("p2p.discovery service stopped")
	}

	return nil
}

// Trigger è§¦å‘ä¸€æ¬¡å‘ç°ï¼ˆreason ç”¨äºæ—¥å¿—ï¼‰
func (s *Service) Trigger(reason string) {
	if s.logger != nil {
		s.logger.Infof("p2p.discovery trigger: %s", reason)
	}

	// é‡æ–°è¿æ¥åˆ° Bootstrap Peersï¼ˆä¸€æ¬¡æ€§ï¼‰
	if s.opts != nil && len(s.opts.BootstrapPeers) > 0 {
		peers := s.filterBootstrapPeers(s.opts.BootstrapPeers)
		if len(peers) > 0 {
			go s.tryDialOnce(context.Background(), peers)
		} else if s.logger != nil {
			s.logger.Debugf("p2p.discovery.trigger skipped: no valid bootstrap peers (reason=%s)", reason)
		}
	}
}

// filterBootstrapPeers è¿‡æ»¤æ— æ•ˆ/å ä½ç¬¦ bootstrap peersï¼Œå¹¶åœ¨æ£€æµ‹åˆ°é—®é¢˜æ—¶è¾“å‡ºä¸€æ¬¡æ€§è¯Šæ–­ä¿¡æ¯ã€‚
//
// ç›®æ ‡ï¼š
// - é¿å… schedulerLoop å¯¹æ— æ•ˆåœ°å€è¿›è¡Œæ— é™é‡è¯•ï¼Œäº§ç”Ÿå¤§é‡ error å™ªéŸ³ï¼›
// - ç»™å‡ºå¯æ“ä½œçš„ä¿®å¤å»ºè®®ï¼ˆæ›¿æ¢çœŸå® multiaddr / å¼€å¯ mDNS / ä½¿ç”¨ admin connectï¼‰ã€‚
func (s *Service) filterBootstrapPeers(peers []string) []string {
	if len(peers) == 0 {
		return nil
	}

	valid := make([]string, 0, len(peers))
	var invalid []string
	var placeholder []string

	for _, p := range peers {
		// æ˜ç¡®è¯†åˆ«â€œæ–‡æ¡£å ä½ç¬¦â€ï¼Œé¿å…æ¯æ¬¡éƒ½èµ° multiaddr è§£æå†æŠ¥é”™
		if strings.Contains(p, "ExampleBootstrapPeerReplaceMe") {
			placeholder = append(placeholder, p)
			continue
		}

		m, err := ma.NewMultiaddr(p)
		if err != nil {
			invalid = append(invalid, p)
			continue
		}
		if _, err := libpeer.AddrInfoFromP2pAddr(m); err != nil {
			invalid = append(invalid, p)
			continue
		}
		valid = append(valid, p)
	}

	if s.logger != nil {
		// ä»…åœ¨å‘ç°é—®é¢˜æ—¶è¾“å‡ºå‘Šè­¦ï¼Œé¿å…æ­£å¸¸åœºæ™¯åˆ·å±
		if len(placeholder) > 0 {
			s.logger.Warnf(
				"p2p.discovery.bootstrap_peers_placeholder detected=%d (example=%s). "+
					"please replace with real multiaddr (/ip4/<ip>/tcp/28683/p2p/<peerId>) for this chain, or enable mDNS for LAN testing",
				len(placeholder),
				placeholder[0],
			)
		}
		if len(invalid) > 0 {
			s.logger.Warnf(
				"p2p.discovery.bootstrap_peers_invalid detected=%d (example=%s). "+
					"invalid peers will be ignored",
				len(invalid),
				invalid[0],
			)
		}
	}

	return valid
}

// SubscribeHints è®¢é˜…ç½‘ç»œè´¨é‡/ä¸šåŠ¡ Hintï¼Œè§¦å‘ä¸€æ¬¡çŸ­ä¿ƒå¼•å¯¼æ‹¨å·
//
// å½“æ”¶åˆ° EventTypeNetworkQualityChanged äº‹ä»¶æ—¶ï¼Œä¼šè§¦å‘ä¸€æ¬¡è½»é‡å¼•å¯¼æ‹¨å·å°è¯•ï¼Œ
// ç”¨äºåœ¨ç½‘ç»œè´¨é‡å˜åŒ–æˆ–ä¸šåŠ¡å±‚å¼‚å¸¸æ—¶å¿«é€Ÿä¿®å¤è¿æ¥ï¼Œè€Œä¸éœ€è¦ç­‰å¾…ä¸‹ä¸€ä¸ª discovery å‘¨æœŸã€‚
//
// - ctx: ç”Ÿå‘½å‘¨æœŸç”± Runtime ç®¡ç†ï¼ŒStop æ—¶ cancel
// - bus: EventBus å®ä¾‹ï¼Œå…è®¸ä¸º nilï¼ˆnil æ—¶ç›´æ¥è¿”å›ï¼‰
func (s *Service) SubscribeHints(ctx context.Context, bus event.EventBus) {
	if bus == nil || s == nil || s.host == nil {
		return
	}
	if s.opts == nil || len(s.opts.BootstrapPeers) == 0 {
		if s.logger != nil {
			s.logger.Debugf("p2p.discovery.hints skip: no bootstrap peers configured")
		}
		return
	}

	if s.logger != nil {
		s.logger.Infof("p2p.discovery.hints subscribe event=%s peers=%d", event.EventTypeNetworkQualityChanged, len(s.opts.BootstrapPeers))
	}

	_ = bus.Subscribe(event.EventTypeNetworkQualityChanged, func(_ event.Event) error {
		if s.logger != nil {
			s.logger.Debugf("p2p.discovery.hints trigger event=%s", event.EventTypeNetworkQualityChanged)
		}

		go func() {
			// ä½¿ç”¨çŸ­ç”Ÿå‘½å‘¨æœŸçš„ contextï¼ˆ30ç§’è¶…æ—¶ï¼‰ï¼Œé¿å…ä¸ Runtime çš„å¤§ ctx æ··åœ¨ä¸€èµ·
			localCtx, cancel := context.WithTimeout(ctx, 30*time.Second)
			defer cancel()

			// è½»é‡çŸ­ä¿ƒå°è¯•ï¼šå¤ç”¨ç°æœ‰çš„æ‹¨å·é€»è¾‘
			ok, _ := s.tryDialOnce(localCtx, s.opts.BootstrapPeers)
			if !ok {
				if s.logger != nil {
					s.logger.Debugf("p2p.discovery.hints first_try_failed retry_after=2s")
				}
				// å¦‚åŒæ—§å®ç°ï¼Œå†è½»å°è¯•ä¸€æ¬¡ï¼ˆ2s å»¶è¿Ÿï¼‰
				time.Sleep(2 * time.Second)
				_, _ = s.tryDialOnce(localCtx, s.opts.BootstrapPeers)
			}
		}()

		return nil
	})
}

// startMDNS å¯åŠ¨ mDNS æœåŠ¡
func (s *Service) startMDNS() error {
	// æ³¨æ„ï¼šmDNS çš„ service name å¿…é¡»åœ¨åŒä¸€å±€åŸŸç½‘å†…ä¿æŒä¸€è‡´ï¼Œå¦åˆ™èŠ‚ç‚¹äº’ç›¸â€œçœ‹ä¸è§â€ã€‚
	// ä¹‹å‰è¿™é‡Œç¡¬ç¼–ç ä¸º "weisyn-p2p"ï¼Œä¼šå¯¼è‡´ä¸é…ç½®ç³»ç»Ÿï¼ˆnode.discovery.mdns.service_nameï¼Œé€šå¸¸ä¸º weisyn-node-<networkNamespace>ï¼‰
	// ä¸ä¸€è‡´ï¼Œä»è€Œå‡ºç°â€œå±€åŸŸç½‘èŠ‚ç‚¹æ— æ³•å‘ç°â€çš„é—®é¢˜ã€‚
	serviceName := "weisyn-node"
	if s.opts != nil && strings.TrimSpace(s.opts.MDNSServiceName) != "" {
		serviceName = strings.TrimSpace(s.opts.MDNSServiceName)
	}

	s.mu.RLock()
	recordMDNSPeerFound := s.recordMDNSPeerFound
	recordMDNSConnectSuccess := s.recordMDNSConnectSuccess
	recordMDNSConnectFail := s.recordMDNSConnectFail
	updateLastMDNSTS := s.updateLastMDNSTS
	s.mu.RUnlock()

	notifee := &mdnsNotifee{
		host:                     s.host,
		logger:                   s.logger,
		eventBus:                 s.eventBus,
		recordMDNSPeerFound:      recordMDNSPeerFound,
		recordMDNSConnectSuccess: recordMDNSConnectSuccess,
		recordMDNSConnectFail:    recordMDNSConnectFail,
		updateLastMDNSTS:         updateLastMDNSTS,
	}

	s.mdnsSvc = mdns.NewMdnsService(s.host, serviceName, notifee)
	if err := s.mdnsSvc.Start(); err != nil {
		return fmt.Errorf("start mdns: %w", err)
	}

	if s.logger != nil {
		s.logger.Infof("p2p.discovery.mdns started service=%s", serviceName)
	}

	return nil
}

// getRendezvousNamespace è·å– Rendezvous å‘½åç©ºé—´
func (s *Service) getRendezvousNamespace() string {
	if s.opts != nil && s.opts.DiscoveryNamespace != "" {
		return s.opts.DiscoveryNamespace
	}
	// ç†è®ºä¸Š opts ç”± internal/config/p2p ç»Ÿä¸€ç”Ÿæˆå¹¶å¸¦æœ‰é»˜è®¤å€¼ï¼Œè¿™é‡Œè¿”å›ç©ºè¡¨ç¤ºä¸å¯ç”¨ DHT rendezvous
	return ""
}

// tryDialOnce è¿›è¡Œä¸€è½®å¼•å¯¼æ‹¨å·ï¼Œè¿”å›æ˜¯å¦è‡³å°‘è¿æ¥æˆåŠŸä¸€ä¸ªèŠ‚ç‚¹ï¼Œä»¥åŠæœ¬è½®æˆåŠŸæ•°é‡
func (s *Service) tryDialOnce(ctx context.Context, peers []string) (bool, int) {
	var connected int
	roundStart := time.Now()
	if s.logger != nil {
		s.logger.Debugf("p2p.discovery.dial_round begin peers=%d", len(peers))
	}

	// è®°å½•å°è¯•
	s.mu.RLock()
	recordAttempt := s.recordBootstrapAttempt
	s.mu.RUnlock()
	if recordAttempt != nil {
		recordAttempt()
	}
	// å§‹ç»ˆé€šè¿‡ EventBus å‘å¸ƒå¼•å¯¼å°è¯•äº‹ä»¶ï¼Œä¾¿äºç»Ÿä¸€è§‚æµ‹
	if s.eventBus != nil {
		s.eventBus.Publish("p2p.discovery.bootstrap.attempt", nil)
	}

	for _, peerAddr := range peers {
		if s.logger != nil {
			s.logger.Debugf("p2p.discovery.dial_peer start addr=%s", peerAddr)
		}
		m, err := ma.NewMultiaddr(peerAddr)
		if err != nil {
			if s.logger != nil {
				s.logger.Errorf("æ— æ•ˆçš„multiaddr: %s, error: %v", peerAddr, err)
			}
			continue
		}
		info, err := libpeer.AddrInfoFromP2pAddr(m)
		if err != nil {
			if s.logger != nil {
				s.logger.Errorf("æ— æ³•è§£æpeeråœ°å€: %s, error: %v", peerAddr, err)
			}
			continue
		}
		cctx, cancel := context.WithTimeout(ctx, 20*time.Second)
		perStart := time.Now()
		err = s.host.Connect(cctx, *info)
		if err == nil {
			connected++
			if s.logger != nil {
				s.logger.Infof("æˆåŠŸè¿æ¥åˆ°peer: %s (%s) duration=%s", info.ID, peerAddr, time.Since(perStart))
			}

			// å‘å¸ƒäº‹ä»¶
			if s.eventBus != nil {
				s.eventBus.Publish("p2p.peer.connected", map[string]interface{}{
					"peer_id": info.ID.String(),
					"source":  "bootstrap",
				})
			}
		} else {
			if s.logger != nil {
				// å°†å¼•å¯¼èŠ‚ç‚¹è¿æ¥å¤±è´¥é™çº§ä¸º Debug çº§åˆ«æ—¥å¿—ï¼Œé¿å…åœ¨å…¬ç½‘ç¯å¢ƒä¸‹äº§ç”Ÿå¤§é‡ Error å™ªéŸ³
				s.logger.Debugf("è¿æ¥peerå¤±è´¥: %s (%s), error: %v duration=%s", info.ID, peerAddr, err, time.Since(perStart))
			}
		}
		cancel()
	}
	if s.logger != nil {
		s.logger.Debugf("p2p.discovery.dial_round end success=%d duration=%s", connected, time.Since(roundStart))
	}

	// è®°å½•æˆåŠŸ
	if connected > 0 {
		s.mu.RLock()
		recordSuccess := s.recordBootstrapSuccess
		updateTS := s.updateLastBootstrapTS
		s.mu.RUnlock()
		if recordSuccess != nil {
			recordSuccess()
		}
		if updateTS != nil {
			updateTS()
		}
		// æ— è®ºæ˜¯å¦è®¾ç½® Prometheus å›è°ƒï¼Œç»Ÿä¸€é€šè¿‡ EventBus å‘å¸ƒä¸€æ¬¡æˆåŠŸäº‹ä»¶
		if s.eventBus != nil {
			s.eventBus.Publish("p2p.discovery.bootstrap.success", map[string]interface{}{
				"connected": connected,
			})
		}
	}

	return connected > 0, connected
}

// mdnsNotifee å®ç° mdns.Notifee æ¥å£
type mdnsNotifee struct {
	host                     lphost.Host
	logger                   logiface.Logger
	eventBus                 event.EventBus
	recordMDNSPeerFound      func()
	recordMDNSConnectSuccess func()
	recordMDNSConnectFail    func()
	updateLastMDNSTS         func()
}

func (n *mdnsNotifee) HandlePeerFound(info libpeer.AddrInfo) {
	if n.host == nil {
		return
	}

	if n.logger != nil {
		n.logger.Debugf("p2p.discovery.mdns peer found id=%s addrs=%d", info.ID.String(), len(info.Addrs))
	}

	// è®°å½• mDNS peer found
	if n.recordMDNSPeerFound != nil {
		n.recordMDNSPeerFound()
	}
	if n.updateLastMDNSTS != nil {
		n.updateLastMDNSTS()
	}

	// å¿½ç•¥è‡ªå·±
	if info.ID == n.host.ID() {
		return
	}

	// å¦‚æœå·²è¿æ¥ï¼Œè·³è¿‡
	if n.host.Network().Connectedness(info.ID) == libnetwork.Connected {
		return
	}

	// === mDNS é€åœ°å€æ‹¨å·ï¼ˆTCP ä¼˜å…ˆï¼‰===
	//
	// èƒŒæ™¯ï¼š
	// - mDNS å‘ç°é€šå¸¸å‘ç”Ÿåœ¨ LANï¼Œä½† libp2p å¯¹ AddrInfo çš„æ‹¨å·ä¼šå¹¶å‘/æ‹©ä¼˜ï¼Œé”™è¯¯ç»å¸¸è¢«èšåˆï¼Œæœ€ç»ˆåªçœ‹åˆ° â€œdial backoff/â€¦skipping N errorsâ€ï¼Œ
	//   å¯¼è‡´â€œå‘ç°äº†å´è¿ä¸ä¸Šâ€çš„æ ¹å› æ— æ³•å®šä½ã€‚
	// - å› æ­¤è¿™é‡ŒæŒ‰åœ°å€é€ä¸ªå°è¯•ï¼Œå¹¶ä¼˜å…ˆ TCPï¼Œå† QUICï¼Œè¾“å‡ºæ¯ä¸ª addr çš„åŸå§‹é”™è¯¯ã€‚
	ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second)
	defer cancel()

	addrs := info.Addrs
	if len(addrs) == 0 {
		// æ²¡åœ°å€ç›´æ¥è§†ä¸ºå¤±è´¥ï¼ˆmDNS ç†è®ºä¸Šä¸åº”å‡ºç°ï¼‰
		if n.logger != nil {
			n.logger.Debugf("p2p.discovery.mdns connect failed id=%s: no_addrs", info.ID)
		}
		if n.recordMDNSConnectFail != nil {
			n.recordMDNSConnectFail()
		}
		return
	}

	// ç§ç½‘ä¼˜å…ˆï¼ˆLAN åœºæ™¯ï¼‰
	var privateAddrs []ma.Multiaddr
	for _, a := range addrs {
		if ip, e := manet.ToIP(a); e == nil && ip != nil && ip.IsPrivate() {
			privateAddrs = append(privateAddrs, a)
		}
	}
	if len(privateAddrs) > 0 {
		addrs = privateAddrs
	}

	var tcpAddrs, quicAddrs, otherAddrs []ma.Multiaddr
	for _, a := range addrs {
		if _, e := a.ValueForProtocol(ma.P_TCP); e == nil {
			tcpAddrs = append(tcpAddrs, a)
			continue
		}
		if _, e := a.ValueForProtocol(ma.P_QUIC_V1); e == nil {
			quicAddrs = append(quicAddrs, a)
			continue
		}
		otherAddrs = append(otherAddrs, a)
	}
	ordered := append(append(append([]ma.Multiaddr{}, tcpAddrs...), quicAddrs...), otherAddrs...)

	var lastErr error
	for _, a := range ordered {
		// æ¯ä¸ªåœ°å€ç»™ä¸€ä¸ªå°è¶…æ—¶ï¼Œé¿å…å•ä¸ªååœ°å€æŠŠ mDNS è¿æ¥çª—å£æ‹–æ­»
		perCtx, perCancel := context.WithTimeout(ctx, 4*time.Second)
		err := n.host.Connect(perCtx, libpeer.AddrInfo{ID: info.ID, Addrs: []ma.Multiaddr{a}})
		perCancel()
		if err == nil {
			lastErr = nil
			break
		}
		lastErr = err
		if n.logger != nil {
			n.logger.Debugf("p2p.discovery.mdns connect failed id=%s addr=%s err=%v", info.ID, a.String(), err)
		}
	}

	if lastErr != nil {
		// è®°å½•å¤±è´¥
		if n.recordMDNSConnectFail != nil {
			n.recordMDNSConnectFail()
		}
		return
	}

	{
		if n.logger != nil {
			n.logger.Infof("p2p.discovery.mdns connected to %s", info.ID)
		}

		// è®°å½•æˆåŠŸ
		if n.recordMDNSConnectSuccess != nil {
			n.recordMDNSConnectSuccess()
		}

		// å‘å¸ƒäº‹ä»¶
		if n.eventBus != nil {
			n.eventBus.Publish("p2p.peer.connected", map[string]interface{}{
				"peer_id": info.ID.String(),
				"source":  "mdns",
			})
		}
	}
}

// schedulerLoop å¼•å¯¼èŠ‚ç‚¹è°ƒåº¦å™¨å¾ªç¯ï¼ˆå¸¦é€€é¿å’ŒåŠ¨æ€é—´éš”ï¼‰
func (s *Service) schedulerLoop(ctx context.Context, peers []string) {
	if len(peers) == 0 || s.host == nil {
		return
	}
	if s.logger != nil {
		s.logger.Infof("p2p.discovery.scheduler start peers=%d connected=%d", len(peers), len(s.host.Network().Peers()))
	}

	// åˆå§‹å¿«é€Ÿé€€é¿å°è¯• - ä¼˜åŒ–é€€é¿ç­–ç•¥ï¼Œå¢åŠ æˆåŠŸç‡
	b := NewBackoff(2*time.Second, 60*time.Second, 1.5, 0.1)
	for i := 0; i < 5; i++ {
		success, roundConn := s.tryDialOnce(ctx, peers)
		if s.logger != nil {
			s.logger.Infof("p2p.discovery.bootstrap_fast attempt=%d success=%t connected_round=%d", i+1, success, roundConn)
		}
		if success {
			break // å·²è¿ä¸Šå¼•å¯¼ï¼Œè·³å‡ºå¿«é€Ÿå°è¯•è¿›å…¥å‘¨æœŸæ£€æµ‹ç»´æŒ
		}
		d := b.Next()
		if s.logger != nil {
			s.logger.Infof("p2p.discovery.backoff sleep=%s", d)
		}
		select {
		case <-ctx.Done():
			return
		case <-time.After(d):
		}
	}

	// ğŸ”§ Phase 3: åŠ¨æ€å‘¨æœŸæ”¹é€  - ä½¿ç”¨æ–°ä¸Šé™DiscoveryMaxIntervalCapï¼ˆé»˜è®¤2mï¼Œä¸å†15mï¼‰
	baseInterval := s.opts.DiscoveryInterval
	if baseInterval == 0 {
		baseInterval = 5 * time.Minute
	}

	// ä½¿ç”¨æ–°é…ç½®çš„ä¸Šé™ï¼ˆé»˜è®¤2mï¼‰ä»£æ›¿AdvertiseIntervalï¼ˆ15mï¼‰
	maxInterval := s.opts.DiscoveryMaxIntervalCap
	if maxInterval == 0 {
		maxInterval = 2 * time.Minute
	}

	dynamic := baseInterval
	stableTarget := s.opts.MinPeers
	if stableTarget <= 0 {
		stableTarget = 8
	}
	stableCount := 0
	stableThreshold := 3

	// é‡ç½®å†·å´æ—¶é—´
	resetCoolDown := s.opts.DiscoveryResetCoolDown
	if resetCoolDown == 0 {
		resetCoolDown = 10 * time.Second
	}

	if s.logger != nil {
		// é…ç½®å¿«ç…§ä¿ç•™ Infoï¼Œä¾¿äºæ’éšœ
		s.logger.Infof("p2p.discovery.scheduler_config base_interval=%s max_interval=%s stable_target=%d threshold=%d reset_cooldown=%s",
			baseInterval, maxInterval, stableTarget, stableThreshold, resetCoolDown)
	}

	for {
		select {
		case <-ctx.Done():
			return
		default:
		}
		// å°è¯•ä¸€æ¬¡æ‹¨å·
		success, roundConn := s.tryDialOnce(ctx, peers)
		connected := len(s.host.Network().Peers())
		if s.logger != nil {
			// å‘¨æœŸæ€§è°ƒåº¦ä¸ºé«˜é¢‘äº‹ä»¶ï¼Œé™çº§ä¸º Debugï¼Œé¿å…åœ¨å…¬ç½‘ç¯å¢ƒåˆ·å±
			s.logger.Debugf("p2p.discovery.cycle interval=%s connected=%d success=%t connected_round=%d stableCount=%d target=%d", dynamic, connected, success, roundConn, stableCount, stableTarget)
		}
		if success {
			// ç½‘ç»œç¨³å®šå»¶åï¼šä½¿ç”¨æœ€å¤§é—´éš”ç­‰å¾…ä¸€æ®µæ—¶é—´ï¼Œé¿å…åˆšè¿ä¸Šåˆç«‹å³æ‰“æ‰°
			d := jitter(maxInterval, 0.1)
			if s.logger != nil {
				// ç¨³å®šå»¶è¿Ÿå±äºå†…éƒ¨è‡ªè°ƒåº¦ç»†èŠ‚ï¼Œä½¿ç”¨ Debug çº§åˆ«
				s.logger.Debugf("p2p.discovery.stable_delay sleep=%s", d)
			}
			select {
			case <-ctx.Done():
				return
			case <-time.After(d):
			}
			continue
		}
		// æ ¹æ®å½“å‰è¿æ¥æ•°è‡ªé€‚åº”è°ƒæ•´é—´éš”
		if connected >= stableTarget {
			stableCount++
			if stableCount >= stableThreshold {
				old := dynamic
				dynamic = dynamic * 2
				if dynamic > maxInterval {
					dynamic = maxInterval
				}
				if s.logger != nil {
					// é—´éš”è°ƒæ•´äº‹ä»¶ä¿ç•™ Infoï¼Œä¾¿äºè§‚å¯Ÿè‡ªé€‚åº”è¡Œä¸º
					s.logger.Infof("p2p.discovery.interval_update from=%s to=%s reason=stable", old, dynamic)
				}
			}
		} else {
			// ä¸ç¨³å®šåˆ™æ¢å¤ä¸ºåŸºç¡€é—´éš”
			if dynamic != baseInterval {
				old := dynamic
				dynamic = baseInterval
				if s.logger != nil {
					// é—´éš”è°ƒæ•´äº‹ä»¶ä¿ç•™ Info
					s.logger.Infof("p2p.discovery.interval_update from=%s to=%s reason=unstable", old, dynamic)
				}
			}
			stableCount = 0
		}
		// ğŸ”§ Phase 3: ç­‰å¾…ä¸‹ä¸ªå‘¨æœŸï¼Œæ”¯æŒé‡ç½®äº‹ä»¶
		d := jitter(dynamic, 0.1)
		if s.logger != nil {
			// å‘¨æœŸ sleep ä¸ºé«˜é¢‘äº‹ä»¶ï¼Œé™çº§ä¸º Debug
			s.logger.Debugf("p2p.discovery.sleep sleep=%s", d)
		}
		select {
		case <-ctx.Done():
			return
		case <-s.schedulerResetChan:
			// æ”¶åˆ°é‡ç½®äº‹ä»¶ï¼šæ£€æŸ¥å†·å´æœŸï¼Œé€šè¿‡åˆ™é‡ç½®é—´éš”å¹¶ç«‹å³è§¦å‘ä¸€è½®æ‹¨å·
			s.resetMu.Lock()
			now := time.Now()
			if now.Sub(s.lastResetAt) < resetCoolDown {
				// å†·å´æœŸå†…ï¼Œå¿½ç•¥é‡ç½®
				if s.logger != nil {
					s.logger.Debugf("p2p.discovery.scheduler_reset ignored reason=cooldown elapsed=%s", now.Sub(s.lastResetAt))
				}
				s.resetMu.Unlock()
				continue
			}
			s.lastResetAt = now
			s.resetMu.Unlock()

			// é‡ç½®é—´éš”åˆ°åŸºç¡€å€¼
			old := dynamic
			dynamic = baseInterval
			stableCount = 0
			if s.logger != nil {
				s.logger.Infof("p2p.discovery.scheduler_reset from=%s to=%s", old, dynamic)
			}

			// ç«‹å³è§¦å‘ä¸€è½®æ‹¨å·ï¼ˆä¸ç­‰å¾…ï¼‰
			continue
		case <-time.After(d):
		}
	}
}

// ===================== DHT Rendezvous å‘ç°çŠ¶æ€æœº =====================

type dhtDiscoveryMode string

const (
	dhtModeBootstrap dhtDiscoveryMode = "bootstrap"
	dhtModeSteady    dhtDiscoveryMode = "steady"
	dhtModeIsolated  dhtDiscoveryMode = "isolated"

	// åœ¨ Bootstrap é˜¶æ®µæœŸæœ›çš„æœ€å° DHT è·¯ç”±è¡¨è§„æ¨¡/è¿æ¥æ•°çš„é»˜è®¤å€¼
	dhtBootstrapMinPeers = 3
	// Bootstrap é˜¶æ®µæœ€é•¿æŒç»­æ—¶é—´ï¼Œè¶…å‡ºåè¿›å…¥ Isolated æ¨¡å¼
	dhtBootstrapMaxDuration = 5 * time.Minute
	// Bootstrap é˜¶æ®µçš„åŸºç¡€è½®è¯¢é—´éš”
	dhtBootstrapInterval = 5 * time.Second

	// Steady é˜¶æ®µçš„é»˜è®¤è½®è¯¢é—´éš”ï¼ˆè‹¥æœªä»é…ç½®ä¸­è·å–åˆ°æ›´åˆé€‚çš„å€¼ï¼‰
	dhtSteadyIntervalDefault = 60 * time.Second

	// Isolated é˜¶æ®µçš„é€€é¿å‚æ•°ï¼ˆæŒ‡æ•°é€€é¿ï¼‰
	dhtIsolatedInitialInterval = 5 * time.Second
	dhtIsolatedMaxInterval     = 10 * time.Minute

	// æ¯è½® DHT å‘ç°çš„è¶…æ—¶æ—¶é—´ï¼ˆä¸åŒæ¨¡å¼å¯åŒºåˆ†ï¼Œä½†ä¿æŒä¿å®ˆä¸Šé™ï¼‰
	dhtBootstrapRoundTimeout = 60 * time.Second
	dhtSteadyRoundTimeout    = 60 * time.Second
	dhtIsolatedRoundTimeout  = 30 * time.Second
)

// dhtDiscoveryState è®°å½•æŸä¸ª rendezvous namespace ä¸‹çš„ DHT å‘ç°çŠ¶æ€
type dhtDiscoveryState struct {
	mode            dhtDiscoveryMode
	lastSuccessTime time.Time
	successCount    int
	failureCount    int
	currentInterval time.Duration // ä¸‹ä¸€è½® sleep çš„åŸºç¡€é—´éš”
	bootstrapStart  time.Time     // è¿›å…¥ bootstrap æ¨¡å¼çš„æ—¶é—´
}

// getDHTExpectedMinPeers è¿”å›å½“å‰ç¯å¢ƒä¸‹ DHT æœŸæœ›çš„æœ€å° peers æ•°é‡
// ä¼˜å…ˆä½¿ç”¨é…ç½®ï¼ˆOptions.DiscoveryExpectedMinPeersï¼‰ï¼Œå¦åˆ™é€€å›é»˜è®¤å€¼ã€‚
func (s *Service) getDHTExpectedMinPeers() int {
	if s != nil && s.opts != nil && s.opts.DiscoveryExpectedMinPeers > 0 {
		return s.opts.DiscoveryExpectedMinPeers
	}
	return dhtBootstrapMinPeers
}

// findPeersLoop é€šè¿‡ DHT rendezvous æŒç»­å‘ç°å¯¹ç«¯å¹¶å°è¯•è¿æ¥
func (s *Service) findPeersLoop(ctx context.Context, ns string) {
	if s.host == nil {
		if s.logger != nil {
			s.logger.Warnf("p2p.discovery.dht_loop host=nil")
		}
		return
	}
	if s.logger != nil {
		s.logger.Infof("p2p.discovery.dht_loop starting ns=%s host_id=%s", ns, s.host.ID().String())
	}

	// åˆå§‹åŒ–å½“å‰ namespace çš„ DHT çŠ¶æ€æœº
	state := &dhtDiscoveryState{
		mode:            dhtModeBootstrap,
		currentInterval: dhtBootstrapInterval,
		bootstrapStart:  time.Now(),
	}

	// ä¸»å¾ªç¯ï¼šæŒç»­é‡å¯DHTå‘ç°
	for {
		select {
		case <-ctx.Done():
			if s.logger != nil {
				s.logger.Infof("p2p.discovery.dht_loop context_cancelled_main ns=%s", ns)
			}
			return
		default:
		}

		// ä¸ºæœ¬è½® DHT å‘ç°åˆ›å»ºçŸ­ç”Ÿå‘½å‘¨æœŸçš„ ctxï¼Œé˜²æ­¢å†…éƒ¨ goroutine é•¿æœŸæŒ‚ä½
		var roundTimeout time.Duration
		switch state.mode {
		case dhtModeIsolated:
			roundTimeout = dhtIsolatedRoundTimeout
		case dhtModeSteady:
			roundTimeout = dhtSteadyRoundTimeout
		default:
			roundTimeout = dhtBootstrapRoundTimeout
		}

		roundCtx, cancel := context.WithTimeout(ctx, roundTimeout)
		// å¯åŠ¨ä¸€è½®DHTå‘ç°
		shouldRestart, discovered, rtSize := s.runDHTDiscoveryRound(roundCtx, ns)
		cancel() // æ˜¾å¼ç»“æŸæœ¬è½®ï¼Œé‡Šæ”¾ libp2p å†…éƒ¨èµ„æº

		now := time.Now()

		// æ›´æ–°çŠ¶æ€æœºç»Ÿè®¡
		if discovered {
			state.successCount++
			state.lastSuccessTime = now
			state.failureCount = 0
		} else {
			state.failureCount++
		}

		// ä¼°ç®—â€œæ˜¯å¦è¶³å¤Ÿå¥åº·â€ï¼šåŸºäº DHT è·¯ç”±è¡¨å¤§å°ä¸å½“å‰è¿æ¥æ•°
		minPeers := s.getDHTExpectedMinPeers()
		enoughPeers := rtSize >= minPeers
		if !enoughPeers && s.host != nil {
			if len(s.host.Network().Peers()) >= minPeers {
				enoughPeers = true
			}
		}

		// æ¨¡å¼è¿ç§»
		switch state.mode {
		case dhtModeBootstrap:
			if discovered && enoughPeers {
				// ğŸ”§ Phase 3: åˆ‡æ¢åˆ°ç¨³å®šé˜¶æ®µï¼Œä½¿ç”¨æ–°é…ç½®DHTSteadyIntervalCapï¼ˆé»˜è®¤2mï¼‰
				state.mode = dhtModeSteady
				// ä½¿ç”¨æ–°çš„ä¸Šé™é…ç½®ï¼Œä¸å†ä½¿ç”¨AdvertiseIntervalï¼ˆ15mï¼‰
				steadyInterval := dhtSteadyIntervalDefault
				if s.opts != nil && s.opts.DHTSteadyIntervalCap > 0 {
					steadyInterval = s.opts.DHTSteadyIntervalCap
				}
				state.currentInterval = steadyInterval
				state.bootstrapStart = time.Time{}
				if s.logger != nil {
					s.logger.Infof("p2p.discovery.dht_loop mode_transition ns=%s from=%s to=%s reason=enough_peers rt_size=%d interval=%s",
						ns, dhtModeBootstrap, dhtModeSteady, rtSize, steadyInterval)
				}
			} else {
				// Bootstrap é•¿æ—¶é—´æ— ä»»ä½•æˆåŠŸå‘ç°ï¼Œè§†ä¸ºå­¤ç«‹ç¯å¢ƒ
				if state.bootstrapStart.IsZero() {
					state.bootstrapStart = now
				}
				if state.successCount == 0 && now.Sub(state.bootstrapStart) >= dhtBootstrapMaxDuration {
					state.mode = dhtModeIsolated
					state.currentInterval = dhtIsolatedInitialInterval
					if s.logger != nil {
						s.logger.Warnf("p2p.discovery.dht_loop mode_transition ns=%s from=%s to=%s reason=bootstrap_timeout",
							ns, dhtModeBootstrap, dhtModeIsolated)
					}
				}
			}
		case dhtModeSteady:
			// ç¨³å®šé˜¶æ®µå¦‚æœè·¯ç”±è¡¨å®Œå…¨æ¸…ç©ºï¼Œå›é€€åˆ° Bootstrap é‡æ–°ç§¯æå‘ç°
			if rtSize == 0 {
				state.mode = dhtModeBootstrap
				state.successCount = 0
				state.failureCount = 0
				state.currentInterval = dhtBootstrapInterval
				state.bootstrapStart = now
				if s.logger != nil {
					s.logger.Warnf("p2p.discovery.dht_loop mode_transition ns=%s from=%s to=%s reason=rt_empty",
						ns, dhtModeSteady, dhtModeBootstrap)
				}
			}
		case dhtModeIsolated:
			if discovered && enoughPeers {
				// ğŸ”§ Phase 3: ä»å­¤ç«‹æ¢å¤ï¼Œç›´æ¥è¿›å…¥ç¨³å®šé˜¶æ®µï¼Œä½¿ç”¨æ–°é…ç½®
				state.mode = dhtModeSteady
				steadyInterval := dhtSteadyIntervalDefault
				if s.opts != nil && s.opts.DHTSteadyIntervalCap > 0 {
					steadyInterval = s.opts.DHTSteadyIntervalCap
				}
				state.currentInterval = steadyInterval
				state.successCount = 1
				state.failureCount = 0
				state.bootstrapStart = time.Time{}
				if s.logger != nil {
					s.logger.Infof("p2p.discovery.dht_loop mode_transition ns=%s from=%s to=%s reason=recovered",
						ns, dhtModeIsolated, dhtModeSteady)
				}
			} else {
				// åœ¨å­¤ç«‹æ¨¡å¼ä¸‹ä½¿ç”¨æŒ‡æ•°é€€é¿ï¼Œé€æ­¥æ‹‰é•¿è½®è¯¢é—´éš”ï¼Œé¿å…ç©ºè·‘
				if state.currentInterval <= 0 {
					state.currentInterval = dhtIsolatedInitialInterval
				} else {
					next := state.currentInterval * 2
					if next > dhtIsolatedMaxInterval {
						next = dhtIsolatedMaxInterval
					}
					state.currentInterval = next
				}
			}
		}
		if !shouldRestart {
			// å¦‚æœä¸éœ€è¦é‡å¯ï¼ˆä¾‹å¦‚contextå–æ¶ˆæˆ– rendezvous ä¸å¯ç”¨ï¼‰ï¼Œåˆ™é€€å‡ºä¸»å¾ªç¯
			return
		}

		// æ ¹æ®å½“å‰æ¨¡å¼é€‰æ‹©ä¸‹ä¸€è½®çš„ç­‰å¾…é—´éš”å¹¶åŠ å…¥è½»å¾®æŠ–åŠ¨
		sleepBase := state.currentInterval
		if sleepBase <= 0 {
			// å„æ¨¡å¼çš„å…œåº•é—´éš”
			switch state.mode {
			case dhtModeIsolated:
				sleepBase = dhtIsolatedInitialInterval
			case dhtModeSteady:
				sleepBase = dhtSteadyIntervalDefault
			default:
				sleepBase = dhtBootstrapInterval
			}
			state.currentInterval = sleepBase
		}
		d := jitter(sleepBase, 0.1)
		if s.logger != nil {
			s.logger.Debugf("p2p.discovery.dht_loop sleep_before_next_round ns=%s mode=%s base=%s sleep=%s",
				ns, state.mode, sleepBase, d)
		}

		// ğŸ”§ Phase 3: æ”¯æŒé‡ç½®äº‹ä»¶
		resetCoolDown := s.opts.DiscoveryResetCoolDown
		if resetCoolDown == 0 {
			resetCoolDown = 10 * time.Second
		}

		select {
		case <-ctx.Done():
			if s.logger != nil {
				s.logger.Infof("p2p.discovery.dht_loop context_cancelled_during_wait ns=%s", ns)
			}
			return
		case <-s.dhtResetChan:
			// æ”¶åˆ°é‡ç½®äº‹ä»¶ï¼šæ£€æŸ¥å†·å´æœŸï¼Œé€šè¿‡åˆ™ç«‹å³è§¦å‘ä¸‹ä¸€è½®
			s.resetMu.Lock()
			now := time.Now()
			if now.Sub(s.lastResetAt) < resetCoolDown {
				// å†·å´æœŸå†…ï¼Œå¿½ç•¥é‡ç½®
				if s.logger != nil {
					s.logger.Debugf("p2p.discovery.dht_reset ignored reason=cooldown elapsed=%s", now.Sub(s.lastResetAt))
				}
				s.resetMu.Unlock()
				continue
			}
			s.lastResetAt = now
			s.resetMu.Unlock()

			if s.logger != nil {
				s.logger.Infof("p2p.discovery.dht_reset triggered ns=%s mode=%s", ns, state.mode)
			}

			// ç«‹å³è§¦å‘ä¸‹ä¸€è½®ï¼ˆä¸ç­‰å¾…ï¼‰
			continue
		case <-time.After(d):
			// ç»§ç»­ä¸‹ä¸€è½®å¾ªç¯
		}
	}
}

// runDHTDiscoveryRound è¿è¡Œä¸€è½®DHTå‘ç°
// è¿”å›å€¼ï¼š
//   - bool: æ˜¯å¦éœ€è¦åœ¨é€šé“å…³é—­åé‡å¯ä¸‹ä¸€è½®
//   - bool: æœ¬è½®æ˜¯å¦è‡³å°‘å‘ç°è¿‡ä¸€ä¸ªâ€œæœ‰æ•ˆâ€peerï¼ˆéè‡ªèº«ä¸”å¸¦åœ°å€ï¼‰
//   - int:  æœ¬è½®ç»“æŸæ—¶çš„ DHT è·¯ç”±è¡¨è§„æ¨¡å¿«ç…§
func (s *Service) runDHTDiscoveryRound(ctx context.Context, ns string) (bool, bool, int) {
	discovered := false
	rtSize := 0
	if s.logger != nil {
		s.logger.Infof("ğŸ”„ DHTé‡å¯å¾ªç¯å¼€å§‹ ns=%s", ns)
		s.logger.Infof("p2p.discovery.dht_loop calling_FindPeers ns=%s", ns)
	}

	s.mu.RLock()
	rendezvous := s.rendezvousRouting
	s.mu.RUnlock()

	if rendezvous == nil {
		if s.logger != nil {
			s.logger.Warnf("p2p.discovery.dht_loop rendezvous_not_available ns=%s", ns)
		}
		return false, false, 0
	}

	pch, err := rendezvous.AdvertiseAndFindPeers(ctx, ns)
	if err != nil {
		if s.logger != nil {
			s.logger.Warnf("p2p.discovery.rendezvous find_peers_error ns=%s err=%v", ns, err)
		}
		return false, false, rendezvous.RoutingTableSize() // å‡ºé”™æ—¶ä¸é‡å¯
	}

	if s.logger != nil {
		s.logger.Infof("p2p.discovery.dht_loop peer_channel_ready ns=%s, waiting_for_peers", ns)
		// æ£€æŸ¥ DHT çŠ¶æ€ï¼ˆé€šè¿‡æ¥å£è·å–è·¯ç”±è¡¨å¤§å°ï¼‰
		rtSize = rendezvous.RoutingTableSize()
		if rtSize > 0 {
			s.logger.Infof("p2p.discovery.dht_loop dht_rt_size=%d connected_peers=%d",
				rtSize, len(s.host.Network().Peers()))
		}
	}

	for {
		select {
		case <-ctx.Done():
			if s.logger != nil {
				s.logger.Infof("p2p.discovery.dht_loop round_done ns=%s reason=context_done err=%v", ns, ctx.Err())
			}
			// è¿™é‡Œçš„ ctx æ˜¯â€œæœ¬è½® roundCtxâ€ï¼Œè¶…æ—¶/å–æ¶ˆåº”å½“è§†ä¸ºâ€œç»“æŸæœ¬è½®å¹¶è¿›å…¥ä¸‹ä¸€è½®â€ï¼Œ
			// å¦åˆ™ä¼šå¯¼è‡´ DHT å‘ç°å¾ªç¯åªè¿è¡Œä¸€æ¬¡ï¼šA å…ˆå¯åŠ¨ã€B åå¯åŠ¨æ—¶ï¼ŒA å¾ˆå¯èƒ½æ°¸è¿œå‘ç°ä¸åˆ° Bã€‚
			//
			// çœŸæ­£çš„é€€å‡ºç”± findPeersLoop å¤–å±‚ ctx.Done() æ§åˆ¶ã€‚
			rtSize = rendezvous.RoutingTableSize()
			return true, discovered, rtSize
		case info, ok := <-pch:
			if !ok {
				if s.logger != nil {
					// DHT/Rendezvous åœ¨â€œæœ¬è½®æ—  peer å¯è¿”å›â€æ—¶å…³é—­ channel å±äºå¸¸è§è¡Œä¸ºï¼Œä¸åº”æŒ‰å¼‚å¸¸ Warn åˆ·å±ã€‚
					// ä»è¿”å› should_restart=true ä»¥è¿›å…¥ä¸‹ä¸€è½®å‘ç°ã€‚
					s.logger.Debugf("p2p.discovery.dht_loop peer_channel_closed ns=%s, should_restart=true", ns)
					// æ£€æŸ¥ DHT çŠ¶æ€ï¼ˆé€šè¿‡æ¥å£è·å–è·¯ç”±è¡¨å¤§å°ï¼‰
					rtSize = rendezvous.RoutingTableSize()
					if rtSize > 0 {
						s.logger.Infof("p2p.discovery.dht_loop final_dht_rt_size=%d connected_peers=%d",
							rtSize, len(s.host.Network().Peers()))
					}
				}
				return true, discovered, rtSize // é€šé“å…³é—­æ—¶éœ€è¦é‡å¯
			}

			// å¤„ç†å‘ç°çš„peer
			if s.handleDiscoveredPeer(ctx, info, ns) {
				discovered = true
			}
		}
	}
}

// handleDiscoveredPeer å¤„ç†å‘ç°çš„peer
// è¿”å›å€¼ï¼š
//   - bool: æ˜¯å¦ä¸ºä¸€ä¸ªâ€œæœ‰æ•ˆâ€peerï¼ˆéè‡ªèº«ä¸”å¸¦åœ°å€ï¼‰ï¼Œç”¨äºä¸Šå±‚ç»Ÿè®¡å‘ç°æˆåŠŸæ¬¡æ•°
func (s *Service) handleDiscoveredPeer(ctx context.Context, info libpeer.AddrInfo, ns string) bool {
	if s.logger != nil {
		// DHT å‘ç° peer åœ¨ä¸»ç½‘ç¯å¢ƒä¸‹ä¼šéå¸¸é¢‘ç¹ï¼š
		// - ä¿ç•™ä¸€æ¡ç²¾ç®€çš„ Info æ—¥å¿—ï¼Œä¾¿äºç¡®è®¤å‘ç°è¡Œä¸ºï¼›
		// - è¯¦ç»†ä¿¡æ¯ï¼ˆaddrs/self_id å¯¹æ¯”ï¼‰é™çº§ä¸º Debugï¼Œé¿å…åˆ·å±ã€‚
		s.logger.Infof("p2p.discovery.dht_loop peer_discovered id=%s addrs=%d ns=%s",
			info.ID.String(), len(info.Addrs), ns)
		s.logger.Debugf("p2p.discovery.dht_loop peer_check discovered_id=%s self_id=%s", info.ID.String(), s.host.ID().String())
	}

	if info.ID == "" || info.ID == s.host.ID() {
		if s.logger != nil {
			reason := func() string {
				if info.ID == "" {
					return "empty_id"
				}
				return "self_id"
			}()
			// è‡ªèº«/ç©ºIDè·³è¿‡ä¸ºé¢„æœŸè¡Œä¸ºï¼Œä½¿ç”¨ Debug çº§åˆ«
			s.logger.Debugf("â© è·³è¿‡peer (åŸå› : %s): %s", reason, info.ID.String())
		}
		return false
	}

	// å¦‚æœ DHT è¿”å›çš„èŠ‚ç‚¹æ²¡æœ‰ä»»ä½•åœ°å€ï¼ˆä»…æœ‰ IDï¼‰ï¼Œå°è¯•é€šè¿‡åœ°å€ç®¡ç†å™¨è·å–
	if len(info.Addrs) == 0 {
		if s.addrManager != nil {
			// å°è¯•ä»åœ°å€ç®¡ç†å™¨è·å–åœ°å€ï¼ˆä¼šè§¦å‘å¼‚æ­¥æŸ¥è¯¢+é‡å‘ç°é˜Ÿåˆ—ï¼‰
			addrs := s.addrManager.GetAddrs(info.ID)
			if len(addrs) == 0 {
				// ğŸ†• ä¼˜åŒ–ï¼šå¦‚æœè¯¥peeræœ€è¿‘æœ‰è¿æ¥è®°å½•ï¼Œæ ‡è®°ä¸ºé«˜ä¼˜å…ˆçº§é‡å‘ç°
				if s.wasRecentlyConnected(info.ID) {
					s.addrManager.TriggerRediscovery(info.ID, true) // high priority
					if s.logger != nil {
						s.logger.Infof("p2p.discovery.dht_loop peer_no_addrs id=%s ns=%s, high_priority_rediscovery_triggered",
							info.ID.String(), ns)
					}
				} else {
					if s.logger != nil {
						s.logger.Warnf("p2p.discovery.dht_loop peer_no_addrs id=%s ns=%s, rediscovery_triggered",
							info.ID.String(), ns)
					}
				}
				return false
			}
			// ä½¿ç”¨åœ°å€ç®¡ç†å™¨è¿”å›çš„åœ°å€
			info.Addrs = addrs
		} else {
			// ä¸åº”è¯¥å‘ç”Ÿï¼šAddrManager ç°åœ¨æ˜¯å¼ºåˆ¶å¯ç”¨çš„åŸºç¡€è®¾æ–½
			if s.logger != nil {
				s.logger.Errorf("p2p.discovery.dht_loop addr_manager_nil (unexpected) peer=%s ns=%s",
					info.ID.String(), ns)
			}
			return false
		}
	}

	// èµ°åˆ°è¿™é‡Œè¯´æ˜æ˜¯ä¸€ä¸ªâ€œæœ‰æ•ˆâ€peer
	validPeer := true

	if s.logger != nil {
		// æ¯æ¬¡è¿æ¥å°è¯•ä¸ºé«˜é¢‘äº‹ä»¶ï¼Œä½¿ç”¨ Debug çº§åˆ«ï¼Œé¿å… Info å™ªéŸ³
		s.logger.Debugf("p2p.discovery.dht_loop connecting_to_peer id=%s addrs=%v", info.ID.String(), info.Addrs)
	}

	// === LAN ä¼˜å…ˆæ‹¨å·ç­–ç•¥ï¼ˆå…³é”®ä¿®å¤ï¼‰===
	// ç›®æ ‡ï¼šå³ä½¿æ²¡æœ‰ mDNSï¼Œåªè¦æ¥å…¥åŒä¸€ DHT/åŒä¸€æ‰¹ bootstrapï¼Œä¹Ÿåº”å°½é‡â€œé—´æ¥å‘ç°å¹¶ç›´è¿â€å±€åŸŸç½‘èŠ‚ç‚¹ã€‚
	// ç°å®é—®é¢˜ï¼šå¾ˆå¤šç½‘ç»œä¸æ”¯æŒ NAT hairpinï¼›è‹¥å¯¹æ–¹åªå…¬å‘Šå…¬ç½‘åœ°å€ï¼Œå³ä½¿åœ¨åŒä¸€ LAN å†…ä¹Ÿå¯èƒ½æ‹¨ä¸é€šã€‚
	//
	// ç­–ç•¥ï¼š
	// - è‹¥æˆ‘ä»¬è‡ªèº«â€œçœ‹èµ·æ¥å¤„äº LANâ€ï¼ˆå¯ç”¨ mDNS æˆ–æœ¬æœº Host åœ°å€åŒ…å«ç§ç½‘ IPï¼‰ï¼Œå¹¶ä¸”å¯¹æ–¹ AddrInfo ä¸­åŒ…å«ç§ç½‘åœ°å€ï¼Œ
	//   åˆ™å…ˆä»…ç”¨ç§ç½‘åœ°å€å°è¯•ä¸€æ¬¡ Connectï¼›å¤±è´¥åå†å›é€€åˆ°å…¨é‡åœ°å€ï¼ˆå«å…¬ç½‘/relayï¼‰ã€‚
	isLANMode := s.opts != nil && s.opts.EnableMDNS
	if !isLANMode && s.host != nil {
		for _, a := range s.host.Addrs() {
			if ip, e := manet.ToIP(a); e == nil && ip != nil && ip.IsPrivate() {
				isLANMode = true
				break
			}
		}
	}

	var privateAddrs []ma.Multiaddr
	for _, a := range info.Addrs {
		if ip, e := manet.ToIP(a); e == nil && ip != nil && ip.IsPrivate() {
			privateAddrs = append(privateAddrs, a)
		}
	}

	cctx, cancel := context.WithTimeout(context.Background(), 20*time.Second)
	defer cancel()

	// ä½¿ç”¨åœ°å€ç®¡ç†å™¨æ·»åŠ DHTå‘ç°çš„åœ°å€ï¼ˆåˆ†çº§TTLç®¡ç†ï¼‰
	// AddrManager ç°åœ¨æ˜¯å¼ºåˆ¶å¯ç”¨çš„åŸºç¡€è®¾æ–½ï¼Œåº”è¯¥å§‹ç»ˆå¯ç”¨
	if s.addrManager != nil {
		s.addrManager.AddDHTAddr(info.ID, info.Addrs)
	}

	var err error
	if isLANMode && len(privateAddrs) > 0 {
		// å…³é”®æ”¹è¿›ï¼š
		// 1) ç§ç½‘åœºæ™¯ä¸‹ï¼Œlibp2p å¯èƒ½ä¼šåœ¨ AddrInfo å†…éƒ¨åšåœ°å€é€‰æ‹©/å¹¶å‘æ‹¨å·ï¼›ä¸€æ—¦å‘½ä¸­ååœ°å€ï¼ˆå°¤å…¶æ˜¯ relay/QUICï¼‰
		//    é”™è¯¯ä¼šè¢«èšåˆæˆ â€œ...skipping N errorsâ€ï¼Œå¯¼è‡´æˆ‘ä»¬éš¾ä»¥çœ‹åˆ°çœŸæ­£çš„å¤±è´¥åŸå› ã€‚
		// 2) å®é™…ä¸Š LAN å†…æœ€ç¨³çš„æ˜¯ TCPï¼Œå…¶æ¬¡æ‰æ˜¯ QUICï¼›å› æ­¤è¿™é‡ŒæŒ‰ä¼ è¾“åšä¼˜å…ˆçº§å¹¶é€ä¸ªåœ°å€å°è¯•æ‹¨å·ï¼Œ
		//    æ¯ä¸ª addr çš„çœŸå®é”™è¯¯éƒ½ä¼šè¢«è®°å½•ä¸‹æ¥ï¼ˆdebug çº§åˆ«ï¼‰ã€‚
		var tcpAddrs, quicAddrs, otherAddrs []ma.Multiaddr
		for _, a := range privateAddrs {
			if _, e := a.ValueForProtocol(ma.P_TCP); e == nil {
				tcpAddrs = append(tcpAddrs, a)
				continue
			}
			if _, e := a.ValueForProtocol(ma.P_QUIC_V1); e == nil {
				quicAddrs = append(quicAddrs, a)
				continue
			}
			otherAddrs = append(otherAddrs, a)
		}
		ordered := append(append(append([]ma.Multiaddr{}, tcpAddrs...), quicAddrs...), otherAddrs...)

		if s.logger != nil {
			s.logger.Debugf(
				"p2p.discovery.dht_loop dialing_private_first id=%s private_addrs=%d tcp=%d quic=%d other=%d",
				info.ID.String(), len(privateAddrs), len(tcpAddrs), len(quicAddrs), len(otherAddrs),
			)
		}

		// å†™å…¥ç§ç½‘åœ°å€ï¼ˆç¡®ä¿ peerstore æœ‰å¯æ‹¨å·çš„ LAN åœ°å€ï¼‰
		// AddrManager ç°åœ¨æ˜¯å¼ºåˆ¶å¯ç”¨çš„åŸºç¡€è®¾æ–½ï¼Œåº”è¯¥å§‹ç»ˆå¯ç”¨
		if s.addrManager != nil {
			s.addrManager.AddDHTAddr(info.ID, privateAddrs)
		}

		for _, a := range ordered {
			tmp := libpeer.AddrInfo{ID: info.ID, Addrs: []ma.Multiaddr{a}}
			perCtx, perCancel := context.WithTimeout(cctx, 10*time.Second)
			perErr := s.host.Connect(perCtx, tmp)
			perCancel()
			if perErr == nil {
				err = nil
				break
			}
			// âœ… è‡ªæ„ˆï¼šå¦‚æœè¯¥åœ°å€å¯¹åº”çš„ remote peerID ä¸é¢„æœŸä¸ä¸€è‡´ï¼Œç«‹å³çº é”™ addr->peer æ˜ å°„ï¼Œé¿å…åç»­æŒç»­è¿é”™äººã€‚
			_ = s.healPeerIDMismatch(info.ID, a, perErr)
			// è¿™é‡Œä¿ç•™æ¯ä¸ªåœ°å€çš„åŸå§‹é”™è¯¯ï¼Œä¾¿äºç›´æ¥å®šä½â€œæ˜¯è¢« gater æ‹¦äº† / æ—  transport / æ¡æ‰‹å¤±è´¥ / è¿æ¥è¢«å¤ä½â€ç­‰ã€‚
			if s.logger != nil {
				s.logger.Debugf("p2p.discovery.dht_loop private_dial_failed id=%s addr=%s err=%v", info.ID.String(), a.String(), perErr)
			}
			err = perErr
		}
	}
	if err != nil {
		// å›é€€ï¼šå…¨é‡åœ°å€ï¼ˆå¯èƒ½åŒ…å«å…¬ç½‘/relayï¼‰
		err = s.host.Connect(cctx, info)
	}
	if err == nil {
		if s.logger != nil {
			// æˆåŠŸè¿æ¥ä¿ç•™ Infoï¼Œä¾¿äºè§‚æµ‹ç½‘ç»œè¿é€šæ€§
			s.logger.Infof("p2p.discovery.dht_loop connect_success id=%s", info.ID.String())
		}

		// å‘å¸ƒäº‹ä»¶
		if s.eventBus != nil {
			s.eventBus.Publish("p2p.peer.connected", map[string]interface{}{
				"peer_id": info.ID.String(),
				"source":  "dht",
			})
		}
	} else {
		// âœ… è‡ªæ„ˆï¼ˆå…œåº•ï¼‰ï¼šfallback Connect() è¿”å›çš„èšåˆé”™è¯¯ä¸­å¯èƒ½åŒ…å« peer id mismatch çš„ addr åˆ—è¡¨ï¼Œå°è¯•æ‰¹é‡çº é”™ã€‚
		s.healPeerIDMismatchFromAggregateError(info.ID, err)
		if s.logger != nil {
			// DHT å‘ç°é˜¶æ®µåœ¨å…¬ç½‘ç¯å¢ƒä¸‹è¿æ¥å¤±è´¥å¾ˆå¸¸è§ï¼ˆå™ªå£°å¤§ï¼‰ï¼Œä½†åœ¨ LAN/ç§ç½‘äº’è”åœºæ™¯ä¸‹ï¼Œ
			// "å‘ç°åˆ°äº†å´è¿ä¸ä¸Š"æ˜¯å¿…é¡»è¢«çœ‹è§çš„å…³é”®æ•…éšœä¿¡å·ã€‚
			//
			// ä¼˜åŒ–åçš„åˆ¤å®šç­–ç•¥ï¼š
			// 1. æ£€æŸ¥æ˜¯å¦æ˜¯dial backoffï¼ˆé¢„æœŸçš„å¤±è´¥ï¼Œä¸åº”è¯¥è­¦å‘Šï¼‰
			// 2. æ£€æŸ¥æ˜¯å¦æ˜¯è·¨ç½‘æ®µç§ç½‘åœ°å€ï¼ˆä¸å¯è¾¾ï¼Œä¸åº”è¯¥è­¦å‘Šï¼‰
			// 3. åªæœ‰åœ¨mDNSæ¨¡å¼ä¸‹ä¸”æ˜¯åŒä¸€LANå†…çš„è¿æ¥å¤±è´¥æ‰è­¦å‘Š
			errMsg := err.Error()
			isDialBackoff := strings.Contains(errMsg, "dial backoff") || strings.Contains(errMsg, "backoff")
			
			// æ£€æŸ¥æ˜¯å¦æœ‰åŒç½‘æ®µçš„ç§ç½‘åœ°å€å¤±è´¥
			isLANMode := s.opts != nil && s.opts.EnableMDNS
			hasSameLANAddr := false
			if isLANMode && s.host != nil {
				// è·å–æœ¬æœºç§ç½‘IPæ®µ
				hostPrivateNets := make(map[string]bool)
				for _, a := range s.host.Addrs() {
					if ip, e := manet.ToIP(a); e == nil && ip != nil && ip.IsPrivate() {
						// æå–ç½‘æ®µï¼ˆå¦‚192.168.0.x -> 192.168.0ï¼‰
						ipStr := ip.String()
						if idx := strings.LastIndex(ipStr, "."); idx > 0 {
							hostPrivateNets[ipStr[:idx]] = true
						}
					}
				}
				// æ£€æŸ¥å¯¹æ–¹åœ°å€æ˜¯å¦åœ¨åŒä¸€ç½‘æ®µ
				for _, a := range info.Addrs {
					if ip, e := manet.ToIP(a); e == nil && ip != nil && ip.IsPrivate() {
						ipStr := ip.String()
						if idx := strings.LastIndex(ipStr, "."); idx > 0 {
							if hostPrivateNets[ipStr[:idx]] {
								hasSameLANAddr = true
								break
							}
						}
					}
				}
			}
			
			// åªåœ¨ä»¥ä¸‹æƒ…å†µè­¦å‘Šï¼šmDNSæ¨¡å¼ && åŒç½‘æ®µ && ébackoff
			if isLANMode && hasSameLANAddr && !isDialBackoff {
				s.logger.Warnf("p2p.discovery.dht_loop connect_failed id=%s addrs=%v error=%v", info.ID.String(), info.Addrs, err)
			} else {
				// å…¶ä»–æƒ…å†µé™çº§ä¸ºDebugï¼Œé¿å…åˆ·å±
				s.logger.Debugf("p2p.discovery.dht_loop connect_failed id=%s error=%v", info.ID.String(), err)
			}
		}
	}

	return validPeer
}
