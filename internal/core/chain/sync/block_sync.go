// block_sync.go - åŒºå—åŒæ­¥æ ¸å¿ƒé€»è¾‘
// è´Ÿè´£æ‰§è¡ŒKæ¡¶æ™ºèƒ½åŒæ­¥å’Œåˆ†é¡µè¡¥é½åŒæ­¥
package sync

import (
	"context"
	"encoding/hex"
	"encoding/json"
	"errors"
	"fmt"
	"runtime"
	"strconv"
	"strings"
	"time"

	peer "github.com/libp2p/go-libp2p/core/peer"
	"google.golang.org/protobuf/proto"

	"github.com/weisyn/v1/internal/config/node"
	core "github.com/weisyn/v1/pb/blockchain/block"
	"github.com/weisyn/v1/pb/network/protocol"
	"github.com/weisyn/v1/pkg/constants"
	"github.com/weisyn/v1/pkg/constants/protocols"
	"github.com/weisyn/v1/pkg/interfaces/block"
	"github.com/weisyn/v1/pkg/interfaces/config"
	"github.com/weisyn/v1/pkg/interfaces/infrastructure/log"
	"github.com/weisyn/v1/pkg/interfaces/infrastructure/storage"
	"github.com/weisyn/v1/pkg/interfaces/network"
	p2pi "github.com/weisyn/v1/pkg/interfaces/p2p"
	"github.com/weisyn/v1/pkg/interfaces/persistence"
	"github.com/weisyn/v1/pkg/types"
)

type helloV2Info struct {
	relationship         string
	remoteTipHeight      uint64
	commonAncestorHeight uint64
	commonAncestorHash   []byte
}

func parseHelloV2Reason(reason string) helloV2Info {
	info := helloV2Info{
		relationship:         "UNKNOWN",
		remoteTipHeight:      0,
		commonAncestorHeight: 0,
		commonAncestorHash:   nil,
	}
	// å½¢å¦‚ï¼šSYNCV2_HELLO:<REL> remote_tip=... local_tip=... ancestor=<h>:<hex>
	if !strings.HasPrefix(reason, "SYNCV2_HELLO:") {
		return info
	}
	rest := strings.TrimPrefix(reason, "SYNCV2_HELLO:")
	// rel åœ¨ç¬¬ä¸€ä¸ªç©ºæ ¼ä¹‹å‰
	if sp := strings.IndexByte(rest, ' '); sp > 0 {
		info.relationship = rest[:sp]
	} else if rest != "" {
		info.relationship = rest
	}

	// remote_tip
	if idx := strings.Index(reason, "remote_tip="); idx >= 0 {
		sub := reason[idx+len("remote_tip="):]
		end := strings.IndexByte(sub, ' ')
		if end > 0 {
			sub = sub[:end]
		}
		if v, err := strconv.ParseUint(sub, 10, 64); err == nil {
			info.remoteTipHeight = v
		}
	}

	// ancestor
	if idx := strings.Index(reason, "ancestor="); idx >= 0 {
		sub := reason[idx+len("ancestor="):]
		end := strings.IndexByte(sub, ' ')
		if end > 0 {
			sub = sub[:end]
		}
		parts := strings.SplitN(sub, ":", 2)
		if len(parts) >= 1 {
			if v, err := strconv.ParseUint(parts[0], 10, 64); err == nil {
				info.commonAncestorHeight = v
			}
		}
		if len(parts) == 2 && parts[1] != "" {
			if b, err := hex.DecodeString(parts[1]); err == nil && len(b) == 32 {
				info.commonAncestorHash = b
			}
		}
	}
	return info
}

func performSyncHelloV2(
	ctx context.Context,
	targetPeer peer.ID,
	localTipHeight uint64,
	localTipHash []byte,
	locatorBytes []byte,
	localChainInfo *types.ChainInfo,
	networkService network.Network,
	p2pService p2pi.Service,
	configProvider config.Provider,
	logger log.Logger,
) (*helloV2Info, error) {
	if logger != nil {
		logger.Debugf("ğŸ¤ å‘èŠ‚ç‚¹ %s å‘èµ· SyncHelloV2", targetPeer.String()[:8])
	}
	if len(localTipHash) != 32 {
		return nil, fmt.Errorf("local tip hash invalid (len=%d)", len(localTipHash))
	}
	// âœ… v2 ç¡¬é—¨æ§›ï¼šSyncHelloV2 å¿…é¡»æºå¸¦æœ¬åœ°é“¾èº«ä»½ï¼ˆç”¨äºå¯¹ç«¯æ ¡éªŒï¼‰ï¼Œä¸”å¿…é¡»èƒ½è¢«æœ¬åœ°è·å–/éªŒè¯
	localChainIdentity, err := GetLocalChainIdentity(ctx, configProvider, nil)
	if err != nil {
		return nil, fmt.Errorf("è·å–æœ¬åœ°é“¾èº«ä»½å¤±è´¥ï¼ˆSyncHelloV2 å¿…éœ€ï¼‰: %w", err)
	}
	if !localChainIdentity.IsValid() {
		return nil, fmt.Errorf("æœ¬åœ°é“¾èº«ä»½æ— æ•ˆï¼ˆSyncHelloV2 å¿…éœ€ï¼‰: %v", localChainIdentity)
	}

	maxResponseSize := uint32(MAX_RESPONSE_SIZE_LIMIT)
	if bc := configProvider.GetBlockchain(); bc != nil && bc.Sync.Advanced.MaxResponseSizeBytes > 0 {
		if bc.Sync.Advanced.MaxResponseSizeBytes < maxResponseSize {
			maxResponseSize = bc.Sync.Advanced.MaxResponseSizeBytes
		}
	}

	req := &protocol.KBucketSyncRequest{
		RequestId:       fmt.Sprintf("sync-hello-v2-%d", time.Now().UnixNano()),
		LocalHeight:     localTipHeight,
		RoutingKey:      localTipHash,
		MaxResponseSize: maxResponseSize,
		// v2: å¤ç”¨ requester_peer_id ä¼ è¾“ locatorï¼ˆäºŒè¿›åˆ¶ç¼–ç ï¼‰ï¼Œfrom peer å·²ç”± stream æä¾›
		RequesterPeerId: locatorBytes,
		TargetHeight:    nil,
	}
	req.ChainIdentity = node.ToProtoChainIdentity(localChainIdentity)

	reqBytes, err := proto.Marshal(req)
	if err != nil {
		return nil, fmt.Errorf("marshal hello v2 request failed: %w", err)
	}

	respBytes, err := networkService.Call(ctx, targetPeer, protocols.ProtocolSyncHelloV2, reqBytes, &types.TransportOptions{
		ConnectTimeout: 10 * time.Second,
		WriteTimeout:   10 * time.Second,
		ReadTimeout:    20 * time.Second,
		MaxRetries:     1,
		RetryDelay:     500 * time.Millisecond,
	})
	if err != nil {
		return nil, fmt.Errorf("hello v2 call failed: %w", err)
	}

	resp := &protocol.IntelligentPaginationResponse{}
	if err := proto.Unmarshal(respBytes, resp); err != nil {
		return nil, fmt.Errorf("unmarshal hello v2 response failed: %w", err)
	}
	if !resp.Success {
		msg := ""
		if resp.ErrorMessage != nil {
			msg = *resp.ErrorMessage
		}
		return nil, fmt.Errorf("hello v2 rejected: %s", msg)
	}

	// âœ… v2 ç¡¬é—¨æ§›ï¼šå“åº”å¿…é¡»å›ä¼  chain_identityï¼Œä¸”å¿…é¡»ä¸æœ¬åœ°ä¸€è‡´ï¼›å¦åˆ™è§†ä¸º"ä¸å…¼å®¹ peer"
	if resp.ChainIdentity == nil {
		MarkBadPeer(targetPeer)
		recordSyncFailure(targetPeer, "hello", FailureReasonChainIdentityMismatch, 
			"hello v2 missing chain_identity in response (incompatible peer)", logger)
		recordUpstreamFailure(targetPeer, logger)
		return nil, fmt.Errorf("hello v2 missing chain_identity in response (incompatible peer)")
	}
	remoteIdentity := node.FromProtoChainIdentity(resp.ChainIdentity)
	if !remoteIdentity.IsValid() || !localChainIdentity.IsSameChain(remoteIdentity) {
		if logger != nil {
			logger.Warnf("policy.reject_sync_peer: SyncHelloV2 å“åº”é“¾èº«ä»½ä¸åŒ¹é…, peer=%s remote=%v local=%v",
				targetPeer.String()[:8], remoteIdentity, localChainIdentity)
		}
		MarkBadPeer(targetPeer)
		recordSyncFailure(targetPeer, "hello", FailureReasonChainIdentityMismatch,
			fmt.Sprintf("hello v2 incompatible peer: remote=%v local=%v", remoteIdentity, localChainIdentity), logger)
		recordUpstreamFailure(targetPeer, logger)
		return nil, fmt.Errorf("hello v2 incompatible peer: remote=%v local=%v", remoteIdentity, localChainIdentity)
	}

	// âœ… ç³»ç»Ÿè·¯å¾„ç¼“å­˜ï¼šå°†å¯¹ç«¯ chain identity è®°å…¥ peerstoreï¼Œä¾› Kæ¡¶ç­‰æœ¬åœ°å¿«è·¯å¾„å¤ç”¨ï¼ˆé¿å…ä¾èµ– UserAgentï¼‰
	cachePeerChainIdentity(p2pService, targetPeer, remoteIdentity)

	// hello æˆåŠŸï¼šåˆ·æ–°ä¸Šæ¸¸è®°å¿†å¹¶æ¸…é›¶å¤±è´¥è®¡æ•°ï¼ˆç”¨äºæŠ—æŠ–åŠ¨/å¿«é€Ÿåˆ‡æ¢ï¼‰
	recordUpstreamSuccess(targetPeer)

	info := parseHelloV2Reason(resp.PaginationReason)
	if info.remoteTipHeight == 0 {
		info.remoteTipHeight = resp.NextHeight
	}
	// ç»™è°ƒç”¨æ–¹ç”¨æŒ‡é’ˆ
	return &info, nil
}

// cachePeerChainIdentity caches a peer's ChainIdentity into the local peerstore.
//
// çº¦æŸï¼š
// - ä»…å†™æœ¬åœ° peerstoreï¼ˆä¸è§¦å‘ç½‘ç»œ I/Oï¼Œä¸ DialPeerï¼‰ï¼›
// - å¤±è´¥æ—¶é™é»˜ï¼ˆä¸å½±å“åŒæ­¥ä¸»æµç¨‹ï¼‰ã€‚
func cachePeerChainIdentity(p2pService p2pi.Service, pid peer.ID, identity types.ChainIdentity) {
	if p2pService == nil {
		return
	}
	h := p2pService.Host()
	if h == nil {
		return
	}
	if !identity.IsValid() {
		return
	}
	b, err := json.Marshal(identity)
	if err != nil {
		return
	}
	_ = h.Peerstore().Put(pid, constants.PeerstoreKeyChainIdentity, string(b))
}

// å†…å­˜ä¼˜åŒ–ç›¸å…³å¸¸é‡
const (
	MAX_BLOCK_BATCH_SIZE    = 20                     // å‡å°æ‰¹æ¬¡å¤§å°ï¼Œé¿å…å†…å­˜å‹åŠ›
	BATCH_PROCESS_DELAY     = 200 * time.Millisecond // å¢åŠ æ‰¹æ¬¡é—´å»¶è¿Ÿï¼Œè®©GCæœ‰æ—¶é—´å·¥ä½œ
	MEMORY_GC_THRESHOLD     = 200 * 1024 * 1024      // é™ä½å†…å­˜GCé˜ˆå€¼ï¼Œ200MB
	MEMORY_CHECK_INTERVAL   = 10                     // æ›´é¢‘ç¹çš„å†…å­˜æ£€æŸ¥ï¼Œæ¯10ä¸ªåŒºå—
	MAX_RESPONSE_SIZE_LIMIT = 2 * 1024 * 1024        // é™åˆ¶å•æ¬¡å“åº”å¤§å°ï¼Œ2MB
	FORCE_GC_INTERVAL       = 100                    // æ¯100ä¸ªåŒºå—å¼ºåˆ¶GCä¸€æ¬¡
)

// EmptyBatchError è¡¨ç¤ºç©ºæ‰¹æ¬¡çš„ç‰¹æ®Šé”™è¯¯ï¼ŒåŒ…å«è·³è·ƒä¿¡æ¯
type EmptyBatchError struct {
	StartHeight uint64
	EndHeight   uint64
	NextHeight  uint64
	Reason      string
}

func (e *EmptyBatchError) Error() string {
	return fmt.Sprintf("ç©ºæ‰¹æ¬¡è·³è·ƒ: [%d, %d] -> %d (%s)",
		e.StartHeight, e.EndHeight, e.NextHeight, e.Reason)
}

// ============================================================================
//                           Kæ¡¶æ™ºèƒ½åŒæ­¥å®ç°
// ============================================================================

// performKBucketSmartSync æ‰§è¡ŒKæ¡¶æ™ºèƒ½åŒæ­¥ï¼ˆè·å–åˆå§‹åŒºå—æ‰¹æ¬¡ï¼‰
//
// ğŸ¯ **æ™ºèƒ½åŒæ­¥ç­–ç•¥**ï¼š
// 1. å‘é€Kæ¡¶åŒæ­¥è¯·æ±‚åˆ°æœ€ä¼˜èŠ‚ç‚¹
// 2. æ¥æ”¶åˆå§‹åŒºå—æ‰¹æ¬¡æ•°æ®
// 3. éªŒè¯å“åº”çš„æœ‰æ•ˆæ€§å’Œå®Œæ•´æ€§
//
// ğŸ“ **æ³¨æ„**ï¼šæ­¤å‡½æ•°ä¸å†è¿”å›"ç½‘ç»œé«˜åº¦"ï¼Œå› ä¸ºçœŸå®çš„ç½‘ç»œé«˜åº¦åº”è¯¥é€šè¿‡
// ä¸“é—¨çš„é«˜åº¦æŸ¥è¯¢è·å¾—ï¼Œè€Œéä»åŒæ­¥å“åº”çš„NextHeightæ¨ç®—ã€‚
func performKBucketSmartSync(
	ctx context.Context,
	targetPeer peer.ID,
	localHeight uint64,
	localChainInfo *types.ChainInfo,
	networkService network.Network,
	p2pService p2pi.Service,
	configProvider config.Provider,
	logger log.Logger,
) (initialBlocks []*core.Block, err error) {
	if logger != nil {
		logger.Debugf("ğŸ“¡ å‘èŠ‚ç‚¹ %s å‘èµ·Kæ¡¶æ™ºèƒ½åŒæ­¥", targetPeer.String()[:8])
	}

	// è·å–æœ¬åœ°èŠ‚ç‚¹ID
	localNodeID := p2pService.Host().ID()

	// è·å–åŒæ­¥é…ç½®
	blockchainConfig := configProvider.GetBlockchain()
	var maxResponseSize uint32 = MAX_RESPONSE_SIZE_LIMIT // ä½¿ç”¨ä¼˜åŒ–çš„å“åº”å¤§å°é™åˆ¶
	if blockchainConfig != nil && blockchainConfig.Sync.Advanced.MaxResponseSizeBytes > 0 {
		// ç¡®ä¿ä¸è¶…è¿‡æˆ‘ä»¬çš„å†…å­˜ä¼˜åŒ–é™åˆ¶
		if blockchainConfig.Sync.Advanced.MaxResponseSizeBytes < maxResponseSize {
			maxResponseSize = blockchainConfig.Sync.Advanced.MaxResponseSizeBytes
		}
	}

	// è·å–æœ¬åœ°é“¾èº«ä»½
	localChainIdentity, err := GetLocalChainIdentity(ctx, configProvider, nil)
	if err != nil {
		if logger != nil {
			logger.Warnf("è·å–æœ¬åœ°é“¾èº«ä»½å¤±è´¥ï¼Œè·³è¿‡é“¾èº«ä»½éªŒè¯: %v", err)
		}
		// å¦‚æœæ— æ³•è·å–é“¾èº«ä»½ï¼Œä»ç„¶ç»§ç»­åŒæ­¥ï¼ˆå‘åå…¼å®¹ï¼‰
		localChainIdentity = types.ChainIdentity{}
	}

	// æ„é€ Kæ¡¶åŒæ­¥è¯·æ±‚
	request := &protocol.KBucketSyncRequest{
		RequestId:       fmt.Sprintf("kbucket-sync-%d", time.Now().UnixNano()),
		LocalHeight:     localHeight,
		RoutingKey:      localChainInfo.BestBlockHash,
		MaxResponseSize: maxResponseSize,              // ä»é…ç½®è·å–
		RequesterPeerId: []byte(localNodeID.String()), // ä½¿ç”¨hostæ¥å£è·å–çœŸå®èŠ‚ç‚¹ID
		TargetHeight:    nil,                          // åŒæ­¥åˆ°æœ€æ–°é«˜åº¦
	}

	// å¡«å……é“¾èº«ä»½ï¼ˆå¦‚æœå¯ç”¨ï¼‰
	if localChainIdentity.IsValid() {
		request.ChainIdentity = node.ToProtoChainIdentity(localChainIdentity)
	}

	// åºåˆ—åŒ–è¯·æ±‚
	requestData, err := proto.Marshal(request)
	if err != nil {
		return nil, fmt.Errorf("åºåˆ—åŒ–kæ¡¶åŒæ­¥è¯·æ±‚å¤±è´¥: %w", err)
	}

	// é…ç½®ä¼ è¾“é€‰é¡¹ï¼ˆä»é…ç½®è·å–è¶…æ—¶å‚æ•°ï¼‰
	var connectTimeout = 15 * time.Second
	var writeTimeout = 10 * time.Second
	var readTimeout = 30 * time.Second
	var maxRetries = 2
	var retryDelay = 2 * time.Second

	if blockchainConfig != nil {
		if blockchainConfig.Sync.Advanced.ConnectTimeout > 0 {
			connectTimeout = blockchainConfig.Sync.Advanced.ConnectTimeout
		}
		if blockchainConfig.Sync.Advanced.WriteTimeout > 0 {
			writeTimeout = blockchainConfig.Sync.Advanced.WriteTimeout
		}
		if blockchainConfig.Sync.Advanced.ReadTimeout > 0 {
			readTimeout = blockchainConfig.Sync.Advanced.ReadTimeout
		}
		if blockchainConfig.Sync.Advanced.MaxRetryAttempts > 0 {
			maxRetries = blockchainConfig.Sync.Advanced.MaxRetryAttempts
		}
		if blockchainConfig.Sync.Advanced.RetryDelay > 0 {
			retryDelay = blockchainConfig.Sync.Advanced.RetryDelay
		}
	}

	transportOpts := &types.TransportOptions{
		ConnectTimeout: connectTimeout,
		WriteTimeout:   writeTimeout,
		ReadTimeout:    readTimeout,
		MaxRetries:     maxRetries,
		RetryDelay:     retryDelay,
		BackoffFactor:  2.0,
	}

	// å‘é€Kæ¡¶æ™ºèƒ½åŒæ­¥è¯·æ±‚
	responseData, err := networkService.Call(ctx, targetPeer, protocols.ProtocolKBucketSync, requestData, transportOpts)
	if err != nil {
		recordUpstreamFailure(targetPeer, logger)
		return nil, fmt.Errorf("kæ¡¶æ™ºèƒ½åŒæ­¥è°ƒç”¨å¤±è´¥: %w", err)
	}

	// è§£æå“åº”
	var response protocol.IntelligentPaginationResponse
	if err := proto.Unmarshal(responseData, &response); err != nil {
		return nil, fmt.Errorf("è§£ækæ¡¶åŒæ­¥å“åº”å¤±è´¥: %w", err)
	}

	// éªŒè¯å“åº”
	if !response.Success {
		errorMsg := "æœªçŸ¥é”™è¯¯"
		if response.ErrorMessage != nil {
			errorMsg = *response.ErrorMessage
		}
		recordUpstreamFailure(targetPeer, logger)
		return nil, fmt.Errorf("kæ¡¶åŒæ­¥è¯·æ±‚å¤±è´¥: %s", errorMsg)
	}

	if response.RequestId != request.RequestId {
		return nil, fmt.Errorf("å“åº”RequestIDä¸åŒ¹é…: æœŸæœ›=%s, å®é™…=%s",
			request.RequestId, response.RequestId)
	}

	// æ ¡éªŒå“åº”çš„é“¾èº«ä»½ï¼ˆå¦‚æœå“åº”ä¸­åŒ…å«ï¼‰
	if response.ChainIdentity != nil {
		remoteIdentity := node.FromProtoChainIdentity(response.ChainIdentity)
		if !localChainIdentity.IsSameChain(remoteIdentity) {
			if logger != nil {
				logger.Warnf("policy.reject_sync_peer: å“åº”é“¾èº«ä»½ä¸åŒ¹é…, peer=%s remote=%v local=%v", targetPeer.String()[:8], remoteIdentity, localChainIdentity)
			}
			// æ ‡è®°è¯¥ peer ä¸º bad-peerï¼ˆåç»­ä¸å†å‘å…¶å‘èµ· syncï¼‰
			MarkBadPeer(targetPeer)
			recordUpstreamFailure(targetPeer, logger)
			return nil, fmt.Errorf("å“åº”é“¾èº«ä»½ä¸åŒ¹é…: remote=%v local=%v", remoteIdentity, localChainIdentity)
		}
		if logger != nil {
			logger.Debugf("âœ… å“åº”é“¾èº«ä»½éªŒè¯é€šè¿‡: peer=%s identity=%v", targetPeer.String()[:8], remoteIdentity)
		}
	}

	// ä½¿ç”¨protobufç»Ÿä¸€çš„åŒºå—æ ¼å¼
	blocks := response.Blocks

	if logger != nil {
		logger.Infof("âœ… Kæ¡¶æ™ºèƒ½åŒæ­¥æˆåŠŸ: æ¥æ”¶åŒºå—=%d, æ•°æ®å¤§å°=%d, NextHeight=%d, HasMore=%t",
			len(blocks), response.ActualSize, response.NextHeight, response.HasMore)
	}

	// åŒæ­¥æˆåŠŸï¼šåˆ·æ–°ä¸Šæ¸¸è®°å¿†å¹¶æ¸…é›¶å¤±è´¥è®¡æ•°
	recordUpstreamSuccess(targetPeer)

	// ğŸš¨ **å†…å­˜ä¼˜åŒ–å…³é”®**ï¼šå¦‚æœå“åº”è¿‡å¤§ï¼Œè®°å½•è­¦å‘Šå¹¶å»ºè®®åˆ†é¡µå¤„ç†
	if response.ActualSize > maxResponseSize/2 {
		if logger != nil {
			logger.Warnf("âš ï¸ Kæ¡¶åŒæ­¥å“åº”è¾ƒå¤§ (%då­—èŠ‚)ï¼Œå»ºè®®åç»­ä½¿ç”¨åˆ†é¡µåŒæ­¥", response.ActualSize)
		}
	}

	return blocks, nil
}

// ============================================================================
//                           åˆ†é¡µè¡¥é½åŒæ­¥å®ç°
// ============================================================================

// performRangePaginatedSync æ‰§è¡Œåˆ†é¡µè¡¥é½åŒæ­¥
//
// ğŸ¯ **åˆ†é¡µåŒæ­¥ç­–ç•¥**ï¼š
// 1. æ ¹æ®å‰©ä½™é«˜åº¦èŒƒå›´è®¡ç®—éœ€è¦åŒæ­¥çš„åŒºå—
// 2. ä½¿ç”¨åˆ†é¡µæ–¹å¼è·å–åŒºå—æ•°æ®ï¼Œæ”¯æŒèŠ‚ç‚¹æ•…éšœè½¬ç§»
// 3. âœ… P1ä¿®å¤ï¼šæ”¯æŒä¸´æ—¶å­˜å‚¨ä¹±åºåŒºå—ï¼Œæ£€æµ‹è¿ç»­æ€§åæ‰¹é‡å¤„ç†
// 4. é€æ‰¹æ¬¡å¤„ç†å’ŒéªŒè¯åŒºå—
func performRangePaginatedSync(
	ctx context.Context,
	sourcePeers []peer.ID, // æ”¯æŒå¤šä¸ªå¤‡ç”¨èŠ‚ç‚¹çš„æ•…éšœè½¬ç§»
	currentHeight, targetHeight uint64,
	networkService network.Network,
	p2pService p2pi.Service,
	blockValidator block.BlockValidator,
	blockProcessor block.BlockProcessor,
	tempStore storage.TempStore, // âœ… P1ä¿®å¤ï¼šä¸´æ—¶å­˜å‚¨æœåŠ¡ï¼ˆå¯é€‰ï¼‰
	configProvider config.Provider,
	logger log.Logger,
) error {
	if len(sourcePeers) == 0 {
		return fmt.Errorf("æ²¡æœ‰å¯ç”¨çš„æºèŠ‚ç‚¹è¿›è¡Œåˆ†é¡µåŒæ­¥")
	}

	remainingHeight := currentHeight

	// ä»é…ç½®è·å–æ‰¹æ¬¡å¤§å°å’Œæ•…éšœè½¬ç§»å‚æ•°
	batchSize := uint64(MAX_BLOCK_BATCH_SIZE) // ä½¿ç”¨ä¼˜åŒ–çš„æ‰¹æ¬¡å¤§å°
	maxFailuresPerPeer := 3                   // é»˜è®¤æ¯ä¸ªèŠ‚ç‚¹æœ€å¤šå¤±è´¥3æ¬¡

	blockchainConfig := configProvider.GetBlockchain()
	if blockchainConfig != nil {
		// è·å–æ‰¹æ¬¡å¤§å°é…ç½®
		if blockchainConfig.Sync.BatchSize > 0 {
			batchSize = uint64(blockchainConfig.Sync.BatchSize)
		} else if blockchainConfig.Sync.Advanced.MaxBatchSize > 0 {
			batchSize = uint64(blockchainConfig.Sync.Advanced.MaxBatchSize)
		}

		// è·å–æ•…éšœè½¬ç§»ç­–ç•¥å‚æ•°
		if blockchainConfig.Sync.Advanced.MaxRetryAttempts > 0 {
			maxFailuresPerPeer = blockchainConfig.Sync.Advanced.MaxRetryAttempts
		}

		// æ ¹æ®FailoverNodeCounté™åˆ¶å¯ç”¨èŠ‚ç‚¹æ•°é‡
		if blockchainConfig.Sync.Advanced.FailoverNodeCount > 0 &&
			blockchainConfig.Sync.Advanced.FailoverNodeCount < len(sourcePeers) {
			maxNodes := blockchainConfig.Sync.Advanced.FailoverNodeCount
			if maxNodes < 1 {
				maxNodes = 1
			}
			sourcePeers = sourcePeers[:maxNodes]
			if logger != nil {
				logger.Debugf("ğŸ“Š åŸºäºFailoverNodeCounté…ç½®é™åˆ¶èŠ‚ç‚¹æ•°é‡: %d", maxNodes)
			}
		}
	}

	if logger != nil {
		logger.Infof("ğŸ”„ å¼€å§‹åˆ†é¡µè¡¥é½åŒæ­¥: ä»é«˜åº¦ %d åˆ° %d (å…±%dä¸ªåŒºå—), å¯ç”¨èŠ‚ç‚¹=%d",
			currentHeight+1, targetHeight, targetHeight-currentHeight, len(sourcePeers))
		logger.Debugf("ğŸ“Š æ•…éšœè½¬ç§»é…ç½®: æ¯èŠ‚ç‚¹æœ€å¤§å¤±è´¥æ¬¡æ•°=%d, æ‰¹æ¬¡å¤§å°=%d",
			maxFailuresPerPeer, batchSize)
	}

	// æ•…éšœè½¬ç§»çŠ¶æ€ç®¡ç†
	currentPeerIndex := 0
	failedAttempts := 0

	for remainingHeight < targetHeight {
		// è®¡ç®—å½“å‰æ‰¹æ¬¡çš„ç»“æŸé«˜åº¦
		batchEndHeight := remainingHeight + batchSize
		if batchEndHeight > targetHeight {
			batchEndHeight = targetHeight
		}

		// è·å–å½“å‰æ‰¹æ¬¡çš„åŒºå—ï¼ˆæ”¯æŒæ•…éšœè½¬ç§»ï¼‰
		if currentPeerIndex >= len(sourcePeers) {
			return fmt.Errorf("æ‰€æœ‰å¤‡ç”¨èŠ‚ç‚¹éƒ½å·²å°è¯•å¤±è´¥")
		}

		currentPeer := sourcePeers[currentPeerIndex]
		blocks, err := fetchBlockRange(ctx, currentPeer, remainingHeight+1, batchEndHeight, networkService, p2pService, configProvider, logger)
		if err != nil {
			failedAttempts++
			// âœ… SYNC-103ä¿®å¤ï¼šè®°å½•åˆ†é¡µåŒæ­¥å¤±è´¥åŸå› ï¼ˆç»†åŒ–åˆ†ç±»ï¼‰
			recordSyncFailure(currentPeer, "paginated", ClassifyError(err), err.Error(), logger)
			// è®°å½•å¤±è´¥ï¼šè‹¥ currentPeer æ°å¥½æ˜¯ lastGoodUpstreamï¼Œå°†è§¦å‘"åä¸Šæ¸¸å¿«é€Ÿåˆ‡æ¢"
			recordUpstreamFailure(currentPeer, logger)
			if logger != nil {
				logger.Warnf("ğŸ’¥ èŠ‚ç‚¹ %s è·å–åŒºå—å¤±è´¥ (å°è¯• %d/%d): %v",
					currentPeer.String()[:8], failedAttempts, maxFailuresPerPeer, err)
			}

			// æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ªèŠ‚ç‚¹
			if failedAttempts >= maxFailuresPerPeer {
				currentPeerIndex++
				failedAttempts = 0
				if logger != nil {
					logger.Warnf("ğŸ”„ èŠ‚ç‚¹ %s å¤±è´¥æ¬¡æ•°è¿‡å¤šï¼Œåˆ‡æ¢åˆ°ä¸‹ä¸ªèŠ‚ç‚¹ (ç´¢å¼•: %d)",
						currentPeer.String()[:8], currentPeerIndex)
				}
				if currentPeerIndex >= len(sourcePeers) {
					return fmt.Errorf("æ‰€æœ‰å¤‡ç”¨èŠ‚ç‚¹éƒ½å·²å°è¯•å¤±è´¥ï¼Œæœ€åé”™è¯¯: %w", err)
				}
			}
			continue // é‡è¯•å½“å‰æ‰¹æ¬¡
		}

		// æˆåŠŸè·å–åŒºå—ï¼Œé‡ç½®å¤±è´¥è®¡æ•°
		failedAttempts = 0
		recordUpstreamSuccess(currentPeer)
		
		// âœ… æ›´æ–°è¯Šæ–­ä¿¡æ¯ï¼šè®°å½•æ‹‰å–çš„åŒºå—æ•°å’Œæ•°æ®æºèŠ‚ç‚¹
		UpdateSyncDiagnostics(func(d *SyncDiagnostics) {
			d.BlocksFetched += uint64(len(blocks))
			d.CurrentDataSourcePeer = currentPeer.String()
		})

		// âœ… P1ä¿®å¤ï¼šå¦‚æœåŒºå—é«˜åº¦ä¸è¿ç»­ï¼Œå­˜å‚¨åˆ°ä¸´æ—¶å­˜å‚¨
		expectedHeight := remainingHeight + 1
		needTempStore := false
		if len(blocks) > 0 && blocks[0] != nil && blocks[0].Header != nil && blocks[0].Header.Height > expectedHeight {
			needTempStore = true
			if logger != nil {
				logger.Debugf("ğŸ“¦ æ£€æµ‹åˆ°åŒºå—é«˜åº¦è·³è·ƒ: æœŸæœ›=%d, å®é™…=%dï¼Œå­˜å‚¨åˆ°ä¸´æ—¶å­˜å‚¨",
					expectedHeight, blocks[0].Header.Height)
			}
		}

		if needTempStore && tempStore != nil {
			// å­˜å‚¨åˆ°ä¸´æ—¶å­˜å‚¨
			tempFileIDs, err := storeBlocksInTempStore(ctx, tempStore, blocks, logger)
			if err != nil {
				if logger != nil {
					logger.Warnf("å­˜å‚¨åŒºå—åˆ°ä¸´æ—¶å­˜å‚¨å¤±è´¥: %vï¼Œç»§ç»­å¤„ç†", err)
				}
				// ç»§ç»­å¤„ç†ï¼Œä¸é˜»æ–­åŒæ­¥æµç¨‹
			} else {
				if logger != nil {
					logger.Debugf("âœ… å·²å°† %d ä¸ªåŒºå—å­˜å‚¨åˆ°ä¸´æ—¶å­˜å‚¨", len(tempFileIDs))
				}
				// æŸ¥æ‰¾è¿ç»­åŒºå—å¹¶å¤„ç†
				continuousBlocks, nextMissingHeight, err := findContinuousBlocks(
					ctx, tempStore, expectedHeight, MAX_BLOCK_BATCH_SIZE, logger)
				if err == nil && len(continuousBlocks) > 0 {
					// å¤„ç†è¿ç»­åŒºå—
					if err := processBlockBatch(ctx, continuousBlocks, blockValidator, blockProcessor, logger); err != nil {
						if logger != nil {
							logger.Warnf("å¤„ç†è¿ç»­åŒºå—å¤±è´¥: %v", err)
						}
					} else {
						// åˆ é™¤å·²å¤„ç†çš„ä¸´æ—¶åŒºå—
						var processedTempIDs []string
						for _, block := range continuousBlocks {
							// ç”Ÿæˆä¸´æ—¶æ–‡ä»¶IDï¼ˆç®€åŒ–å®ç°ï¼‰
							height := block.Header.Height
							hashPrefix := ""
							if len(block.Header.PreviousHash) >= 8 {
								hashPrefix = hex.EncodeToString(block.Header.PreviousHash[:8])
							} else {
								hashPrefix = fmt.Sprintf("%010d", height)
							}
							tempID := fmt.Sprintf("sync_pending_%010d_%s", height, hashPrefix)
							processedTempIDs = append(processedTempIDs, tempID)
						}
						removeBlocksFromTempStore(ctx, tempStore, processedTempIDs, logger)

						// æ›´æ–°è¿›åº¦
						processedInBatch := uint64(len(continuousBlocks))
						updateSyncProgress(processedInBatch)
						remainingHeight += processedInBatch
						
						// âœ… æ›´æ–°è¯Šæ–­ä¿¡æ¯ï¼šè®°å½•å¤„ç†çš„åŒºå—æ•°
						UpdateSyncDiagnostics(func(d *SyncDiagnostics) {
							d.BlocksProcessed += processedInBatch
						})

						if logger != nil {
							logger.Debugf("âœ… å¤„ç†äº† %d ä¸ªè¿ç»­åŒºå—ï¼Œå½“å‰é«˜åº¦: %d", processedInBatch, remainingHeight)
						}

						// å¦‚æœè¿˜æœ‰ç¼ºå¤±çš„é«˜åº¦ï¼Œç»§ç»­åŒæ­¥
						if nextMissingHeight > 0 {
							remainingHeight = nextMissingHeight - 1
							if logger != nil {
								logger.Debugf("ğŸ“Š ç»§ç»­åŒæ­¥ç¼ºå¤±åŒºå—ï¼Œä»é«˜åº¦ %d å¼€å§‹", nextMissingHeight)
							}
						}

						// è·³è¿‡å½“å‰æ‰¹æ¬¡å¤„ç†ï¼Œå› ä¸ºå·²ç»å¤„ç†äº†è¿ç»­åŒºå—
						continue
					}
				}
			}
		}

		// å¤„ç†å½“å‰æ‰¹æ¬¡çš„åŒºå—ï¼ˆå¦‚æœæ²¡æœ‰ä½¿ç”¨ä¸´æ—¶å­˜å‚¨ï¼Œæˆ–ä¸´æ—¶å­˜å‚¨å¤±è´¥ï¼‰
		err = processBlockBatch(ctx, blocks, blockValidator, blockProcessor, logger)
		if err != nil {
			return fmt.Errorf("å¤„ç†åŒºå—æ‰¹æ¬¡å¤±è´¥: %w", err)
		}

		// æ›´æ–°è¿›åº¦
		processedInBatch := uint64(len(blocks))
		updateSyncProgress(processedInBatch)
		remainingHeight += processedInBatch
		
		// âœ… æ›´æ–°è¯Šæ–­ä¿¡æ¯ï¼šè®°å½•å¤„ç†çš„åŒºå—æ•°
		UpdateSyncDiagnostics(func(d *SyncDiagnostics) {
			d.BlocksProcessed += processedInBatch
		})

		if logger != nil {
			logger.Infof("ğŸ“Š åˆ†é¡µåŒæ­¥è¿›åº¦: %d/%d (%.1f%%)",
				remainingHeight, targetHeight,
				float64(remainingHeight)/float64(targetHeight)*100.0)
		}

		// æ£€æŸ¥æ˜¯å¦è¢«å–æ¶ˆ
		select {
		case <-ctx.Done():
			return fmt.Errorf("åˆ†é¡µåŒæ­¥è¢«å–æ¶ˆ: %w", ctx.Err())
		default:
			// ç»§ç»­
		}
	}

	if logger != nil {
		logger.Info("âœ… range_paginated åè®®è°ƒç”¨å®Œæˆ")
		logger.Info("ğŸ‰ åˆ†é¡µè¡¥é½åŒæ­¥åè®®æ‰§è¡ŒæˆåŠŸ")
	}

	return nil
}

// fetchBlockRange è·å–æŒ‡å®šé«˜åº¦èŒƒå›´çš„åŒºå—
//
// ğŸ¯ **æ™ºèƒ½åˆ†é¡µåŒºå—èŒƒå›´åŒæ­¥**ï¼š
// 1. æ„é€ KBucketSyncRequestï¼ˆå¤ç”¨ä½œä¸ºRangeRequestï¼‰
// 2. ä½¿ç”¨ProtocolRangePaginatedåè®®å‘é€è¯·æ±‚
// 3. è§£æIntelligentPaginationResponseå“åº”
// 4. è¿”å›åŒºå—åˆ—è¡¨ç»™è°ƒç”¨æ–¹å¤„ç†
//
// å‚æ•°ï¼š
//   - ctx: ä¸Šä¸‹æ–‡å¯¹è±¡ï¼ˆè¶…æ—¶æ§åˆ¶ï¼‰
//   - sourcePeer: æºèŠ‚ç‚¹ID
//   - startHeight, endHeight: æœŸæœ›çš„åŒºå—é«˜åº¦èŒƒå›´
//   - networkService: ç½‘ç»œæœåŠ¡æ¥å£
//   - logger: æ—¥å¿—è®°å½•å™¨
//
// è¿”å›ï¼š
//   - []*core.Block: è·å–åˆ°çš„åŒºå—åˆ—è¡¨
//   - error: è·å–å¤±è´¥æ—¶çš„é”™è¯¯ä¿¡æ¯
func fetchBlockRange(
	ctx context.Context,
	sourcePeer peer.ID,
	startHeight, endHeight uint64,
	networkService network.Network,
	p2pService p2pi.Service,
	configProvider config.Provider,
	logger log.Logger,
) ([]*core.Block, error) {
	if logger != nil {
		logger.Infof("ğŸ“¥ å¼€å§‹ä»èŠ‚ç‚¹ %s è·å–åŒºå—èŒƒå›´ [%d, %d] (å…±%dä¸ªåŒºå—)",
			sourcePeer.String()[:8], startHeight, endHeight, endHeight-startHeight+1)
	}

	// è·å–åŒæ­¥é…ç½®
	blockchainConfig := configProvider.GetBlockchain()
	var maxResponseSize uint32 = MAX_RESPONSE_SIZE_LIMIT // ä½¿ç”¨ä¼˜åŒ–çš„å“åº”å¤§å°é™åˆ¶
	if blockchainConfig != nil && blockchainConfig.Sync.Advanced.MaxResponseSizeBytes > 0 {
		// ç¡®ä¿ä¸è¶…è¿‡æˆ‘ä»¬çš„å†…å­˜ä¼˜åŒ–é™åˆ¶
		if blockchainConfig.Sync.Advanced.MaxResponseSizeBytes < maxResponseSize {
			maxResponseSize = blockchainConfig.Sync.Advanced.MaxResponseSizeBytes
		}
	}

	// 1. æ„é€ KBucketSyncRequestï¼ˆå¤ç”¨ä¸º SyncBlocksV2 èŒƒå›´è¯·æ±‚ï¼‰
	localChainIdentity, err := GetLocalChainIdentity(ctx, configProvider, nil)
	if err != nil {
		return nil, fmt.Errorf("è·å–æœ¬åœ°é“¾èº«ä»½å¤±è´¥ï¼ˆSyncBlocksV2 å¿…éœ€ï¼‰: %w", err)
	}
	if !localChainIdentity.IsValid() {
		return nil, fmt.Errorf("æœ¬åœ°é“¾èº«ä»½æ— æ•ˆï¼ˆSyncBlocksV2 å¿…éœ€ï¼‰: %v", localChainIdentity)
	}
	request := &protocol.KBucketSyncRequest{
		RequestId:       fmt.Sprintf("range-sync-%d-%d", startHeight, time.Now().UnixNano()),
		LocalHeight:     startHeight - 1, // æœ¬åœ°é«˜åº¦ä¸ºèµ·å§‹é«˜åº¦å‰ä¸€ä¸ª
		RoutingKey:      nil,
		MaxResponseSize: maxResponseSize,                         // ä»é…ç½®è·å–
		RequesterPeerId: []byte(p2pService.Host().ID().String()), // æœ¬åœ°èŠ‚ç‚¹IDï¼ˆè¯·æ±‚è€…ï¼‰
		TargetHeight:    &endHeight,                              // ç›®æ ‡é«˜åº¦
	}
	request.ChainIdentity = node.ToProtoChainIdentity(localChainIdentity)

	// 2. åºåˆ—åŒ–è¯·æ±‚
	reqBytes, err := proto.Marshal(request)
	if err != nil {
		return nil, fmt.Errorf("åºåˆ—åŒ–èŒƒå›´åŒæ­¥è¯·æ±‚å¤±è´¥: %w", err)
	}

	if logger != nil {
		logger.Debugf("ğŸ“¤ å‘é€èŒƒå›´åŒæ­¥è¯·æ±‚: ID=%s, å¤§å°=%då­—èŠ‚", request.RequestId, len(reqBytes))
	}

	// 3. é…ç½®ä¼ è¾“é€‰é¡¹ï¼ˆä»é…ç½®è·å–ï¼‰
	var connectTimeout = 10 * time.Second
	var writeTimeout = 15 * time.Second
	var readTimeout = 30 * time.Second
	var maxRetries = 2
	var retryDelay = 1 * time.Second

	if blockchainConfig != nil {
		if blockchainConfig.Sync.Advanced.ConnectTimeout > 0 {
			connectTimeout = blockchainConfig.Sync.Advanced.ConnectTimeout
		}
		if blockchainConfig.Sync.Advanced.WriteTimeout > 0 {
			writeTimeout = blockchainConfig.Sync.Advanced.WriteTimeout
		}
		if blockchainConfig.Sync.Advanced.ReadTimeout > 0 {
			readTimeout = blockchainConfig.Sync.Advanced.ReadTimeout
		}
		if blockchainConfig.Sync.Advanced.MaxRetryAttempts > 0 {
			maxRetries = blockchainConfig.Sync.Advanced.MaxRetryAttempts
		}
		if blockchainConfig.Sync.Advanced.RetryDelay > 0 {
			retryDelay = blockchainConfig.Sync.Advanced.RetryDelay
		}
	}

	// 4. å‘é€åè®®è¯·æ±‚ï¼ˆSyncBlocksV2ï¼‰
	responseBytes, err := networkService.Call(
		ctx,
		sourcePeer,
		protocols.ProtocolSyncBlocksV2,
		reqBytes,
		&types.TransportOptions{
			ConnectTimeout: connectTimeout,
			WriteTimeout:   writeTimeout,
			ReadTimeout:    readTimeout,
			MaxRetries:     maxRetries,
			RetryDelay:     retryDelay,
		},
	)
	if err != nil {
		return nil, fmt.Errorf("å‘é€èŒƒå›´åŒæ­¥è¯·æ±‚å¤±è´¥: %w", err)
	}

	if logger != nil {
		logger.Debugf("ğŸ“¦ æ”¶åˆ°èŒƒå›´åŒæ­¥å“åº”: å¤§å°=%då­—èŠ‚", len(responseBytes))
	}

	// 4. è§£æIntelligentPaginationResponse
	response := &protocol.IntelligentPaginationResponse{}
	if err := proto.Unmarshal(responseBytes, response); err != nil {
		return nil, fmt.Errorf("è§£æèŒƒå›´åŒæ­¥å“åº”å¤±è´¥: %w", err)
	}

	// 5. æ£€æŸ¥å“åº”çŠ¶æ€
	if !response.Success {
		errorMsg := "æœªçŸ¥é”™è¯¯"
		if response.ErrorMessage != nil {
			errorMsg = *response.ErrorMessage
		}
		return nil, fmt.Errorf("å¯¹ç«¯å¤„ç†å¤±è´¥: %s", errorMsg)
	}

	// 6. éªŒè¯å“åº”å†…å®¹
	if response.RequestId != request.RequestId {
		return nil, fmt.Errorf("å“åº”IDä¸åŒ¹é…: æœŸæœ›=%s, å®é™…=%s", request.RequestId, response.RequestId)
	}

	// âœ… v2 ç¡¬é—¨æ§›ï¼šå“åº”å¿…é¡»å›ä¼  chain_identityï¼Œä¸”å¿…é¡»ä¸æœ¬åœ°ä¸€è‡´ï¼›å¦åˆ™è§†ä¸º"ä¸å…¼å®¹ peer"
	if response.ChainIdentity == nil {
		MarkBadPeer(sourcePeer)
		recordSyncFailure(sourcePeer, "blocks", FailureReasonChainIdentityMismatch,
			"SyncBlocksV2 missing chain_identity in response (incompatible peer)", logger)
		recordUpstreamFailure(sourcePeer, logger)
		return nil, fmt.Errorf("SyncBlocksV2 missing chain_identity in response (incompatible peer)")
	}
	remoteIdentity := node.FromProtoChainIdentity(response.ChainIdentity)
	if !remoteIdentity.IsValid() || !localChainIdentity.IsSameChain(remoteIdentity) {
		if logger != nil {
			logger.Warnf("policy.reject_sync_peer: SyncBlocksV2 å“åº”é“¾èº«ä»½ä¸åŒ¹é…, peer=%s remote=%v local=%v",
				sourcePeer.String()[:8], remoteIdentity, localChainIdentity)
		}
		MarkBadPeer(sourcePeer)
		recordSyncFailure(sourcePeer, "blocks", FailureReasonChainIdentityMismatch,
			fmt.Sprintf("SyncBlocksV2 incompatible peer: remote=%v local=%v", remoteIdentity, localChainIdentity), logger)
		recordUpstreamFailure(sourcePeer, logger)
		return nil, fmt.Errorf("SyncBlocksV2 incompatible peer: remote=%v local=%v", remoteIdentity, localChainIdentity)
	}

	blocks := response.Blocks
	if len(blocks) == 0 {
		if logger != nil {
			logger.Warnf("âš ï¸ èŠ‚ç‚¹ %s è¿”å›ç©ºåŒºå—åˆ—è¡¨ (èŒƒå›´ [%d, %d]), NextHeight=%d",
				sourcePeer.String()[:8], startHeight, endHeight, response.NextHeight)
		}

		// ğŸ”§ **ç©ºæ‰¹æ¬¡å¤„ç†ç­–ç•¥**ï¼š
		// å¦‚æœå¯¹ç«¯è¿”å›ç©ºåŒºå—ä½†æä¾›äº†NextHeightï¼Œè¯´æ˜å¯ä»¥è·³è¿‡å½“å‰èŒƒå›´
		if response.NextHeight > startHeight {
			// è¿”å›ç‰¹æ®Šçš„"ç©ºè·³è·ƒ"ç»“æœï¼Œè®©ä¸Šå±‚èƒ½æ ¹æ®NextHeightæ¨è¿›
			return []*core.Block{}, &EmptyBatchError{
				StartHeight: startHeight,
				EndHeight:   endHeight,
				NextHeight:  response.NextHeight,
				Reason:      response.PaginationReason,
			}
		}

		// NextHeightæœªå‰è¿›ï¼Œè¯´æ˜èŠ‚ç‚¹å¯èƒ½æœ‰é—®é¢˜
		return []*core.Block{}, fmt.Errorf("èŠ‚ç‚¹è¿”å›ç©ºæ‰¹æ¬¡ä¸”æœªæä¾›æœ‰æ•ˆçš„NextHeight: start=%d, next=%d",
			startHeight, response.NextHeight)
	}

	// 7. éªŒè¯åŒºå—é«˜åº¦è¿ç»­æ€§
	if err := validateBlockSequence(blocks, startHeight, logger); err != nil {
		return nil, fmt.Errorf("åŒºå—åºåˆ—éªŒè¯å¤±è´¥: %w", err)
	}

	if logger != nil {
		logger.Infof("âœ… æˆåŠŸè·å–åŒºå—èŒƒå›´ [%d, %d]: è¿”å›%dä¸ªåŒºå—, å¤§å°=%då­—èŠ‚, åˆ†é¡µ=%s",
			startHeight, endHeight, len(blocks), response.ActualSize, response.PaginationReason)

		if response.HasMore {
			logger.Infof("ğŸ“„ è¿˜æœ‰æ›´å¤šæ•°æ®ï¼Œä¸‹æ¬¡è¯·æ±‚é«˜åº¦: %d", response.NextHeight)
		}
	}

	return blocks, nil
}

// validateBlockSequence éªŒè¯åŒºå—åºåˆ—çš„è¿ç»­æ€§å’Œæœ‰æ•ˆæ€§
func validateBlockSequence(blocks []*core.Block, expectedStartHeight uint64, logger log.Logger) error {
	if len(blocks) == 0 {
		return nil // ç©ºåºåˆ—æ— éœ€éªŒè¯
	}

	// æ£€æŸ¥ç¬¬ä¸€ä¸ªåŒºå—æ˜¯å¦ä¸º nil
	firstBlock := blocks[0]
	if firstBlock == nil {
		return fmt.Errorf("é¦–ä¸ªåŒºå—ä¸º nil")
	}

	// æ£€æŸ¥ç¬¬ä¸€ä¸ªåŒºå—å¤´æ˜¯å¦ä¸º nil
	if firstBlock.Header == nil {
		return fmt.Errorf("é¦–ä¸ªåŒºå—å¤´ä¸º nil")
	}

	if firstBlock.Header.Height != expectedStartHeight {
		return fmt.Errorf("é¦–ä¸ªåŒºå—é«˜åº¦ä¸åŒ¹é…: æœŸæœ›=%d, å®é™…=%d",
			expectedStartHeight, firstBlock.Header.Height)
	}

	// æ£€æŸ¥åŒºå—é«˜åº¦è¿ç»­æ€§
	for i := 1; i < len(blocks); i++ {
		// æ£€æŸ¥å½“å‰åŒºå—å’Œå‰ä¸€ä¸ªåŒºå—æ˜¯å¦ä¸º nil
		if blocks[i-1] == nil {
			return fmt.Errorf("åŒºå—åºåˆ—ä¸­ä½ç½® %d çš„åŒºå—ä¸º nil", i-1)
		}
		if blocks[i-1].Header == nil {
			return fmt.Errorf("åŒºå—åºåˆ—ä¸­ä½ç½® %d çš„åŒºå—å¤´ä¸º nil", i-1)
		}
		if blocks[i] == nil {
			return fmt.Errorf("åŒºå—åºåˆ—ä¸­ä½ç½® %d çš„åŒºå—ä¸º nil", i)
		}
		if blocks[i].Header == nil {
			return fmt.Errorf("åŒºå—åºåˆ—ä¸­ä½ç½® %d çš„åŒºå—å¤´ä¸º nil", i)
		}

		prevHeight := blocks[i-1].Header.Height
		currentHeight := blocks[i].Header.Height

		if currentHeight != prevHeight+1 {
			return fmt.Errorf("åŒºå—é«˜åº¦ä¸è¿ç»­: ä½ç½®%d height=%d, ä½ç½®%d height=%d",
				i-1, prevHeight, i, currentHeight)
		}
	}

	if logger != nil {
		// å†æ¬¡æ£€æŸ¥æœ€åä¸€ä¸ªåŒºå—æ˜¯å¦ä¸º nil
		lastBlock := blocks[len(blocks)-1]
		if lastBlock != nil && lastBlock.Header != nil {
			logger.Debugf("âœ… åŒºå—åºåˆ—éªŒè¯é€šè¿‡: é«˜åº¦èŒƒå›´ [%d, %d]",
				blocks[0].Header.Height, lastBlock.Header.Height)
		} else {
			logger.Debugf("âœ… åŒºå—åºåˆ—éªŒè¯é€šè¿‡: èµ·å§‹é«˜åº¦=%d", blocks[0].Header.Height)
		}
	}

	return nil
}

// ============================================================================
//                           åŒºå—æ‰¹å¤„ç†å®ç°
// ============================================================================

// processBlockBatch å¤„ç†åŒºå—æ‰¹æ¬¡ï¼ˆå†…å­˜ä¼˜åŒ–ç‰ˆæœ¬ï¼‰
//
// ğŸ¯ **åŒºå—å¤„ç†ç­–ç•¥**ï¼š
// 1. å°†å¤§æ‰¹æ¬¡åˆ†å‰²ä¸ºå°æ‰¹æ¬¡ï¼ˆé»˜è®¤50ä¸ªåŒºå—ä¸€æ‰¹ï¼‰
// 2. æ‰¹æ¬¡é—´æ·»åŠ å»¶è¿Ÿï¼Œè®©GCæœ‰æ—¶é—´å·¥ä½œ
// 3. å®šæœŸæ£€æŸ¥å†…å­˜ä½¿ç”¨ï¼Œå¿…è¦æ—¶è§¦å‘GC
// 4. é€ä¸ªéªŒè¯åŒºå—çš„æœ‰æ•ˆæ€§
// 5. éªŒè¯é€šè¿‡åå¤„ç†åŒºå—ï¼ˆåº”ç”¨çŠ¶æ€å˜æ›´ï¼‰
// 6. è®°å½•å¤„ç†ç»“æœå’Œé”™è¯¯ä¿¡æ¯
func processBlockBatch(
	ctx context.Context,
	blocks []*core.Block,
	blockValidator block.BlockValidator,
	blockProcessor block.BlockProcessor,
	logger log.Logger,
) error {
	if len(blocks) == 0 {
		return nil // ç©ºæ‰¹æ¬¡ï¼Œç›´æ¥è¿”å›
	}

	if logger != nil {
		logger.Infof("ğŸ”¨ å¼€å§‹å¤„ç†åŒºå—æ‰¹æ¬¡: %d ä¸ªåŒºå— (åˆ†æ‰¹å¤„ç†ï¼Œæ¯æ‰¹%dä¸ª)",
			len(blocks), MAX_BLOCK_BATCH_SIZE)
	}

	// åˆ†æ‰¹å¤„ç†åŒºå—
	for i := 0; i < len(blocks); i += MAX_BLOCK_BATCH_SIZE {
		end := i + MAX_BLOCK_BATCH_SIZE
		if end > len(blocks) {
			end = len(blocks)
		}

		batch := blocks[i:end]

		// å¤„ç†å½“å‰æ‰¹æ¬¡
		if err := processBatch(ctx, batch, blockValidator, blockProcessor, logger, i+1, len(blocks)); err != nil {
			return err
		}

		// æ‰¹æ¬¡é—´å»¶è¿Ÿï¼Œè®©GCæœ‰æ—¶é—´å·¥ä½œ
		if end < len(blocks) {
			select {
			case <-ctx.Done():
				return fmt.Errorf("åŒºå—å¤„ç†è¢«å–æ¶ˆ: %w", ctx.Err())
			case <-time.After(BATCH_PROCESS_DELAY):
				// ç»§ç»­ä¸‹ä¸€æ‰¹æ¬¡
				if logger != nil {
					logger.Debugf("â³ æ‰¹æ¬¡é—´å»¶è¿Ÿå®Œæˆï¼Œç»§ç»­å¤„ç†ä¸‹ä¸€æ‰¹æ¬¡")
				}
			}
		}
	}

	if logger != nil {
		logger.Infof("âœ… åŒºå—æ‰¹æ¬¡å¤„ç†å®Œæˆ: %d ä¸ªåŒºå—", len(blocks))
	}

	return nil
}

// processBatch å¤„ç†å•ä¸ªå°æ‰¹æ¬¡
func processBatch(ctx context.Context, batch []*core.Block,
	blockValidator block.BlockValidator,
	blockProcessor block.BlockProcessor,
	logger log.Logger,
	startIndex, totalBlocks int) error {

	var memStats runtime.MemStats

	for i, block := range batch {
		// æ£€æŸ¥å–æ¶ˆä¿¡å·
		select {
		case <-ctx.Done():
			return fmt.Errorf("åŒºå—å¤„ç†è¢«å–æ¶ˆ: %w", ctx.Err())
		default:
			// ç»§ç»­å¤„ç†
		}

		// éªŒè¯åŒºå—ï¼ˆå§”æ‰˜ç»™BlockValidatorï¼Œé¿å…é‡å¤éªŒè¯é€»è¾‘ï¼‰
		valid, err := blockValidator.ValidateBlock(ctx, block)
		if err != nil {
			return fmt.Errorf("éªŒè¯åŒºå— %d å¤±è´¥: %w", block.Header.Height, err)
		}

		if !valid {
			return fmt.Errorf("åŒºå— %d éªŒè¯å¤±è´¥ï¼šåŒºå—æ— æ•ˆ", block.Header.Height)
		}

		// å¤„ç†åŒºå—ï¼ˆå§”æ‰˜ç»™BlockProcessorï¼‰
		err = blockProcessor.ProcessBlock(ctx, block)
		if err != nil {
			// ğŸ†• 2025-12-18: å¤„ç†"åŒºå—å·²è¢«å…¶ä»–æµç¨‹å¤„ç†"çš„æƒ…å†µï¼ˆå¹‚ç­‰æ€§ï¼‰
			// åœºæ™¯ï¼šåŒæ­¥æµç¨‹å’Œèšåˆå™¨/æŒ–çŸ¿åŒæ—¶å†™å…¥åŒºå—ï¼Œåè€…å…ˆå®Œæˆ
			if errors.Is(err, persistence.ErrBlockAlreadyProcessed) {
				if logger != nil {
					logger.Infof("â­ï¸ åŒºå— %d å·²è¢«å…¶ä»–æµç¨‹å¤„ç†ï¼Œè·³è¿‡ï¼ˆå¹‚ç­‰æ€§ä¿æŠ¤ï¼‰", block.Header.Height)
				}
				continue // è·³è¿‡è¯¥åŒºå—ï¼Œç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ª
			}
			return fmt.Errorf("å¤„ç†åŒºå— %d å¤±è´¥: %w", block.Header.Height, err)
		}

		// å®šæœŸæ£€æŸ¥å†…å­˜ä½¿ç”¨å’Œå¼ºåˆ¶GC
		shouldCheckMemory := (i+1)%MEMORY_CHECK_INTERVAL == 0
		shouldForceGC := (startIndex+i)%FORCE_GC_INTERVAL == 0

		if shouldCheckMemory || shouldForceGC {
			runtime.ReadMemStats(&memStats)
			currentMemMB := memStats.Alloc / 1024 / 1024

			// å¦‚æœå†…å­˜ä½¿ç”¨è¶…è¿‡é˜ˆå€¼ï¼Œå¼ºåˆ¶GC
			if memStats.Alloc > MEMORY_GC_THRESHOLD || shouldForceGC {
				if logger != nil {
					logger.Debugf("ğŸ§¹ %s å†…å­˜ä½¿ç”¨: %d MBï¼Œè§¦å‘GC",
						map[bool]string{true: "å¼ºåˆ¶", false: "é˜ˆå€¼"}[shouldForceGC], currentMemMB)
				}
				runtime.GC()
				runtime.ReadMemStats(&memStats)
				newMemMB := memStats.Alloc / 1024 / 1024
				if logger != nil {
					logger.Debugf("ğŸ§¹ GCå®Œæˆï¼Œå†…å­˜ä½¿ç”¨: %d MB -> %d MB (èŠ‚çœ: %d MB)",
						currentMemMB, newMemMB, currentMemMB-newMemMB)
				}
			} else if shouldCheckMemory && logger != nil {
				logger.Debugf("ğŸ’¾ å†…å­˜æ£€æŸ¥: %d MB (é˜ˆå€¼: %d MB)", currentMemMB, MEMORY_GC_THRESHOLD/1024/1024)
			}
		}

		// æ¯10ä¸ªåŒºå—è®°å½•ä¸€æ¬¡è¿›åº¦
		if logger != nil && (i+1)%10 == 0 {
			currentIndex := startIndex + i
			logger.Debugf("âœ… åŒºå— %d å¤„ç†æˆåŠŸ (%d/%d)",
				block.Header.Height, currentIndex, totalBlocks)
		}
	}

	if logger != nil {
		logger.Debugf("âœ… å°æ‰¹æ¬¡å¤„ç†å®Œæˆ: %d ä¸ªåŒºå—", len(batch))
	}

	return nil
}
