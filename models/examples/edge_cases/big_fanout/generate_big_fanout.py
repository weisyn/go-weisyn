#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# This script creates example_big_fanout.onnx to use in testing. The idea is
# to create a newtwork where parallelism makes a big difference.

"""
å¤§æ‰‡å‡ºç½‘ç»œ ONNX æ¨¡å‹ç”Ÿæˆè„šæœ¬ï¼ˆä¸­æ–‡æ³¨é‡Šè¡¥å……ï¼‰

æœ¬è„šæœ¬ç”¨äºç”Ÿæˆ example_big_fanout.onnx æ¨¡å‹æ–‡ä»¶ï¼Œç”¨äºæµ‹è¯• WES å¹³å°å¯¹å¹¶è¡Œè®¡ç®—çš„å¤„ç†èƒ½åŠ›ã€‚

æ¨¡å‹è®¾è®¡ç›®çš„ï¼š
- æµ‹è¯• WES å¹³å°å¯¹å¹¶è¡ŒåŒ–ç½‘ç»œçš„å¤„ç†èƒ½åŠ›
- éªŒè¯å¤§é‡å¹¶è¡ŒçŸ©é˜µä¹˜æ³•æ“ä½œçš„æ‰§è¡Œæ•ˆç‡
- æµ‹è¯•æ‰‡å‡ºï¼ˆfanoutï¼‰ç½‘ç»œç»“æ„çš„å¤„ç†
- éªŒè¯åˆå¹¶å’Œæ±‚å’Œæ“ä½œçš„æ€§èƒ½

æ¨¡å‹è¯´æ˜ï¼š
- è¾“å…¥ï¼š1x4 å‘é‡
- è¾“å‡ºï¼š1x4 å‘é‡
- ç»“æ„ï¼š100 ä¸ªå¹¶è¡Œçš„çŸ©é˜µä¹˜æ³•æ“ä½œï¼Œç„¶ååˆå¹¶å¹¶æ±‚å’Œ

WES å¹³å°æµ‹è¯•åœºæ™¯ï¼š
- âœ… å¹¶è¡Œè®¡ç®—èƒ½åŠ›ï¼ˆ100 ä¸ªå¹¶è¡ŒçŸ©é˜µä¹˜æ³•ï¼‰
- âœ… å¤§æ‰‡å‡ºç½‘ç»œå¤„ç†
- âœ… å¼ é‡åˆå¹¶ï¼ˆconcatï¼‰æ“ä½œ
- âœ… æ±‚å’Œï¼ˆsumï¼‰æ“ä½œ
- âœ… æ€§èƒ½ä¼˜åŒ–æµ‹è¯•

ä½¿ç”¨æ–¹æ³•ï¼š
    python generate_big_fanout.py

ä¾èµ–è¦æ±‚ï¼š
    pip install torch onnx
"""
import torch


class BigFanoutModel(torch.nn.Module):
    """å¤§æ‰‡å‡ºç½‘ç»œæ¨¡å‹ã€‚
    
    å°† 1x4 å‘é‡æ˜ å°„åˆ°å¦ä¸€ä¸ª 1x4 å‘é‡ï¼Œä½†é€šè¿‡å¤§é‡å¯å¹¶è¡Œçš„å…¨è¿æ¥æ“ä½œã€‚
    è¯¥æ¨¡å‹è®¾è®¡ç”¨äºæµ‹è¯•å¹¶è¡Œè®¡ç®—èƒ½åŠ›ã€‚
    
    Maps a 1x4 vector to another 1x4 vector, but goes through a large
    number of parallelizable useless FC operations.
    """
    
    def __init__(self):
        """åˆå§‹åŒ–æ¨¡å‹ã€‚
        
        åˆ›å»º 100 ä¸ªéšæœºçš„ 4x4 çŸ©é˜µï¼Œç”¨äºå¹¶è¡ŒçŸ©é˜µä¹˜æ³•æ“ä½œã€‚
        """
        super().__init__()
        # æ‰‡å‡ºæ•°é‡ï¼š100 ä¸ªå¹¶è¡Œæ“ä½œ
        # Fanout amount: 100 parallel operations
        self.fanout_amount = 100
        # åˆ›å»º 100 ä¸ªéšæœºçš„ 4x4 çŸ©é˜µ
        # Create 100 random 4x4 matrices
        self.matrices = [torch.rand((4, 4)) for i in range(self.fanout_amount)]

    def forward(self, x):
        """å‰å‘ä¼ æ’­ï¼šæ‰§è¡Œå¤§é‡å¹¶è¡ŒçŸ©é˜µä¹˜æ³•ï¼Œç„¶ååˆå¹¶å¹¶æ±‚å’Œã€‚
        
        Args:
            x: float32 ç±»å‹çš„è¾“å…¥å¼ é‡ï¼Œå½¢çŠ¶ [1, 4]
        
        Returns:
            output: float32 ç±»å‹çš„è¾“å‡ºå¼ é‡ï¼Œå½¢çŠ¶ [1, 4]
        
        è®¡ç®—æµç¨‹ï¼š
        1. æ‰§è¡Œ 100 ä¸ªå¹¶è¡Œçš„çŸ©é˜µä¹˜æ³•æ“ä½œ
        2. å°†æ‰€æœ‰ç»“æœåˆå¹¶ï¼ˆconcatï¼‰
        3. å¯¹åˆå¹¶åçš„å¼ é‡æ±‚å’Œ
        """
        # æ‰§è¡Œ fanout_amount ä¸ªçŸ©é˜µä¹˜æ³•ï¼Œç„¶ååˆå¹¶å¹¶æ±‚å’Œç»“æœ
        # Do fanout_amount matrix multiplies, then merge and sum the result
        # è¿™ 100 ä¸ªæ“ä½œå¯ä»¥å¹¶è¡Œæ‰§è¡Œï¼Œæµ‹è¯• WES å¹³å°çš„å¹¶è¡Œè®¡ç®—èƒ½åŠ›
        # These 100 operations can be executed in parallel, testing WES platform's parallel computing capability
        tmp_results = [
            torch.matmul(x, self.matrices[i])
            for i in range(self.fanout_amount)
        ]
        # åˆå¹¶æ‰€æœ‰ç»“æœï¼šå°† 100 ä¸ª [1, 4] å¼ é‡åˆå¹¶ä¸º [100, 4]
        # Concatenate all results: merge 100 [1, 4] tensors into [100, 4]
        combined_tensor = torch.cat(tmp_results)
        # å¯¹ç¬¬ 0 ç»´æ±‚å’Œï¼šå°† [100, 4] æ±‚å’Œä¸º [4]ï¼Œç„¶åæ‰©å±•ä¸º [1, 4]
        # Sum along dimension 0: sum [100, 4] to [4], then expand to [1, 4]
        return combined_tensor.sum(0)


def main():
    """ä¸»å‡½æ•°ï¼šåˆ›å»ºæ¨¡å‹ã€ç”Ÿæˆæµ‹è¯•æ•°æ®ã€å¯¼å‡º ONNX æ¨¡å‹ã€‚
    
    æµç¨‹ï¼š
    1. åˆ›å»ºæ¨¡å‹å®ä¾‹å¹¶è®¾ç½®ä¸º float32 ç±»å‹
    2. è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
    3. ç¦ç”¨æ¢¯åº¦è®¡ç®—ï¼ˆæ¨ç†æ¨¡å¼ï¼‰
    4. å¯¼å‡ºä¸º ONNX æ ¼å¼
    """
    # åˆ›å»ºæ¨¡å‹å®ä¾‹
    # Create model instance
    model = BigFanoutModel()
    # å°†æ¨¡å‹è½¬æ¢ä¸º float32 ç±»å‹ï¼ˆç¡®ä¿æ‰€æœ‰å‚æ•°éƒ½æ˜¯ float32ï¼‰
    # Convert model to float32 type (ensure all parameters are float32)
    model.float()
    # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼ï¼šç¦ç”¨ dropoutã€batch normalization ç­‰è®­ç»ƒæ—¶çš„è¡Œä¸º
    # Set to evaluation mode: disable dropout, batch normalization, etc.
    model.eval()
    
    # ç”Ÿæˆæµ‹è¯•è¾“å…¥æ•°æ®
    # Generate test input data
    test_input = torch.rand((1, 4), dtype=torch.float32)
    output_name = "example_big_fanout.onnx"
    
    # ç¦ç”¨æ¢¯åº¦è®¡ç®—ï¼šæ¨ç†æ—¶ä¸éœ€è¦æ¢¯åº¦
    # Disable gradient computation: not needed for inference
    test_input.requires_grad = False
    for param in model.parameters():
        param.requires_grad = False
    
    # ä½¿ç”¨ torch.no_grad() ä¸Šä¸‹æ–‡ç®¡ç†å™¨å¯¼å‡ºæ¨¡å‹
    # Export model using torch.no_grad() context manager
    # è¿™æ ·å¯ä»¥èŠ‚çœå†…å­˜å¹¶åŠ å¿«å¯¼å‡ºé€Ÿåº¦
    # This saves memory and speeds up export
    with torch.no_grad():
        torch.onnx.export(
            model, 
            (test_input), 
            output_name,
            input_names=["input"], 
            output_names=["output"]
        )
    print(f"Saved {output_name} OK.")
    
    print("\nâœ… æ¨¡å‹ç”Ÿæˆå®Œæˆï¼")
    print("ğŸ“ è¯¥æ¨¡å‹å¯ç”¨äºæµ‹è¯• WES å¹³å°å¯¹å¹¶è¡Œè®¡ç®—çš„å¤„ç†èƒ½åŠ›ã€‚")
    print("ğŸ“– è¯¦ç»†ä½¿ç”¨è¯´æ˜è¯·å‚è€ƒ README.md")

if __name__ == "__main__":
    main()

