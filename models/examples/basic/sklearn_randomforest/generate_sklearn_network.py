#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# This script is a modified version of the example from
# https://pypi.org/project/skl2onnx/, which we use to produce
# sklearn_randomforest.onnx. sklearn makes heavy use of onnxruntime maps and
# sequences in its networks, so this is used for testing those data types.

"""
sklearn éšæœºæ£®æ— ONNX æ¨¡å‹ç”Ÿæˆè„šæœ¬ï¼ˆä¸­æ–‡æ³¨é‡Šè¡¥å……ï¼‰

æœ¬è„šæœ¬ç”¨äºç”Ÿæˆ sklearn_randomforest.onnx æ¨¡å‹æ–‡ä»¶ï¼Œç”¨äºæµ‹è¯• WES å¹³å°å¯¹
sklearn æ¨¡å‹å’Œå¤æ‚æ•°æ®ç±»å‹ï¼ˆMapã€Sequenceï¼‰çš„æ”¯æŒèƒ½åŠ›ã€‚

æ¨¡å‹è®¾è®¡ç›®çš„ï¼š
- æµ‹è¯• WES å¹³å°å¯¹ sklearn æ¨¡å‹çš„æ”¯æŒ
- éªŒè¯ ONNX Runtime å¯¹ Map å’Œ Sequence æ•°æ®ç±»å‹çš„æ”¯æŒ
- æµ‹è¯•éšæœºæ£®æ—åˆ†ç±»å™¨çš„æ¨ç†èƒ½åŠ›
- éªŒè¯å¤šè¾“å‡ºæ¨¡å‹ï¼ˆæ ‡ç­¾ + æ¦‚ç‡ï¼‰çš„å¤„ç†

æ¨¡å‹è¯´æ˜ï¼š
- åŸºäº scikit-learn çš„éšæœºæ£®æ—åˆ†ç±»å™¨
- ä½¿ç”¨ Irisï¼ˆé¸¢å°¾èŠ±ï¼‰æ•°æ®é›†è¿›è¡Œè®­ç»ƒ
- è¾“å…¥ï¼š4 ä¸ªç‰¹å¾ï¼ˆèŠ±è¼é•¿åº¦ã€èŠ±è¼å®½åº¦ã€èŠ±ç“£é•¿åº¦ã€èŠ±ç“£å®½åº¦ï¼‰
- è¾“å‡ºï¼šåˆ†ç±»æ ‡ç­¾ï¼ˆ0, 1, 2ï¼‰å’Œæ¦‚ç‡åˆ†å¸ƒ

WES å¹³å°æµ‹è¯•åœºæ™¯ï¼š
- âœ… sklearn æ¨¡å‹è½¬æ¢åˆ° ONNX
- âœ… Map æ•°æ®ç±»å‹æ”¯æŒï¼ˆsklearn æ¨¡å‹å¤§é‡ä½¿ç”¨ï¼‰
- âœ… Sequence æ•°æ®ç±»å‹æ”¯æŒï¼ˆsklearn æ¨¡å‹å¤§é‡ä½¿ç”¨ï¼‰
- âœ… å¤šè¾“å‡ºæ¨¡å‹ï¼ˆoutput_label, output_probabilityï¼‰
- âœ… åˆ†ç±»ä»»åŠ¡æ¨ç†

ä½¿ç”¨æ–¹æ³•ï¼š
    python generate_sklearn_network.py

ä¾èµ–è¦æ±‚ï¼š
    pip install numpy scikit-learn skl2onnx onnxruntime
"""
import numpy as np
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier

# åŠ è½½ Iris æ•°æ®é›†
# Load Iris dataset
# Iris æ•°æ®é›†åŒ…å« 150 ä¸ªæ ·æœ¬ï¼Œæ¯ä¸ªæ ·æœ¬æœ‰ 4 ä¸ªç‰¹å¾ï¼ˆèŠ±è¼é•¿åº¦ã€èŠ±è¼å®½åº¦ã€èŠ±ç“£é•¿åº¦ã€èŠ±ç“£å®½åº¦ï¼‰
# 3 ä¸ªç±»åˆ«ï¼ˆSetosa, Versicolor, Virginicaï¼‰
# Iris dataset contains 150 samples, each with 4 features (sepal length, sepal width, petal length, petal width)
# 3 classes (Setosa, Versicolor, Virginica)
iris = load_iris()
inputs, outputs = iris.data, iris.target

# å°†è¾“å…¥è½¬æ¢ä¸º float32 ç±»å‹ï¼ˆONNX å¸¸ç”¨ç±»å‹ï¼‰
# Convert inputs to float32 type (commonly used in ONNX)
inputs = inputs.astype(np.float32)

# åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
# Split into training and test sets
inputs_train, inputs_test, outputs_train, outputs_test = train_test_split(inputs, outputs)

# åˆ›å»ºå¹¶è®­ç»ƒéšæœºæ£®æ—åˆ†ç±»å™¨
# Create and train RandomForest classifier
# éšæœºæ£®æ—ä½¿ç”¨é»˜è®¤å‚æ•°ï¼Œé€‚åˆå¿«é€Ÿæµ‹è¯•
# RandomForest uses default parameters, suitable for quick testing
classifier = RandomForestClassifier()
classifier.fit(inputs_train, outputs_train)

# è½¬æ¢ä¸º ONNX æ ¼å¼
# Convert to ONNX format
# skl2onnx æ˜¯ sklearn æ¨¡å‹è½¬æ¢ä¸º ONNX çš„å·¥å…·
# skl2onnx is a tool for converting sklearn models to ONNX
from skl2onnx import to_onnx

output_filename = "sklearn_randomforest.onnx"
# ä½¿ç”¨ç¬¬ä¸€ä¸ªæ ·æœ¬ä½œä¸ºç¤ºä¾‹è¾“å…¥ï¼Œç”¨äºç¡®å®šè¾“å…¥å½¢çŠ¶å’Œç±»å‹
# Use first sample as example input to determine input shape and type
onnx_content = to_onnx(classifier, inputs[:1])

# ä¿å­˜ ONNX æ¨¡å‹æ–‡ä»¶
# Save ONNX model file
with open(output_filename, "wb") as f:
    f.write(onnx_content.SerializeToString())

# ä½¿ç”¨ ONNX Runtime éªŒè¯æ¨¡å‹
# Verify model with ONNX Runtime
import onnxruntime as ort

def float_formatter(f):
    """
    æµ®ç‚¹æ•°æ ¼å¼åŒ–å‡½æ•°ï¼šä¿ç•™ 6 ä½å°æ•°
    
    Float formatter function: keep 6 decimal places
    """
    return f"{float(f):.06f}"

# è®¾ç½® numpy æ‰“å°æ ¼å¼ï¼šä½¿ç”¨è‡ªå®šä¹‰æ ¼å¼åŒ–å‡½æ•°
# Set numpy print format: use custom formatter function
np.set_printoptions(formatter={'float_kind': float_formatter})

# åˆ›å»º ONNX Runtime æ¨ç†ä¼šè¯
# Create ONNX Runtime inference session
session = ort.InferenceSession(output_filename)

# æ‰“å°æ¨¡å‹çš„è¾“å…¥è¾“å‡ºä¿¡æ¯
# Print model input/output information
print(f"Input names: {[n.name for n in session.get_inputs()]!s}")
print(f"Output names: {[o.name for o in session.get_outputs()]!s}")

# å‡†å¤‡æµ‹è¯•è¾“å…¥ï¼šä½¿ç”¨æµ‹è¯•é›†çš„å‰ 6 ä¸ªæ ·æœ¬
# Prepare test inputs: use first 6 samples from test set
example_inputs = inputs_test.astype(np.float32)[:6]
print(f"Inputs shape = {example_inputs.shape!s}")

# è¿è¡Œæ¨ç†ï¼šè·å–åˆ†ç±»æ ‡ç­¾å’Œæ¦‚ç‡
# Run inference: get classification labels and probabilities
onnx_predictions = session.run(
    ["output_label", "output_probability"],
    {"X": example_inputs}
)
labels = onnx_predictions[0]
probabilities = onnx_predictions[1]

# æ‰“å°æ¨ç†ç»“æœ
# Print inference results
print(f"Inputs to network: {example_inputs.astype(np.float32)}")
print(f"ONNX predicted labels: {labels!s}")
print(f"ONNX predicted probabilities: {probabilities!s}")

print("\nâœ… æ¨¡å‹ç”Ÿæˆå®Œæˆï¼")
print("ğŸ“ è¯¥æ¨¡å‹å¯ç”¨äºæµ‹è¯• WES å¹³å°å¯¹ sklearn æ¨¡å‹å’Œå¤æ‚æ•°æ®ç±»å‹çš„æ”¯æŒèƒ½åŠ›ã€‚")
print("ğŸ“– è¯¦ç»†ä½¿ç”¨è¯´æ˜è¯·å‚è€ƒ README.md")

